# AI ê¸°ë°˜ í…ìŠ¤íŠ¸ ë¶„ì„ ë° ì»¤ë¦¬í˜ëŸ¼ ìƒì„± ëª¨ë“ˆ
# AI Provider Managerë¥¼ ì‚¬ìš©í•˜ì—¬ PDF ë‚´ìš©ì„ ë¶„ì„í•˜ê³  í•™ìŠµ ì»¤ë¦¬í˜ëŸ¼ì„ ìƒì„±í•©ë‹ˆë‹¤.

import os
import json
from pathlib import Path
from typing import Dict, List, Optional
from dotenv import load_dotenv
from langchain.text_splitter import RecursiveCharacterTextSplitter

# AI Provider Manager ì„í¬íŠ¸
try:
    from ai_providers import get_ai_manager
    from config import settings
    USE_AI_MANAGER = True
except ImportError:
    # ê¸°ì¡´ OpenAI ë°©ì‹ìœ¼ë¡œ í´ë°±
    import openai
    USE_AI_MANAGER = False

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

class AIProcessor:
    """AIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ë¶„ì„ ë° ì»¤ë¦¬í˜ëŸ¼ ìƒì„±ì„ ë‹´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤."""
    
    def __init__(self, data_folder: str = "data"):
        """
        AI ì²˜ë¦¬ê¸°ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        
        Args:
            data_folder: ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ ì €ì¥í•  í´ë”
        """
        self.data_folder = data_folder
        self.summaries_folder = f"{data_folder}/summaries"
        
        # í•„ìš”í•œ í´ë” ìƒì„±
        Path(self.summaries_folder).mkdir(parents=True, exist_ok=True)
        
        # AI Provider Manager ì´ˆê¸°í™”
        if USE_AI_MANAGER:
            try:
                self.ai_manager = get_ai_manager()
                self.model = settings.AI_PROVIDERS_CONFIG.get("openai", {}).get("default_model", "gpt-3.5-turbo")
                self.max_tokens = int(os.getenv("MAX_TOKENS", "1000"))
                self.temperature = float(os.getenv("TEMPERATURE", "0.7"))
                print(f"ğŸ¤– AI ì²˜ë¦¬ê¸° ì´ˆê¸°í™” ì™„ë£Œ (AI Manager ì‚¬ìš©, ëª¨ë¸: {self.model})")
            except Exception as e:
                print(f"âš ï¸ AI Manager ì´ˆê¸°í™” ì‹¤íŒ¨, ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±: {str(e)}")
                self._init_legacy_openai()
        else:
            self._init_legacy_openai()
        
        # í…ìŠ¤íŠ¸ ë¶„í•  ì„¤ì •
        self.chunk_size = int(os.getenv("CHUNK_SIZE", "1000"))
        self.chunk_overlap = int(os.getenv("CHUNK_OVERLAP", "200"))
    
    def _init_legacy_openai(self):
        """ê¸°ì¡´ OpenAI ë°©ì‹ìœ¼ë¡œ ì´ˆê¸°í™” (í´ë°±ìš©)"""
        self.api_key = os.getenv("OPENAI_API_KEY")
        if not self.api_key:
            try:
                raise ValueError("âŒ OPENAI_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
            except UnicodeEncodeError:
                raise ValueError("OPENAI_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        
        # Initialize OpenAI client
        self.client = openai.OpenAI(api_key=self.api_key)
        self.model = os.getenv("OPENAI_MODEL", "gpt-3.5-turbo")
        self.max_tokens = int(os.getenv("MAX_TOKENS", "1000"))
        self.temperature = float(os.getenv("TEMPERATURE", "0.7"))
        self.ai_manager = None
        
        try:
            print(f"ğŸ¤– AI ì²˜ë¦¬ê¸° ì´ˆê¸°í™” ì™„ë£Œ (ë ˆê±°ì‹œ ëª¨ë“œ, ëª¨ë¸: {self.model})")
        except UnicodeEncodeError:
            print(f"AI ì²˜ë¦¬ê¸° ì´ˆê¸°í™” ì™„ë£Œ (ë ˆê±°ì‹œ ëª¨ë“œ, ëª¨ë¸: {self.model})")
    
    def create_curriculum(self, extracted_data: Dict) -> Dict:
        """
        ì¶”ì¶œëœ PDF ë°ì´í„°ë¡œë¶€í„° í•™ìŠµ ì»¤ë¦¬í˜ëŸ¼ì„ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            extracted_data: PDFì—ì„œ ì¶”ì¶œëœ ë°ì´í„°
            
        Returns:
            ìƒì„±ëœ ì»¤ë¦¬í˜ëŸ¼ ë°ì´í„°
        """
        try:
            file_name = extracted_data["file_name"]
            print(f"ğŸ“š ì»¤ë¦¬í˜ëŸ¼ ìƒì„± ì‹œì‘: {file_name}")
            
            # 1ë‹¨ê³„: í…ìŠ¤íŠ¸ë¥¼ ì˜ë¯¸ ìˆëŠ” ë‹¨ìœ„ë¡œ ë¶„í• 
            chunks = self._split_text_into_chunks(extracted_data["full_text"])
            print(f"  ğŸ“ í…ìŠ¤íŠ¸ë¥¼ {len(chunks)}ê°œ ë©ì–´ë¦¬ë¡œ ë¶„í•  ì™„ë£Œ")
            
            # 2ë‹¨ê³„: ê¸°ì¡´ ëª©ì°¨ê°€ ìˆìœ¼ë©´ í™œìš©, ì—†ìœ¼ë©´ AIë¡œ ìƒì„±
            curriculum_structure = self._create_curriculum_structure(
                extracted_data["toc"], 
                chunks,
                extracted_data["total_pages"]
            )
            
            # 3ë‹¨ê³„: ê° ì„¹ì…˜ë³„ë¡œ ìš”ì•½, í‚¤ì›Œë“œ, ì§ˆë¬¸ ìƒì„±
            curriculum_content = self._generate_section_content(chunks, curriculum_structure)
            
            # 4ë‹¨ê³„: ìµœì¢… ì»¤ë¦¬í˜ëŸ¼ êµ¬ì„±
            final_curriculum = {
                "file_name": file_name,
                "total_pages": extracted_data["total_pages"],
                "total_chunks": len(chunks),
                "structure": curriculum_structure,
                "content": curriculum_content,
                "metadata": {
                    "created_by": "AI Processor",
                    "model_used": self.model,
                    "chunks_processed": len(chunks)
                }
            }
            
            # 5ë‹¨ê³„: ê²°ê³¼ ì €ì¥
            self._save_curriculum(final_curriculum, file_name)
            
            print(f"ğŸ‰ ì»¤ë¦¬í˜ëŸ¼ ìƒì„± ì™„ë£Œ: {file_name}")
            return final_curriculum
            
        except Exception as e:
            print(f"âŒ ì»¤ë¦¬í˜ëŸ¼ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            raise Exception(f"AI ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
    
    def _split_text_into_chunks(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ë¥¼ ì˜ë¯¸ ìˆëŠ” ë‹¨ìœ„ë¡œ ë¶„í• í•©ë‹ˆë‹¤."""
        try:
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=self.chunk_size,
                chunk_overlap=self.chunk_overlap,
                length_function=len,
                separators=["\n\n", "\n", ". ", " ", ""]
            )
            
            chunks = text_splitter.split_text(text)
            return [chunk.strip() for chunk in chunks if chunk.strip()]
            
        except Exception as e:
            print(f"  âš ï¸ í…ìŠ¤íŠ¸ ë¶„í•  ì¤‘ ì˜¤ë¥˜: {str(e)}")
            # ê°„ë‹¨í•œ ë¶„í• ë¡œ ëŒ€ì²´
            return [text[i:i+self.chunk_size] for i in range(0, len(text), self.chunk_size)]
    
    def _create_curriculum_structure(self, existing_toc: List[Dict], chunks: List[str], total_pages: int) -> List[Dict]:
        """ì»¤ë¦¬í˜ëŸ¼ êµ¬ì¡°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        try:
            if existing_toc and len(existing_toc) > 0:
                print("  ğŸ“‹ ê¸°ì¡´ ëª©ì°¨ë¥¼ í™œìš©í•˜ì—¬ êµ¬ì¡° ìƒì„±")
                return self._use_existing_toc(existing_toc)
            else:
                print("  ğŸ¤– AIë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒˆë¡œìš´ êµ¬ì¡° ìƒì„±")
                return self._generate_ai_structure(chunks[:3])  # ì²˜ìŒ 3ê°œ ë©ì–´ë¦¬ë¡œ êµ¬ì¡° ìƒì„±
                
        except Exception as e:
            print(f"  âš ï¸ êµ¬ì¡° ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            # ê¸°ë³¸ êµ¬ì¡° ë°˜í™˜
            return self._create_default_structure(len(chunks))
    
    def _use_existing_toc(self, toc: List[Dict]) -> List[Dict]:
        """ê¸°ì¡´ ëª©ì°¨ë¥¼ ì»¤ë¦¬í˜ëŸ¼ êµ¬ì¡°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        structure = []
        for i, item in enumerate(toc):
            structure.append({
                "section_id": f"section_{i+1}",
                "title": item["title"],
                "level": item["level"],
                "page": item["page"],
                "chunk_range": None  # ë‚˜ì¤‘ì— ì„¤ì •
            })
        return structure
    
    def _generate_ai_structure(self, sample_chunks: List[str]) -> List[Dict]:
        """AIë¥¼ ì‚¬ìš©í•˜ì—¬ ì»¤ë¦¬í˜ëŸ¼ êµ¬ì¡°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        try:
            # ìƒ˜í”Œ í…ìŠ¤íŠ¸ ì¤€ë¹„
            sample_text = "\n\n".join(sample_chunks[:3])
            if len(sample_text) > 2000:
                sample_text = sample_text[:2000] + "..."
            
            prompt = f"""
ë‹¤ìŒ ë¬¸ì„œì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ í•™ìŠµì— ì í•©í•œ ëª©ì°¨ êµ¬ì¡°ë¥¼ 3-5ê°œ ì„¹ì…˜ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ìƒì„±í•´ì£¼ì„¸ìš”.

ë¬¸ì„œ ë‚´ìš©:
{sample_text}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
1. [ì„¹ì…˜ ì œëª©]
2. [ì„¹ì…˜ ì œëª©] 
3. [ì„¹ì…˜ ì œëª©]
...

ê° ì„¹ì…˜ì€ í•™ìŠµìê°€ ë‹¨ê³„ì ìœ¼ë¡œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ë…¼ë¦¬ì  ìˆœì„œë¡œ ë°°ì—´í•´ì£¼ì„¸ìš”.
"""

            # AI Manager ì‚¬ìš© ë˜ëŠ” ê¸°ì¡´ ë°©ì‹ í´ë°±
            if self.ai_manager:
                generation_result = self.ai_manager.generate_text(
                    prompt=prompt,
                    model=self.model,
                    max_tokens=500,
                    temperature=self.temperature
                )
                # GenerationResult ê°ì²´ì—ì„œ ì‹¤ì œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                ai_response = generation_result.text
            else:
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[{"role": "user", "content": prompt}],
                    max_tokens=500,
                    temperature=self.temperature
                )
                ai_response = response.choices[0].message.content.strip()
            
            return self._parse_ai_structure_response(ai_response)
            
        except Exception as e:
            print(f"    âš ï¸ AI êµ¬ì¡° ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return self._create_default_structure(5)
    
    def _parse_ai_structure_response(self, ai_response: str) -> List[Dict]:
        """AI ì‘ë‹µì„ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        structure = []
        lines = ai_response.split('\n')
        
        for i, line in enumerate(lines):
            line = line.strip()
            if line and (line[0].isdigit() or line.startswith('-')):
                # ë²ˆí˜¸ë‚˜ ëŒ€ì‹œë¡œ ì‹œì‘í•˜ëŠ” ì¤„ì„ ì„¹ì…˜ìœ¼ë¡œ ì¸ì‹
                title = line.split('.', 1)[-1].strip() if '.' in line else line.strip('- ')
                if title:
                    structure.append({
                        "section_id": f"section_{i+1}",
                        "title": title,
                        "level": 1,
                        "page": None,
                        "chunk_range": None
                    })
        
        return structure if structure else self._create_default_structure(3)
    
    def _create_default_structure(self, num_sections: int) -> List[Dict]:
        """ê¸°ë³¸ êµ¬ì¡°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        structure = []
        section_names = ["ë„ì…", "ì£¼ìš” ë‚´ìš©", "ì‹¬í™” í•™ìŠµ", "ê²°ë¡ ", "ì°¸ê³ ì‚¬í•­"]
        
        for i in range(min(num_sections, len(section_names))):
            structure.append({
                "section_id": f"section_{i+1}",
                "title": section_names[i],
                "level": 1,
                "page": None,
                "chunk_range": None
            })
        
        return structure
    
    def _generate_section_content(self, chunks: List[str], structure: List[Dict]) -> Dict:
        """ê° ì„¹ì…˜ë³„ë¡œ ìš”ì•½, í‚¤ì›Œë“œ, ì§ˆë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        content = {}
        chunks_per_section = max(1, len(chunks) // len(structure))
        
        for i, section in enumerate(structure):
            section_id = section["section_id"]
            
            # í•´ë‹¹ ì„¹ì…˜ì˜ í…ìŠ¤íŠ¸ ë©ì–´ë¦¬ë“¤ í• ë‹¹
            start_idx = i * chunks_per_section
            end_idx = min((i + 1) * chunks_per_section, len(chunks))
            section_chunks = chunks[start_idx:end_idx]
            
            print(f"  ğŸ” ì„¹ì…˜ '{section['title']}' ì²˜ë¦¬ ì¤‘... ({len(section_chunks)}ê°œ ë©ì–´ë¦¬)")
            
            # AIë¡œ ì„¹ì…˜ ë‚´ìš© ìƒì„±
            section_content = self._process_section_with_ai(section_chunks, section["title"])
            content[section_id] = section_content
        
        return content
    
    def _process_section_with_ai(self, chunks: List[str], section_title: str) -> Dict:
        """AIë¥¼ ì‚¬ìš©í•˜ì—¬ ì„¹ì…˜ ë‚´ìš©ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        try:
            # ì„¹ì…˜ì˜ ëª¨ë“  í…ìŠ¤íŠ¸ í•©ì¹˜ê¸°
            section_text = "\n\n".join(chunks)
            if len(section_text) > 3000:  # ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸°
                section_text = section_text[:3000] + "..."
            
            prompt = f"""
ë‹¤ìŒì€ "{section_title}" ì„¹ì…˜ì˜ ë‚´ìš©ì…ë‹ˆë‹¤. í•™ìŠµìë¥¼ ìœ„í•´ ë‹¤ìŒ ì •ë³´ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”:

ë‚´ìš©:
{section_text}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:

[ìš”ì•½]
(ì´ ì„¹ì…˜ì˜ í•µì‹¬ ë‚´ìš©ì„ 2-3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½)

[í‚¤ì›Œë“œ]
(í•µì‹¬ í‚¤ì›Œë“œ 5ê°œë¥¼ ì‰¼í‘œë¡œ êµ¬ë¶„)

[ì˜ˆìƒì§ˆë¬¸]
1. (ì´í•´ë„ í™•ì¸ ì§ˆë¬¸)
2. (ì‘ìš© ì§ˆë¬¸)  
3. (ì‹¬í™” ì§ˆë¬¸)
"""

            # AI Manager ì‚¬ìš© ë˜ëŠ” ê¸°ì¡´ ë°©ì‹ í´ë°±
            if self.ai_manager:
                generation_result = self.ai_manager.generate_text(
                    prompt=prompt,
                    model=self.model,
                    max_tokens=self.max_tokens,
                    temperature=self.temperature
                )
                # GenerationResult ê°ì²´ì—ì„œ ì‹¤ì œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                ai_response = generation_result.text
            else:
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[{"role": "user", "content": prompt}],
                    max_tokens=self.max_tokens,
                    temperature=self.temperature
                )
                ai_response = response.choices[0].message.content.strip()
            
            return self._parse_section_response(ai_response, chunks)
            
        except Exception as e:
            print(f"    âš ï¸ ì„¹ì…˜ AI ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            return self._create_default_section_content(chunks, section_title)
    
    def _parse_section_response(self, ai_response: str, chunks: List[str]) -> Dict:
        """AI ì‘ë‹µì„ êµ¬ì¡°í™”ëœ ì„¹ì…˜ ë°ì´í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        try:
            sections = ai_response.split('[')
            summary = ""
            keywords = []
            questions = []
            
            for section in sections:
                if section.startswith('ìš”ì•½]'):
                    summary = section.replace('ìš”ì•½]', '').strip()
                elif section.startswith('í‚¤ì›Œë“œ]'):
                    keywords_text = section.replace('í‚¤ì›Œë“œ]', '').strip()
                    keywords = [k.strip() for k in keywords_text.split(',') if k.strip()]
                elif section.startswith('ì˜ˆìƒì§ˆë¬¸]'):
                    questions_text = section.replace('ì˜ˆìƒì§ˆë¬¸]', '').strip()
                    questions = [q.strip() for q in questions_text.split('\n') if q.strip() and any(q.strip().startswith(str(i)) for i in range(1, 10))]
            
            return {
                "summary": summary or "ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "keywords": keywords or ["í‚¤ì›Œë“œ", "ì¶”ì¶œ", "ì‹¤íŒ¨"],
                "questions": questions or ["ì´ ì„¹ì…˜ì˜ ì£¼ìš” ë‚´ìš©ì€ ë¬´ì—‡ì¸ê°€ìš”?"],
                "original_chunks": chunks,
                "chunk_count": len(chunks)
            }
            
        except Exception as e:
            print(f"    âš ï¸ ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
            return self._create_default_section_content(chunks, "ì„¹ì…˜")
    
    def _create_default_section_content(self, chunks: List[str], section_title: str) -> Dict:
        """ê¸°ë³¸ ì„¹ì…˜ ë‚´ìš©ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        return {
            "summary": f"ì´ ì„¹ì…˜({section_title})ì—ëŠ” {len(chunks)}ê°œì˜ í…ìŠ¤íŠ¸ ë‹¨ìœ„ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.",
            "keywords": ["í•µì‹¬", "ë‚´ìš©", "í•™ìŠµ", "ì´í•´", "ì •ë¦¬"],
            "questions": [
                f"{section_title}ì˜ ì£¼ìš” ë‚´ìš©ì€ ë¬´ì—‡ì¸ê°€ìš”?",
                f"ì´ ì„¹ì…˜ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ê°œë…ì€ ë¬´ì—‡ì¸ê°€ìš”?",
                f"ì‹¤ì œë¡œ ì–´ë–»ê²Œ í™œìš©í•  ìˆ˜ ìˆì„ê¹Œìš”?"
            ],
            "original_chunks": chunks,
            "chunk_count": len(chunks)
        }
    
    def _save_curriculum(self, curriculum: Dict, file_name: str) -> str:
        """ìƒì„±ëœ ì»¤ë¦¬í˜ëŸ¼ì„ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
        try:
            json_path = f"{self.summaries_folder}/{file_name}_curriculum.json"
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(curriculum, f, ensure_ascii=False, indent=2)
            
            print(f"  ğŸ’¾ ì»¤ë¦¬í˜ëŸ¼ ì €ì¥: {json_path}")
            return json_path
            
        except Exception as e:
            print(f"  âš ï¸ ì»¤ë¦¬í˜ëŸ¼ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
            return ""

# ì‚¬ìš© ì˜ˆì‹œ í•¨ìˆ˜
def create_curriculum_from_pdf(extracted_data: Dict) -> Dict:
    """
    ì¶”ì¶œëœ PDF ë°ì´í„°ë¡œë¶€í„° ì»¤ë¦¬í˜ëŸ¼ì„ ìƒì„±í•˜ëŠ” ê°„ë‹¨í•œ í•¨ìˆ˜ì…ë‹ˆë‹¤.
    
    Args:
        extracted_data: PDFì—ì„œ ì¶”ì¶œëœ ë°ì´í„°
        
    Returns:
        ìƒì„±ëœ ì»¤ë¦¬í˜ëŸ¼
    """
    processor = AIProcessor()
    return processor.create_curriculum(extracted_data)

# í…ŒìŠ¤íŠ¸ìš© ë©”ì¸ í•¨ìˆ˜
if __name__ == "__main__":
    import sys
    import io
    
    # Windows í™˜ê²½ì—ì„œ UTF-8 ì¶œë ¥ ì„¤ì •
    if sys.platform == "win32":
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')
    
    print("ğŸ¤– AI Processor ëª¨ë“ˆ")
    print("ğŸ’¡ ì´ ëª¨ë“ˆì€ main.pyì—ì„œ importí•˜ì—¬ ì‚¬ìš©ë©ë‹ˆë‹¤.")
    print("ğŸ”‘ OPENAI_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")