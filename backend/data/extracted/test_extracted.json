{
  "file_name": "test",
  "file_path": "C:\\Users\\limjeasung\\Desktop\\클로드코드\\pdflearner\\uploads\\test.pdf",
  "total_pages": 46,
  "metadata": {
    "title": "",
    "author": "",
    "subject": "",
    "creator": "LaTeX with hyperref",
    "producer": "pdfTeX-1.40.24",
    "creation_date": "D:20250714183430-04'00'",
    "modification_date": "D:20250717141645-04'00'"
  },
  "toc": [
    {
      "level": 1,
      "title": "Introduction",
      "page": 3
    },
    {
      "level": 1,
      "title": "AI-Powered Trading Algorithms",
      "page": 10
    },
    {
      "level": 2,
      "title": "Bellman Equation and Q-Function",
      "page": 10
    },
    {
      "level": 2,
      "title": "Q-Learning Algorithm",
      "page": 11
    },
    {
      "level": 2,
      "title": "Experimentation",
      "page": 12
    },
    {
      "level": 1,
      "title": "Model and Laboratory Design",
      "page": 13
    },
    {
      "level": 2,
      "title": "Economic Environment",
      "page": 13
    },
    {
      "level": 2,
      "title": "Theoretical Benchmarks",
      "page": 16
    },
    {
      "level": 2,
      "title": "Two Mechanisms Underlying Collusive Equilibrium",
      "page": 17
    },
    {
      "level": 2,
      "title": "Existence of Collusive Equilibrium",
      "page": 19
    },
    {
      "level": 2,
      "title": "The Impact of Collusive Informed Trading on Market Efficiency",
      "page": 20
    },
    {
      "level": 1,
      "title": "Simulation Experiments on AI Trading Algorithms",
      "page": 21
    },
    {
      "level": 2,
      "title": "Algorithms as Experimental Subjects",
      "page": 22
    },
    {
      "level": 2,
      "title": "Numerical Specifications",
      "page": 24
    },
    {
      "level": 1,
      "title": "AI Trading Equilibrium: Outcomes from Simulation Experiments",
      "page": 26
    },
    {
      "level": 2,
      "title": "Two Distinct Algorithmic Mechanisms behind AI Collusion",
      "page": 26
    },
    {
      "level": 2,
      "title": "Key Findings on AI Collusion",
      "page": 28
    },
    {
      "level": 2,
      "title": "Simulation Experiments in Trading Environments with High ",
      "page": 29
    },
    {
      "level": 2,
      "title": "Simulation Experiments in Trading Environments with Low ",
      "page": 37
    },
    {
      "level": 2,
      "title": "Intuition Behind AI Collusion and Its Underlying Algorithmic Mechanisms",
      "page": 38
    },
    {
      "level": 2,
      "title": "Winners and Losers: The Role of Information-Insensitive Investors",
      "page": 41
    },
    {
      "level": 1,
      "title": "Comparative Statics of AI Equilibrium",
      "page": 42
    },
    {
      "level": 1,
      "title": "Conclusions",
      "page": 44
    }
  ],
  "pages": [
    {
      "page_number": 1,
      "text": "NBER WORKING PAPER SERIES\nAI-POWERED TRADING, ALGORITHMIC COLLUSION, AND PRICE EFFICIENCY\nWinston Wei Dou\nItay Goldstein\nYan Ji\nWorking Paper 34054\nhttp://www.nber.org/papers/w34054\nNATIONAL BUREAU OF ECONOMIC RESEARCH\n1050 Massachusetts Avenue\nCambridge, MA 02138\nJuly 2025\nWe thank Tobias Adrian, Kerry Back, Snehal Banerjee, Hui Chen, Jean-Edouard Colliard,  Will \nCong, Antoine Didisheim, Itamar Drechsler, Maryam Farboodi, Slava Fos, Paolo Fulghieri, Joao \nGomes, Mark Grinblatt, Ming Guo, Wei Jiang, Chris Jones, Scott Joslin, Joe Harrington, Larry \nHarris, Zhiguo He, Harrison Hong, Mariana Khapko, Leonid Kogan, Pete Kyle, Tse-Chun Lin, \nDeborah Lucas, Ye Luo, Semyon Malamud, Andrey Malenko, George Malikov, Albert Menkveld, \nJonathan Parker, Lasse Pedersen, Paul Romer, Nick Roussanov, Tom Sargent, Antoinette Schoar, \nHyun-Song Shin, Rob Stambaugh, Eric Talley, Anton Tsoy, Stijn Van Nieuwerburgh, Dimitri \nVayanos, Laura Veldkamp, Jiang Wang, Neng Wang, Xian Wu, Liyan Yang, Jacob Yunger, David \nZhang, and seminar and conference participants at AsianFA, ASU Sonoran Winter Finance \nConference, BIS, BIS Meeting of Heads of Financial Stability, BI-SHoF Conference, Boston \nCollege, CFTRC, CFEA, CICF, CMU, Columbia, Cubist Systematic Strategies (Point72), CUFE, \nDuke/UNC Asset Pricing Conference, EFA, Fed Board, FINRA, FIRS, Florida International \nUniversity, FMA Asia/Pacific Conference, Frankfurt School of Finance and Management, Fudan, \nGeorge Mason, Harvard University, HKU, HKUST, HK Conference for Fintech and AI, IESE \nBarcelona Workshop on AI in Finance, IMF-WIFPR Conference, Imperial College, Jackson Hole \nFinance Conference, Johns Hopkins Carey Finance Conference, LSE, Melbourne Asset Pricing \nMeeting, MIT, MFA, NBER Summer Institute (Asset Pricing), Nordic Fintech Symposium, NTU \nConference on AI for Finance, NYU/Penn Law and Finance Conference, OECD, Olin Finance \nConference at WashU, OSU, Oxford, PKU, PKU/PHBS Sargent Institute Macro-Finance \nWorkshop, QES Global Quant and Macro Investing Conference, QRFE Workshop on Market \nMicrostructure, Fintech and AI, Renmin University, Rice University, Shanghai Jiao Tong \nUniversity (SAIF & Antai), SFS Cavalcade North America, SHUFE, Toronto Macro/Finance \nConference, Tsinghua (PBCSF & SEM), UCLA, UIC Finance Conference, UIUC, UT Austin, \nUniversity of Houston, University of Macau, University of Mannheim, University of Miami, \nUniversity of Minnesota, University of Toronto, University of Zurich, USC, WashU, Western \nUniversity, WFA, and Wharton for their comments. Dou is grateful for the financial supports \nfrom the Golub Faculty Scholar Award at Wharton. The views expressed herein are those of the \nauthors and do not necessarily reflect the views of the National Bureau of Economic Research.\nNBER working papers are circulated for discussion and comment purposes. They have not been \npeer-reviewed or been subject to the review by the NBER Board of Directors that accompanies \nofficial NBER publications.\n© 2025 by Winston Wei Dou, Itay Goldstein, and Yan Ji. All rights reserved. Short sections of text, \nnot to exceed two paragraphs, may be quoted without explicit permission provided that full credit, \nincluding © notice, is given to the source.\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "NBER WORKING PAPER SERIES",
          "bbox": [
            220.13699340820312,
            28.666973114013672,
            395.14398193359375,
            44.830970764160156
          ],
          "font_info": {
            "font": "TimesNewRomanPSMT",
            "size": 12.0,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "AI-POWERED TRADING, ALGORITHMIC COLLUSION, AND PRICE EFFICIENCY",
          "bbox": [
            91.9949951171875,
            56.66697311401367,
            523.2980346679688,
            72.83097076416016
          ],
          "font_info": {
            "font": "TimesNewRomanPSMT",
            "size": 12.0,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Winston Wei Dou\nItay Goldstein\nYan Ji",
          "bbox": [
            264.4280090332031,
            84.66697692871094,
            350.8310241699219,
            128.8309783935547
          ],
          "font_info": {
            "font": "TimesNewRomanPSMT",
            "size": 12.0,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Working Paper 34054\nhttp://www.nber.org/papers/w34054",
          "bbox": [
            220.32296752929688,
            140.66697692871094,
            394.9709777832031,
            170.8309783935547
          ],
          "font_info": {
            "font": "TimesNewRomanPSMT",
            "size": 12.0,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "NATIONAL BUREAU OF ECONOMIC RESEARCH\n1050 Massachusetts Avenue\nCambridge, MA 02138\nJuly 2025",
          "bbox": [
            175.86297607421875,
            182.66697692871094,
            439.4189758300781,
            240.8309783935547
          ],
          "font_info": {
            "font": "TimesNewRomanPSMT",
            "size": 12.0,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "We thank Tobias Adrian, Kerry Back, Snehal Banerjee, Hui Chen, Jean-Edouard Colliard,  Will \nCong, Antoine Didisheim, Itamar Drechsler, Maryam Farboodi, Slava Fos, Paolo Fulghieri, Joao \nGomes, Mark Grinblatt, Ming Guo, Wei Jiang, Chris Jones, Scott Joslin, Joe Harrington, Larry \nHarris, Zhiguo He, Harrison Hong, Mariana Khapko, Leonid Kogan, Pete Kyle, Tse-Chun Lin, \nDeborah Lucas, Ye Luo, Semyon Malamud, Andrey Malenko, George Malikov, Albert Menkveld, \nJonathan Parker, Lasse Pedersen, Paul Romer, Nick Roussanov, Tom Sargent, Antoinette Schoar, \nHyun-Song Shin, Rob Stambaugh, Eric Talley, Anton Tsoy, Stijn Van Nieuwerburgh, Dimitri \nVayanos, Laura Veldkamp, Jiang Wang, Neng Wang, Xian Wu, Liyan Yang, Jacob Yunger, David \nZhang, and seminar and conference participants at AsianFA, ASU Sonoran Winter Finance \nConference, BIS, BIS Meeting of Heads of Financial Stability, BI-SHoF Conference, Boston \nCollege, CFTRC, CFEA, CICF, CMU, Columbia, Cubist Systematic Strategies (Point72), CUFE, \nDuke/UNC Asset Pricing Conference, EFA, Fed Board, FINRA, FIRS, Florida International \nUniversity, FMA Asia/Pacific Conference, Frankfurt School of Finance and Management, Fudan, \nGeorge Mason, Harvard University, HKU, HKUST, HK Conference for Fintech and AI, IESE \nBarcelona Workshop on AI in Finance, IMF-WIFPR Conference, Imperial College, Jackson Hole \nFinance Conference, Johns Hopkins Carey Finance Conference, LSE, Melbourne Asset Pricing \nMeeting, MIT, MFA, NBER Summer Institute (Asset Pricing), Nordic Fintech Symposium, NTU \nConference on AI for Finance, NYU/Penn Law and Finance Conference, OECD, Olin Finance \nConference at WashU, OSU, Oxford, PKU, PKU/PHBS Sargent Institute Macro-Finance \nWorkshop, QES Global Quant and Macro Investing Conference, QRFE Workshop on Market \nMicrostructure, Fintech and AI, Renmin University, Rice University, Shanghai Jiao Tong \nUniversity (SAIF & Antai), SFS Cavalcade North America, SHUFE, Toronto Macro/Finance \nConference, Tsinghua (PBCSF & SEM), UCLA, UIC Finance Conference, UIUC, UT Austin, \nUniversity of Houston, University of Macau, University of Mannheim, University of Miami, \nUniversity of Minnesota, University of Toronto, University of Zurich, USC, WashU, Western \nUniversity, WFA, and Wharton for their comments. Dou is grateful for the financial supports \nfrom the Golub Faculty Scholar Award at Wharton. The views expressed herein are those of the \nauthors and do not necessarily reflect the views of the National Bureau of Economic Research.",
          "bbox": [
            72.26194763183594,
            252.66697692871094,
            546.0349731445312,
            646.8309936523438
          ],
          "font_info": {
            "font": "TimesNewRomanPSMT",
            "size": 12.0,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "NBER working papers are circulated for discussion and comment purposes. They have not been \npeer-reviewed or been subject to the review by the NBER Board of Directors that accompanies \nofficial NBER publications.",
          "bbox": [
            72.26199340820312,
            658.510986328125,
            546.0330200195312,
            702.8309936523438
          ],
          "font_info": {
            "font": "Times-Roman",
            "size": 12.0,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "© 2025 by Winston Wei Dou, Itay Goldstein, and Yan Ji. All rights reserved. Short sections of text, \nnot to exceed two paragraphs, may be quoted without explicit permission provided that full credit, \nincluding © notice, is given to the source.",
          "bbox": [
            72.261962890625,
            714.510986328125,
            546.02197265625,
            758.5189819335938
          ],
          "font_info": {
            "font": "Times-Roman",
            "size": 12.0,
            "color": 0,
            "flags": 4
          }
        }
      ]
    },
    {
      "page_number": 2,
      "text": "AI-Powered Trading, Algorithmic Collusion, and Price Efficiency\nWinston Wei Dou, Itay Goldstein, and Yan Ji\nNBER Working Paper No. 34054\nJuly 2025\nJEL No. D43, G10, G14, L13\nABSTRACT\nThe integration of algorithmic trading with reinforcement learning, termed AI-powered trading, is \ntransforming financial markets. Alongside the benefits, it raises concerns for collusion. This study \nfirst develops a model to explore the possibility of collusion among informed speculators in a \ntheoretical environment. We then conduct simulation experiments, replacing the speculators in the \nmodel with informed AI speculators who trade based on reinforcement-learning algorithms. We \nshow that they autonomously sustain collusive supra-competitive profits without agreement, \ncommunication, or intent. Such collusion undermines competition and market efficiency. We \ndemonstrate that two separate mechanisms are underlying this collusion and characterize when \neach one arises.\nWinston Wei Dou\nUniversity of Pennsylvania\nThe Wharton School\nand NBER\nwdou@wharton.upenn.edu\nItay Goldstein\nUniversity of Pennsylvania\nThe Wharton School\nand NBER\nitayg@wharton.upenn.edu\nYan Ji\nHong Kong University of Science\nand Technology (HKUST) \njiy@ust.hk\nA data appendix is available at http://www.nber.org/data-appendix/w34054\nA SSRN Link is available at https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4452704\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "AI-Powered Trading, Algorithmic Collusion, and Price Efficiency\nWinston Wei Dou, Itay Goldstein, and Yan Ji\nNBER Working Paper No. 34054\nJuly 2025\nJEL No. D43, G10, G14, L13",
          "bbox": [
            72.0,
            79.36399841308594,
            389.9520263671875,
            151.3719940185547
          ],
          "font_info": {
            "font": "Times-Roman",
            "size": 12.0,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "ABSTRACT",
          "bbox": [
            273.33001708984375,
            163.4720001220703,
            338.6700134277344,
            180.0919952392578
          ],
          "font_info": {
            "font": "Times-Bold",
            "size": 12.0,
            "color": 0,
            "flags": 20
          }
        },
        {
          "text": "The integration of algorithmic trading with reinforcement learning, termed AI-powered trading, is \ntransforming financial markets. Alongside the benefits, it raises concerns for collusion. This study \nfirst develops a model to explore the possibility of collusion among informed speculators in a \ntheoretical environment. We then conduct simulation experiments, replacing the speculators in the \nmodel with informed AI speculators who trade based on reinforcement-learning algorithms. We \nshow that they autonomously sustain collusive supra-competitive profits without agreement, \ncommunication, or intent. Such collusion undermines competition and market efficiency. We \ndemonstrate that two separate mechanisms are underlying this collusion and characterize when \neach one arises.",
          "bbox": [
            71.99998474121094,
            191.36399841308594,
            546.0109252929688,
            319.37200927734375
          ],
          "font_info": {
            "font": "Times-Roman",
            "size": 12.0,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Winston Wei Dou\nUniversity of Pennsylvania\nThe Wharton School\nand NBER\nwdou@wharton.upenn.edu",
          "bbox": [
            72.0,
            331.364013671875,
            202.656005859375,
            403.37200927734375
          ],
          "font_info": {
            "font": "Times-Roman",
            "size": 12.0,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Itay Goldstein\nUniversity of Pennsylvania\nThe Wharton School\nand NBER\nitayg@wharton.upenn.edu",
          "bbox": [
            72.0,
            415.364013671875,
            202.656005859375,
            487.37200927734375
          ],
          "font_info": {
            "font": "Times-Roman",
            "size": 12.0,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Yan Ji\nHong Kong University of Science\nand Technology (HKUST) \njiy@ust.hk",
          "bbox": [
            306.0,
            331.364013671875,
            469.3080139160156,
            389.37200927734375
          ],
          "font_info": {
            "font": "Times-Roman",
            "size": 12.0,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "A data appendix is available at http://www.nber.org/data-appendix/w34054\nA SSRN Link is available at https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4452704",
          "bbox": [
            72.0,
            679.364013671875,
            508.4040222167969,
            709.3720092773438
          ],
          "font_info": {
            "font": "Times-Roman",
            "size": 12.0,
            "color": 0,
            "flags": 4
          }
        }
      ]
    },
    {
      "page_number": 3,
      "text": "1\nIntroduction\nThe integration of algorithmic trading with reinforcement learning (RL) algorithms, often termed AI-\npowered trading, has the potential to reshape financial markets and poses new regulatory challenges.\nWhile traditional algorithmic trading relies on static, hardcoded rules defined by humans, RL-based\ntrading algorithms autonomously optimize their strategies through self-learning, trial-and-error\ninteractions with the market and adapt in real time based on observed outcomes. Such adoption of AI\nalgorithms in trade execution has recently gained significant momentum and its future progression\nseems unavoidable.1\nOne of the most pressing regulatory concerns related to the adoption of AI is the risk of AI\ncollusion. As we discuss in the literature review below, AI collusion has been a concern in areas\noutside financial markets and it poses particular risks in financial markets. We define AI collusion as\na scenario where autonomous, self-interested RL algorithms independently learn to coordinate their\ntrading in a way that secures supra-competitive profits, without explicit agreements, communication,\nor pre-programmed intent. Such algorithmic collusion could benefit a small group of sophisticated\nspeculators equipped with advanced technologies, while harming broader market participants by\nundermining competition, liquidity, and market efficiency.\nWhat makes AI collusion particularly challenging to regulators is that it falls outside the scope\nof existing antitrust enforcement frameworks,2 which focus on detecting explicit communication or\nevidence of shared intent (e.g., Harrington, 2018; Massarotto, 2025). This focus reflects the prevailing\nview that communication is important for humans to sustain collusion.3 As a result, AI collusion,\ndespite yielding similar anti-competitive outcomes, remains largely unaddressed under current\nlaw. This legal gap is particularly salient in financial markets, where the boundary between illegal\ncommunication used for manipulation and lawful communication necessary for enhancing market\nefficiency and stability is inherently difficult to define and detect. But before evaluating these issues,\nwe need a better understanding of whether AI collusion in securities trading can arise in the first\nplace, given the unique nature and structure of the financial market, and if so, then how it is affected\nby the parameters of the market.\nIn this article, we show that AI collusion in securities trading can robustly arise. Our analysis\nstarts with a model to analyze the possibilities of collusion in equilibrium without considering AI\nagents. We then conduct simulation experiments with RL algorithms trading in an environment\nsimilar to the model and explore the patterns of collusion they achieve. We show that there are two\nfundamentally distinct algorithmic mechanisms through which collusion is achieved across a range\nof market environments: one based on price-trigger strategies, and the other driven by over-pruning\nbias in learning. We systematically characterize the conditions under which each mechanism prevails.\nBoth algorithmic mechanisms underlying AI collusion have counterparts in economic theory and can\n1For example, the Securities and Exchange Commission (SEC) recently approved Nasdaq’s RL-based, AI-driven order\ntype; major digital platforms have begun deploying RL trading bots; and leading hedge funds and trading powerhouses\nare increasingly adopting AI for trading.\n2While securities trading is primarily governed by securities laws, Section 1 of the Sherman Act applies to collusive\npractices that suppress competition in financial markets. Overlap arises when manipulative conduct has anti-competitive\neffects, triggering dual enforcement by the Department of Justice (DOJ) and SEC.\n3This is rooted in historical case studies and experimental research on human tacit collusion (e.g., Levine, Palfrey and\nPlott, 1991; Genesove and Mullin, 2001; Fonseca and Normann, 2012; Charness et al., 2014; Cooper and Kühn, 2014).\n1\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "1\nIntroduction",
          "bbox": [
            64.08000183105469,
            49.489784240722656,
            168.47731018066406,
            63.83598709106445
          ],
          "font_info": {
            "font": "URWPalladioL-Bold",
            "size": 14.346199989318848,
            "color": 0,
            "flags": 20
          }
        },
        {
          "text": "The integration of algorithmic trading with reinforcement learning (RL) algorithms, often termed AI-",
          "bbox": [
            63.742000579833984,
            80.3485107421875,
            549.7342529296875,
            91.18647003173828
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.837958335876465,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "powered trading, has the potential to reshape financial markets and poses new regulatory challenges.",
          "bbox": [
            63.75299835205078,
            96.7993392944336,
            549.8341674804688,
            107.61531066894531
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.815974235534668,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "While traditional algorithmic trading relies on static, hardcoded rules defined by humans, RL-based\ntrading algorithms autonomously optimize their strategies through self-learning, trial-and-error",
          "bbox": [
            63.534000396728516,
            113.1871337890625,
            548.1387329101562,
            140.5433349609375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.881793022155762,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "interactions with the market and adapt in real time based on observed outcomes. Such adoption of AI",
          "bbox": [
            64.08000183105469,
            146.11715698242188,
            547.9187622070312,
            156.91661071777344
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "algorithms in trade execution has recently gained significant momentum and its future progression",
          "bbox": [
            64.08000183105469,
            162.4656982421875,
            547.9152221679688,
            173.38571166992188
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.920002937316895,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "seems unavoidable.1",
          "bbox": [
            64.08000183105469,
            177.0561981201172,
            162.7010498046875,
            189.81761169433594
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "One of the most pressing regulatory concerns related to the adoption of AI is the risk of AI\ncollusion. As we discuss in the literature review below, AI collusion has been a concern in areas",
          "bbox": [
            64.08000183105469,
            195.2656707763672,
            547.916748046875,
            222.71832275390625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "outside financial markets and it poses particular risks in financial markets. We define AI collusion as",
          "bbox": [
            64.08000183105469,
            228.2724151611328,
            547.916015625,
            239.09938049316406
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.826972007751465,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "a scenario where autonomous, self-interested RL algorithms independently learn to coordinate their",
          "bbox": [
            64.08000183105469,
            244.67201232910156,
            548.1400146484375,
            255.54833984375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.876322746276855,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "trading in a way that secures supra-competitive profits, without explicit agreements, communication,",
          "bbox": [
            64.08000183105469,
            261.1394958496094,
            549.289306640625,
            271.9719543457031
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.832467079162598,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "or pre-programmed intent. Such algorithmic collusion could benefit a small group of sophisticated\nspeculators equipped with advanced technologies, while harming broader market participants by",
          "bbox": [
            64.08000183105469,
            277.4921875,
            548.3502807617188,
            304.89434814453125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.94721508026123,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "undermining competition, liquidity, and market efficiency.\nWhat makes AI collusion particularly challenging to regulators is that it falls outside the scope",
          "bbox": [
            64.08000183105469,
            310.3895263671875,
            547.9249877929688,
            337.7551574707031
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "of existing antitrust enforcement frameworks,2 which focus on detecting explicit communication or",
          "bbox": [
            64.08000183105469,
            339.28387451171875,
            548.13671875,
            354.1748046875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.930895805358887,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "evidence of shared intent (e.g., Harrington, 2018; Massarotto, 2025). This focus reflects the prevailing\nview that communication is important for humans to sustain collusion.3 As a result, AI collusion,\ndespite yielding similar anti-competitive outcomes, remains largely unaddressed under current\nlaw. This legal gap is particularly salient in financial markets, where the boundary between illegal\ncommunication used for manipulation and lawful communication necessary for enhancing market",
          "bbox": [
            63.775001525878906,
            359.74554443359375,
            549.2783813476562,
            436.3600158691406
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.837958335876465,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "efficiency and stability is inherently difficult to define and detect. But before evaluating these issues,\nwe need a better understanding of whether AI collusion in securities trading can arise in the first",
          "bbox": [
            63.62200164794922,
            441.89404296875,
            549.27880859375,
            469.2453308105469
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.876322746276855,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "place, given the unique nature and structure of the financial market, and if so, then how it is affected",
          "bbox": [
            63.75299835205078,
            474.8033447265625,
            547.9239501953125,
            485.6248474121094
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.8214750289917,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "by the parameters of the market.\nIn this article, we show that AI collusion in securities trading can robustly arise. Our analysis\nstarts with a model to analyze the possibilities of collusion in equilibrium without considering AI\nagents. We then conduct simulation experiments with RL algorithms trading in an environment",
          "bbox": [
            64.08000183105469,
            491.1755065917969,
            547.91650390625,
            551.4213256835938
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "similar to the model and explore the patterns of collusion they achieve. We show that there are two",
          "bbox": [
            64.08000183105469,
            556.91259765625,
            547.9239501953125,
            567.8271484375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.91455364227295,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "fundamentally distinct algorithmic mechanisms through which collusion is achieved across a range",
          "bbox": [
            64.08000183105469,
            573.3475952148438,
            547.9240112304688,
            584.2621459960938
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.91455364227295,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "of market environments: one based on price-trigger strategies, and the other driven by over-pruning",
          "bbox": [
            64.08000183105469,
            589.8257446289062,
            547.92041015625,
            600.6801147460938
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.854416847229004,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "bias in learning. We systematically characterize the conditions under which each mechanism prevails.",
          "bbox": [
            64.08000183105469,
            606.3001098632812,
            549.83251953125,
            617.099609375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Both algorithmic mechanisms underlying AI collusion have counterparts in economic theory and can",
          "bbox": [
            64.08000183105469,
            622.7322387695312,
            547.92041015625,
            633.5371704101562
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.80496597290039,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "1For example, the Securities and Exchange Commission (SEC) recently approved Nasdaq’s RL-based, AI-driven order\ntype; major digital platforms have begun deploying RL trading bots; and leading hedge funds and trading powerhouses\nare increasingly adopting AI for trading.\n2While securities trading is primarily governed by securities laws, Section 1 of the Sherman Act applies to collusive\npractices that suppress competition in financial markets. Overlap arises when manipulative conduct has anti-competitive\neffects, triggering dual enforcement by the Department of Justice (DOJ) and SEC.\n3This is rooted in historical case studies and experimental research on human tacit collusion (e.g., Levine, Palfrey and\nPlott, 1991; Genesove and Mullin, 2001; Fonseca and Normann, 2012; Charness et al., 2014; Cooper and Kühn, 2014).",
          "bbox": [
            63.81100082397461,
            643.3617553710938,
            548.09619140625,
            731.6991577148438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 6.973800182342529,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "1",
          "bbox": [
            303.27301025390625,
            765.1044921875,
            308.7275695800781,
            776.0136108398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        }
      ]
    },
    {
      "page_number": 4,
      "text": "be interpreted through game-theoretic equilibrium concepts. We analyze the resulting AI collusive\nequilibrium using extensive simulations and provide heuristic justification for how these algorithmic\nmechanisms operate.\nTheoretical Benchmarks.\nWe start by developing a model that incorporates key ingredients of\ntrading in financial markets. We provide theoretical analysis of this model as benchmark, and then\nuse it as basis for our simulation experiments with RL algorithms. Our model builds on the influential\nframework of Kyle (1985), in which an informed speculator trades against noise traders, and a market\nmaker sets prices to minimize pricing errors based on the information gleaned from the total order\nflow. We start from the static framework of Kyle (1985) and extend it in the following ways that are\ncritical for the exploration of collusion in trading.\nFirst, instead of a single informed speculator operating in a one-period market, we consider\noligopolistic informed speculators who trade repeatedly across periods, with each period involving\na different short-lived asset.4 At the beginning of each period, each informed speculator receives a\nprivate signal about the fundamental value of that period’s short-lived asset, which is realized at\nthe end of the period. Clearly, the introduction of multiple oligopolistic speculators who interact\nrepeatedly reflects realistic market settings, such as quantitative hedge funds and proprietary trading\nfirms engaged in trading that happens at increasingly higher frequencies. These features are essential\nfor studying how collusion may arise in financial markets.\nSecond, we introduce a continuum of atomistic, information-insensitive investors who trade\nthe asset and collectively generate a downward-sloping demand curve within each trading period\n(similar to Kyle and Xiong, 2001; Vayanos and Vila, 2021). These investors, such as retail traders\nusing technical analysis or institutional investors seeking hold-to-maturity positions for hedging\nshort-term risks, are typically unresponsive to real-time information about the asset’s fundamental\nvalue. Instead, they trade against the current price and in the direction of the asset’s expected\nlong-term value. While we do not endogenize the behavior of these information-insensitive investors,\nthey need not be behaviorally biased. They may find it optimal not to pay attention to short-term\nfluctuations or may behave this way for institutional reasons. As discussed above, these traders\nresemble different types of investors in real-world markets. This feature, together with the next one,\ninjects inefficiency into the pricing mechanism of Kyle (1985), which as we show, is a critical element\nfor a key mechanism for collusion.\nThird, trading occurs through the market maker who sets the market price and holds inventory\nto clear the market. The market maker observes the total order flow from informed speculators and\nnoise traders, along with the deterministic order flow schedule of information-insensitive investors\nas a function of price. Given this information, the market maker sets the market price optimally to\nminimize a weighted average of inventory costs and pricing errors. Hence, unlike in Kyle (1985),\ninventory costs play a role in the pricing mechanism, which is a realistic feature of financial markets.\nHaving the information-insensitive traders alongside this concern for inventory costs is what injects\ninefficiency to the price, which will be important for the analysis of collusion.\nWe analyze the theoretical model and generate some novel results about the possibility of collusion\n4Our repeated trading setup is distinct from dynamic trading frameworks with a long-lived asset traded over multiple\nrounds within each period (e.g., Kyle, 1985; Holden and Subrahmanyam, 1992; Rostek and Weretka, 2015).\n2\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "be interpreted through game-theoretic equilibrium concepts. We analyze the resulting AI collusive",
          "bbox": [
            64.08000183105469,
            52.05553436279297,
            547.9219970703125,
            63.01904296875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.963509559631348,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "equilibrium using extensive simulations and provide heuristic justification for how these algorithmic",
          "bbox": [
            64.08000183105469,
            68.58154296875,
            547.918701171875,
            79.41950225830078
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.837958335876465,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "mechanisms operate.",
          "bbox": [
            64.08000183105469,
            84.96552276611328,
            166.17828369140625,
            95.87462615966797
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Theoretical Benchmarks.\nWe start by developing a model that incorporates key ingredients of",
          "bbox": [
            64.08000183105469,
            117.70072174072266,
            547.9194946289062,
            128.96832275390625
          ],
          "font_info": {
            "font": "URWPalladioL-BoldItal",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 22
          }
        },
        {
          "text": "trading in financial markets. We provide theoretical analysis of this model as benchmark, and then",
          "bbox": [
            64.08000183105469,
            134.43617248535156,
            547.9240112304688,
            145.38339233398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.94721508026123,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "use it as basis for our simulation experiments with RL algorithms. Our model builds on the influential",
          "bbox": [
            64.08000183105469,
            150.97714233398438,
            547.9189453125,
            161.77659606933594
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "framework of Kyle (1985), in which an informed speculator trades against noise traders, and a market",
          "bbox": [
            64.08000183105469,
            167.41213989257812,
            547.9188842773438,
            178.2115936279297
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "maker sets prices to minimize pricing errors based on the information gleaned from the total order",
          "bbox": [
            64.08000183105469,
            183.7450714111328,
            548.134521484375,
            194.6868438720703
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.941778182983398,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "flow. We start from the static framework of Kyle (1985) and extend it in the following ways that are",
          "bbox": [
            64.08000183105469,
            200.19281005859375,
            547.9168090820312,
            211.11827087402344
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.925451278686523,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "critical for the exploration of collusion in trading.\nFirst, instead of a single informed speculator operating in a one-period market, we consider",
          "bbox": [
            64.08000183105469,
            216.63954162597656,
            548.1390991210938,
            244.01434326171875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "oligopolistic informed speculators who trade repeatedly across periods, with each period involving\na different short-lived asset.4 At the beginning of each period, each informed speculator receives a\nprivate signal about the fundamental value of that period’s short-lived asset, which is realized at\nthe end of the period. Clearly, the introduction of multiple oligopolistic speculators who interact",
          "bbox": [
            63.75299835205078,
            249.505615234375,
            547.9247436523438,
            309.75433349609375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.91455364227295,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "repeatedly reflects realistic market settings, such as quantitative hedge funds and proprietary trading",
          "bbox": [
            64.08000183105469,
            315.32916259765625,
            547.9188232421875,
            326.12860107421875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "firms engaged in trading that happens at increasingly higher frequencies. These features are essential",
          "bbox": [
            64.08000183105469,
            331.76416015625,
            547.9188842773438,
            342.5635986328125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "for studying how collusion may arise in financial markets.\nSecond, we introduce a continuum of atomistic, information-insensitive investors who trade\nthe asset and collectively generate a downward-sloping demand curve within each trading period\n(similar to Kyle and Xiong, 2001; Vayanos and Vila, 2021). These investors, such as retail traders\nusing technical analysis or institutional investors seeking hold-to-maturity positions for hedging\nshort-term risks, are typically unresponsive to real-time information about the asset’s fundamental\nvalue. Instead, they trade against the current price and in the direction of the asset’s expected",
          "bbox": [
            63.720001220703125,
            348.1205139160156,
            547.9246215820312,
            457.67132568359375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "long-term value. While we do not endogenize the behavior of these information-insensitive investors,\nthey need not be behaviorally biased. They may find it optimal not to pay attention to short-term\nfluctuations or may behave this way for institutional reasons. As discussed above, these traders",
          "bbox": [
            64.08000183105469,
            463.23724365234375,
            549.2810668945312,
            506.976318359375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.810471534729004,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "resemble different types of investors in real-world markets. This feature, together with the next one,",
          "bbox": [
            64.08000183105469,
            512.4872436523438,
            549.288330078125,
            523.37451171875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.887259483337402,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "injects inefficiency into the pricing mechanism of Kyle (1985), which as we show, is a critical element",
          "bbox": [
            64.08000183105469,
            528.95751953125,
            547.9187622070312,
            539.7954711914062
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.837958335876465,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "for a key mechanism for collusion.",
          "bbox": [
            64.08000183105469,
            545.3414916992188,
            232.24375915527344,
            556.2506103515625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Third, trading occurs through the market maker who sets the market price and holds inventory",
          "bbox": [
            81.01599884033203,
            561.7579956054688,
            548.34130859375,
            572.6943359375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.936338424682617,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "to clear the market. The market maker observes the total order flow from informed speculators and",
          "bbox": [
            64.08000183105469,
            578.2203369140625,
            547.9215698242188,
            589.1185302734375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.898184776306152,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "noise traders, along with the deterministic order flow schedule of information-insensitive investors\nas a function of price. Given this information, the market maker sets the market price optimally to\nminimize a weighted average of inventory costs and pricing errors. Hence, unlike in Kyle (1985),",
          "bbox": [
            64.08000183105469,
            594.6240844726562,
            549.2850341796875,
            638.4573364257812
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.941778182983398,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "inventory costs play a role in the pricing mechanism, which is a realistic feature of financial markets.",
          "bbox": [
            64.08000183105469,
            643.9917602539062,
            549.8319702148438,
            654.8461303710938
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.854416847229004,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Having the information-insensitive traders alongside this concern for inventory costs is what injects",
          "bbox": [
            64.08000183105469,
            660.3992919921875,
            547.91552734375,
            671.2919921875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.89272403717041,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "inefficiency to the price, which will be important for the analysis of collusion.",
          "bbox": [
            64.08000183105469,
            676.822509765625,
            441.283935546875,
            687.7316284179688
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "We analyze the theoretical model and generate some novel results about the possibility of collusion",
          "bbox": [
            81.01599884033203,
            693.337158203125,
            547.9203491210938,
            704.1366577148438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "4Our repeated trading setup is distinct from dynamic trading frameworks with a long-lived asset traded over multiple\nrounds within each period (e.g., Kyle, 1985; Holden and Subrahmanyam, 1992; Rostek and Weretka, 2015).",
          "bbox": [
            64.08000183105469,
            713.9627075195312,
            547.9200439453125,
            735.714111328125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 6.973800182342529,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "2",
          "bbox": [
            303.27301025390625,
            765.1044921875,
            308.7275695800781,
            776.0136108398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        }
      ]
    },
    {
      "page_number": 5,
      "text": "in financial market trading. We first consider two theoretical benchmarks to characterize the steady-\nstate behavior of informed speculators: the non-collusive Nash equilibrium benchmark and the perfect\ncartel benchmark. The non-collusive Nash equilibrium refers to the one-shot Nash equilibrium of the\nstage game, in which no one can profitably deviate. Here, every speculator is trading to maximize\ncurrent trading profit, not taking into account the effect on the profit of others. In contrast, the\nperfect cartel represents the outcome in which informed speculators act collectively as a monopolist\nto maximize joint profits. Relative to the non-collusive Nash equilibrium, informed speculators in the\ncartel trade less aggressively on the information about asset, as this enables them to make higher\ncollective profits. A collusive equilibrium, if it arises, would lie between these two benchmarks. We\ndefine such an equilibrium by two features: (i) informed speculators earn supra-competitive profits\nthat exceed those obtained in the non-collusive Nash equilibrium by trading less aggressively on\nsignals; and (ii) each speculator has the option to deviate for unilateral one-period gains, with such\ndeviations imposing losses on others.\nA collusive trading equilibrium can be sustained as a subgame perfect Nash equilibrium in our\nframework as a result of price-trigger strategies. When market prices are sufficiently informative,\nspeculators can imperfectly infer others’ trades from market price movements, enabling tacit coordi-\nnation. Specifically, speculators trade less aggressively on their information, knowing that a deviation\nto a more aggressive strategy is likely to lead to the price shooting over the trigger, which will lead\nthe other speculators to punish them by reverting to the aggressive strategy in the non-collusive\nNash equilibrium. This form of collusion was introduced by Green and Porter (1984) and Abreu,\nPearce and Stacchetti (1986). Importantly, the viability of this equilibrium hinges critically on high\nprice informativeness, which is a central concept in the context of financial markets. We show that\nsustaining a collusive Nash equilibrium via price-trigger strategies becomes impossible when noise\ntrading risk is high or when information-insensitive investors are only weakly present. Intuitively,\nhigh noise trading risk leads to low price informativeness, weakening the effectiveness of prices\nas monitoring devices. Moreover, when the information-insensitive investors are not prominent,\nspeculators must trade conservatively on private signals to preserve information rents, reducing price\ninformativeness and rendering prices ineffective for detecting deviations, regardless of the level of\nnoise trading risk. This characterization of when price-trigger collusive equilibria are possible is\nnovel in the literature on financial-market trading.\nOther possibilities of collusive equilibria arise outside the concept of a Nash equilibrium. Specifi-\ncally, following the concept of experience-based equilibrium (Fershtman and Pakes, 2012), informed\nspeculators may trade less aggressively on their private signals because of a learning bias that leads\nthem to undervalue the payoff from aggressive trading. The bias persists because learning is based\nsolely on realized outcomes along the equilibrium path, while off-path strategies are insufficiently\nrevisited or updated. As a result, the learning process reinforces outcome evaluations that are\ninternally consistent with observed on-path data but fails to correct for underexplored off-path\nstrategies. We show that such equilibria exist for the entire parameter space, not depending on how\nprominent noise traders or information-insensitive traders are.\nAlgorithmic Mechanisms That Lead to AI Collusion.\nIn the main part of the paper, we examine\nwhether informed speculators, each governed by an independent and self-interested AI algorithm,\n3\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "in financial market trading. We first consider two theoretical benchmarks to characterize the steady-",
          "bbox": [
            64.08000183105469,
            52.10629653930664,
            549.7316284179688,
            62.999019622802734
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.89272403717041,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "state behavior of informed speculators: the non-collusive Nash equilibrium benchmark and the perfect",
          "bbox": [
            64.08000183105469,
            68.60916137695312,
            547.9188842773438,
            79.40861511230469
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "cartel benchmark. The non-collusive Nash equilibrium refers to the one-shot Nash equilibrium of the\nstage game, in which no one can profitably deviate. Here, every speculator is trading to maximize\ncurrent trading profit, not taking into account the effect on the profit of others. In contrast, the",
          "bbox": [
            64.08000183105469,
            85.04020690917969,
            547.9254760742188,
            128.77532958984375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.80496597290039,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "perfect cartel represents the outcome in which informed speculators act collectively as a monopolist",
          "bbox": [
            63.75299835205078,
            134.2861785888672,
            547.9183349609375,
            145.17344665527344
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.887259483337402,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "to maximize joint profits. Relative to the non-collusive Nash equilibrium, informed speculators in the\ncartel trade less aggressively on the information about asset, as this enables them to make higher",
          "bbox": [
            64.08000183105469,
            150.78414916992188,
            548.1387939453125,
            178.080322265625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "collective profits. A collusive equilibrium, if it arises, would lie between these two benchmarks. We",
          "bbox": [
            64.08000183105469,
            183.56378173828125,
            547.9169311523438,
            194.48924255371094
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.925451278686523,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "define such an equilibrium by two features: (i) informed speculators earn supra-competitive profits\nthat exceed those obtained in the non-collusive Nash equilibrium by trading less aggressively on",
          "bbox": [
            64.08000183105469,
            200.00372314453125,
            547.916259765625,
            227.3863525390625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.920002937316895,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "signals; and (ii) each speculator has the option to deviate for unilateral one-period gains, with such",
          "bbox": [
            64.08000183105469,
            232.86981201171875,
            547.9168701171875,
            243.79527282714844
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.925451278686523,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "deviations imposing losses on others.",
          "bbox": [
            64.08000183105469,
            249.31654357910156,
            245.81468200683594,
            260.22564697265625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "A collusive trading equilibrium can be sustained as a subgame perfect Nash equilibrium in our\nframework as a result of price-trigger strategies. When market prices are sufficiently informative,",
          "bbox": [
            64.08000183105469,
            265.7203063964844,
            549.284912109375,
            293.1263427734375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.952649116516113,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "speculators can imperfectly infer others’ trades from market price movements, enabling tacit coordi-",
          "bbox": [
            64.08000183105469,
            298.63720703125,
            549.7339477539062,
            309.5244445800781
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.887259483337402,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "nation. Specifically, speculators trade less aggressively on their information, knowing that a deviation",
          "bbox": [
            64.08000183105469,
            315.13616943359375,
            547.9188232421875,
            325.93560791015625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "to a more aggressive strategy is likely to lead to the price shooting over the trigger, which will lead\nthe other speculators to punish them by reverting to the aggressive strategy in the non-collusive\nNash equilibrium. This form of collusion was introduced by Green and Porter (1984) and Abreu,\nPearce and Stacchetti (1986). Importantly, the viability of this equilibrium hinges critically on high\nprice informativeness, which is a central concept in the context of financial markets. We show that",
          "bbox": [
            63.75299835205078,
            331.4729919433594,
            549.2848510742188,
            408.1646728515625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.936338424682617,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "sustaining a collusive Nash equilibrium via price-trigger strategies becomes impossible when noise\ntrading risk is high or when information-insensitive investors are only weakly present. Intuitively,\nhigh noise trading risk leads to low price informativeness, weakening the effectiveness of prices\nas monitoring devices. Moreover, when the information-insensitive investors are not prominent,",
          "bbox": [
            64.08000183105469,
            413.6557922363281,
            549.2874755859375,
            473.913330078125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.925451278686523,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "speculators must trade conservatively on private signals to preserve information rents, reducing price\ninformativeness and rendering prices ineffective for detecting deviations, regardless of the level of\nnoise trading risk. This characterization of when price-trigger collusive equilibria are possible is",
          "bbox": [
            64.08000183105469,
            479.4871520996094,
            547.9254150390625,
            523.2183227539062
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "novel in the literature on financial-market trading.",
          "bbox": [
            64.08000183105469,
            528.7135009765625,
            308.29107666015625,
            539.6226196289062
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Other possibilities of collusive equilibria arise outside the concept of a Nash equilibrium. Specifi-",
          "bbox": [
            81.01599884033203,
            545.1837768554688,
            549.7342529296875,
            556.043701171875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.85989761352539,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "cally, following the concept of experience-based equilibrium (Fershtman and Pakes, 2012), informed",
          "bbox": [
            64.08000183105469,
            561.6002197265625,
            547.9193115234375,
            572.4874877929688
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.887259483337402,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "speculators may trade less aggressively on their private signals because of a learning bias that leads",
          "bbox": [
            64.08000183105469,
            578.02734375,
            547.9217529296875,
            588.925537109375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.898184776306152,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "them to undervalue the payoff from aggressive trading. The bias persists because learning is based\nsolely on realized outcomes along the equilibrium path, while off-path strategies are insufficiently\nrevisited or updated. As a result, the learning process reinforces outcome evaluations that are\ninternally consistent with observed on-path data but fails to correct for underexplored off-path",
          "bbox": [
            64.08000183105469,
            594.4271850585938,
            548.3468017578125,
            654.6993408203125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.94721508026123,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "strategies. We show that such equilibria exist for the entire parameter space, not depending on how",
          "bbox": [
            64.08000183105469,
            660.2023315429688,
            548.3790283203125,
            671.1005249023438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.898184776306152,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "prominent noise traders or information-insensitive traders are.",
          "bbox": [
            63.75299835205078,
            676.6295166015625,
            367.90966796875,
            687.5386352539062
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Algorithmic Mechanisms That Lead to AI Collusion.\nIn the main part of the paper, we examine\nwhether informed speculators, each governed by an independent and self-interested AI algorithm,",
          "bbox": [
            63.62200164794922,
            709.36572265625,
            549.2833862304688,
            737.0607299804688
          ],
          "font_info": {
            "font": "URWPalladioL-BoldItal",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 22
          }
        },
        {
          "text": "3",
          "bbox": [
            303.27301025390625,
            765.1044921875,
            308.7275695800781,
            776.0136108398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        }
      ]
    },
    {
      "page_number": 6,
      "text": "can reach the collusive outcomes described above without explicit agreements, communication, or\npre-programmed intent. To do so, we run simulation experiments using autonomous, model-free\nQ-learning algorithms that replace the informed speculators in the theoretical framework. Unlike\ntheir theoretical counterparts, these algorithms rely on RL to determine how to trade on private\nsignals, rather than on rationality or strategic foresight. Q-learning serves as a foundational basis\nfor many RL algorithms that have significantly advanced the AI field. It is valued for its simplicity,\ntransparency, and economic interpretability.\nWe provide additional details about the algorithms in Section 2. As described there, in each\nperiod, an algorithm selects an action (i.e., quantity traded) based on the state it faces (more on the\nstate variables below). It stores and updates estimated values for each state-action pair, including both\noptimal and suboptimal actions. These values are referred to as estimated Q-values, and together\nthey form the estimated Q-matrix over the discrete state and action space. At the start of each\nperiod, the algorithm observes the realized state and uses it to update one cell in the Q-matrix\ncorresponding to the state-action pair from the previous period. The realized state may depend\non both the prior state and action. The update is a weighted average of past experience and new\ninformation, incorporating both the reward just received and the estimated continuation value based\non the newly realized state. At the end of each period, the algorithm selects an action according to a\nstandard exploration-exploitation rule. Exploitation involves choosing the action with the highest\nestimated Q-value for the current state, while exploration involves selecting a random action. The\ninterplay between exploration and exploitation is a defining feature of RL algorithms and is critical\nfor effective learning. Typically, the likelihood of exploration gradually declines to zero, while that of\nexploitation increases toward one. In our simulation experiments, the Q-learning algorithms use a\nstate vector that includes (i) the lagged market price, (ii) the lagged fundamental value, and (iii) the\ncurrent fundamental value. Because market prices are endogenously determined through interactions\namong algorithms, noise traders, information-insensitive investors, and the pricing rule, the system is\nhighly complex and does not yield easily predictable outcomes.\nOur simulation experiments show that AI collusion arises across a wide range of market pa-\nrameters and RL hyperparameters. It emerges through two distinct algorithmic mechanisms, each\ncorresponding to one of the two theoretical collusion mechanisms discussed above and occurring in a\ndifferent region of the market parameter space. One mechanism is based on price-trigger strategies,\nclosely approximating the collusive Nash equilibrium sustained by such strategies. The other results\nfrom a learning bias that leads to the over-pruning of aggressive strategies, aligning with the collusive\nexperience-based equilibrium. We refer to the former as AI collusion driven by “artificial intelligence,”\nand the latter as AI collusion driven by “artificial stupidity.” We elaborate below on the conditions\nunder which each mechanism arises and explain how it emerges.\nSimilar to the predictions from the theoretical model described above, our simulation experiments\nshow that an AI collusive equilibrium sustained by price-trigger strategies emerges robustly in\nenvironments with low noise trading risk and a significant presence of information-insensitive\ninvestors.\nIn such environments, the lagged price, as an endogenous state variable, is highly\ninformative about whether all algorithms traded conservatively in the previous period, which is a\nkey requirement in the theory for sustaining price-trigger strategies. Given that the RL algorithms do\nnot know whom they are playing against or how their payoffs are generated — they simply track\n4\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "can reach the collusive outcomes described above without explicit agreements, communication, or\npre-programmed intent. To do so, we run simulation experiments using autonomous, model-free\nQ-learning algorithms that replace the informed speculators in the theoretical framework. Unlike\ntheir theoretical counterparts, these algorithms rely on RL to determine how to trade on private\nsignals, rather than on rationality or strategic foresight. Q-learning serves as a foundational basis\nfor many RL algorithms that have significantly advanced the AI field. It is valued for its simplicity,",
          "bbox": [
            63.75299835205078,
            52.0322151184082,
            549.288330078125,
            145.19500732421875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.996026039123535,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "transparency, and economic interpretability.\nWe provide additional details about the algorithms in Section 2. As described there, in each",
          "bbox": [
            64.08000183105469,
            150.7055206298828,
            547.9165649414062,
            178.080322265625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "period, an algorithm selects an action (i.e., quantity traded) based on the state it faces (more on the",
          "bbox": [
            63.75299835205078,
            183.5520782470703,
            547.9173583984375,
            194.4938507080078
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.941778182983398,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "state variables below). It stores and updates estimated values for each state-action pair, including both\noptimal and suboptimal actions. These values are referred to as estimated Q-values, and together\nthey form the estimated Q-matrix over the discrete state and action space. At the start of each\nperiod, the algorithm observes the realized state and uses it to update one cell in the Q-matrix\ncorresponding to the state-action pair from the previous period. The realized state may depend\non both the prior state and action. The update is a weighted average of past experience and new",
          "bbox": [
            63.75299835205078,
            200.09017944335938,
            548.3837280273438,
            293.1263427734375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "information, incorporating both the reward just received and the estimated continuation value based",
          "bbox": [
            64.08000183105469,
            298.6764831542969,
            547.9234008789062,
            309.5089416503906
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.832467079162598,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "on the newly realized state. At the end of each period, the algorithm selects an action according to a\nstandard exploration-exploitation rule. Exploitation involves choosing the action with the highest\nestimated Q-value for the current state, while exploration involves selecting a random action. The",
          "bbox": [
            64.08000183105469,
            315.09674072265625,
            547.92041015625,
            358.8658142089844
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.854416847229004,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "interplay between exploration and exploitation is a defining feature of RL algorithms and is critical",
          "bbox": [
            64.08000183105469,
            364.3468933105469,
            547.9172973632812,
            375.2778015136719
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.930895805358887,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "for effective learning. Typically, the likelihood of exploration gradually declines to zero, while that of\nexploitation increases toward one. In our simulation experiments, the Q-learning algorithms use a",
          "bbox": [
            64.08000183105469,
            380.8682556152344,
            547.9244995117188,
            408.16314697265625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.810471534729004,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "state vector that includes (i) the lagged market price, (ii) the lagged fundamental value, and (iii) the",
          "bbox": [
            64.08000183105469,
            413.67535400390625,
            547.9217529296875,
            424.57354736328125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.898184776306152,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "current fundamental value. Because market prices are endogenously determined through interactions",
          "bbox": [
            64.08000183105469,
            430.18115234375,
            547.9187622070312,
            440.9805908203125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "among algorithms, noise traders, information-insensitive investors, and the pricing rule, the system is",
          "bbox": [
            64.08000183105469,
            446.6171569824219,
            547.9188232421875,
            457.4166259765625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "highly complex and does not yield easily predictable outcomes.\nOur simulation experiments show that AI collusion arises across a wide range of market pa-\nrameters and RL hyperparameters. It emerges through two distinct algorithmic mechanisms, each",
          "bbox": [
            64.08000183105469,
            462.9735107421875,
            549.7304077148438,
            506.7771911621094
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "corresponding to one of the two theoretical collusion mechanisms discussed above and occurring in a",
          "bbox": [
            64.08000183105469,
            512.3571166992188,
            547.9189453125,
            523.1566162109375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "different region of the market parameter space. One mechanism is based on price-trigger strategies,",
          "bbox": [
            64.08000183105469,
            528.7135009765625,
            549.2841186523438,
            539.6226196289062
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "closely approximating the collusive Nash equilibrium sustained by such strategies. The other results",
          "bbox": [
            64.08000183105469,
            545.191650390625,
            547.9171752929688,
            556.0405883789062
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.848934173583984,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "from a learning bias that leads to the over-pruning of aggressive strategies, aligning with the collusive",
          "bbox": [
            64.08000183105469,
            561.6631469726562,
            547.918701171875,
            572.462646484375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "experience-based equilibrium. We refer to the former as AI collusion driven by “artificial intelligence,”\nand the latter as AI collusion driven by “artificial stupidity.” We elaborate below on the conditions",
          "bbox": [
            64.08000183105469,
            578.09814453125,
            550.0997314453125,
            605.3790283203125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "under which each mechanism arises and explain how it emerges.",
          "bbox": [
            64.08000183105469,
            610.8895263671875,
            380.9457092285156,
            621.7986450195312
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Similar to the predictions from the theoretical model described above, our simulation experiments\nshow that an AI collusive equilibrium sustained by price-trigger strategies emerges robustly in\nenvironments with low noise trading risk and a significant presence of information-insensitive\ninvestors.\nIn such environments, the lagged price, as an endogenous state variable, is highly\ninformative about whether all algorithms traded conservatively in the previous period, which is a",
          "bbox": [
            64.08000183105469,
            627.4031372070312,
            548.3502197265625,
            704.0037841796875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "key requirement in the theory for sustaining price-trigger strategies. Given that the RL algorithms do\nnot know whom they are playing against or how their payoffs are generated — they simply track",
          "bbox": [
            64.08000183105469,
            709.5791015625,
            548.2278442382812,
            736.8753051757812
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "4",
          "bbox": [
            303.27301025390625,
            765.1044921875,
            308.7275695800781,
            776.0136108398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        }
      ]
    },
    {
      "page_number": 7,
      "text": "states, their own actions, and their own realized payoffs — it is natural to ask how they converge to\nan outcome that closely resembles the one predicted by the fully rational model.\nThe intuition is as follows. After the exploration-intensive phase, the algorithms assign higher\nestimated Q-values to aggressive strategies, where they trade strongly on news about the fundamental,\nas these strategies yield much higher payoffs when played against opponents who randomly choose\nto trade aggressively. Hence, as the system transitions into the exploitation-intensive phase, the\nalgorithms consistently select aggressive trading strategies when they trade against each other, and\nprices move strongly with fundamentals as a result. This leads the estimated Q-values of aggressive\nstrategies to gradually decline, as they converge towards their non-collusive Nash equilibrium levels\nwhen the aggressive strategy is commonplace among the algorithms. At the same time, occasional\nbut ongoing exploration reveals to the algorithms that conservative trading strategies yield higher\nestimated Q-values than aggressive ones in states where lagged prices respond only moderately\nto lagged fundamentals. As a result, the algorithms gradually converge to adopting conservative\nstrategies when others do the same, mirroring collusive behavior. A feedback loop reinforces this\noutcome: in these states, all algorithms select conservative strategies during exploitation, which\ncauses similar states to recur, where lagged prices respond only moderately to fundamentals. Finally,\nfor this pattern to amount to price-trigger collusive behavior, a form of “punishment” following large\nprice responses to fundamentals is needed. Indeed, we observe that all algorithms shift to aggressive\ntrading following such a price response. This occurs because the algorithms recognize the pattern that\nwhen prices respond strongly to fundamentals, trading aggressively is still the best option. Overall,\nthe trading behavior thus exhibits mostly conservative trading with moderate price reactions but\nthere are occasional reversions to punishment phases characterized by aggressive trading behavior.\nThis pattern emerges even though the algorithms lack the strategic sophistication of the fully rational\ninformed speculators in the model. This is why we refer to it as AI collusion through “artificial\nintelligence.”\nImportantly, the convergence to this pattern relies on the informativeness of prices. In envi-\nronments with high noise trading risk or a limited presence of information-insensitive investors,\nboth of which result in low price informativeness, the price-trigger mechanism breaks down. This\nis because the link between the fundamental value, the action, and the price becomes too noisy\nfor the RL process to reliably distinguish patterns where conservative behavior leads to moderate\nprice responses to fundamentals from those where aggressive behavior leads to strong responses.\nInterestingly, we find that across a wide range of such settings, AI collusion still emerges, but through\na learning bias that systematically over-prunes aggressive strategies.\nThe intuition for this particular form of learning bias lies in the asymmetry of estimated Q-\nvalue updates in response to noise trading shocks, a feature inherent to RL due to its reliance on\nexploitation. When noise traders happen to trade in the same direction as the algorithm’s trade,\nalgorithms submitting aggressive trades incur large losses, which become more severe as noise\ntrading risk increases. The algorithm then sharply lowers the estimated Q-value of that strategy,\ntreating it as a very poor action. This discourages the algorithm from revisiting the strategy, thereby\nlocking in the downward bias on its estimated value. Conversely, when noise traders happen to\ntrade in the opposite direction of the algorithm’s trade, the algorithm earns large profits and may\ninitially overestimate the Q-value. However, because exploitation leads to frequent reuse of strategies\n5\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "states, their own actions, and their own realized payoffs — it is natural to ask how they converge to",
          "bbox": [
            64.08000183105469,
            52.09846496582031,
            547.9160766601562,
            63.00210952758789
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.903643608093262,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "an outcome that closely resembles the one predicted by the fully rational model.\nThe intuition is as follows. After the exploration-intensive phase, the algorithms assign higher",
          "bbox": [
            64.08000183105469,
            68.53052520751953,
            548.1390991210938,
            95.90532684326172
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "estimated Q-values to aggressive strategies, where they trade strongly on news about the fundamental,",
          "bbox": [
            64.08000183105469,
            101.47915649414062,
            549.2872924804688,
            112.27861022949219
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "as these strategies yield much higher payoffs when played against opponents who randomly choose\nto trade aggressively. Hence, as the system transitions into the exploitation-intensive phase, the",
          "bbox": [
            64.08000183105469,
            117.86687469482422,
            547.923828125,
            145.2103271484375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.865375518798828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "algorithms consistently select aggressive trading strategies when they trade against each other, and",
          "bbox": [
            64.08000183105469,
            150.68988037109375,
            547.9171752929688,
            161.6207733154297
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.930895805358887,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "prices move strongly with fundamentals as a result. This leads the estimated Q-values of aggressive",
          "bbox": [
            63.75299835205078,
            167.1561737060547,
            547.9181518554688,
            178.04344177246094
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.887259483337402,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "strategies to gradually decline, as they converge towards their non-collusive Nash equilibrium levels\nwhen the aggressive strategy is commonplace among the algorithms. At the same time, occasional\nbut ongoing exploration reveals to the algorithms that conservative trading strategies yield higher\nestimated Q-values than aggressive ones in states where lagged prices respond only moderately\nto lagged fundamentals. As a result, the algorithms gradually converge to adopting conservative\nstrategies when others do the same, mirroring collusive behavior. A feedback loop reinforces this\noutcome: in these states, all algorithms select conservative strategies during exploitation, which",
          "bbox": [
            63.62200164794922,
            183.61473083496094,
            548.350341796875,
            293.1263427734375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.854416847229004,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "causes similar states to recur, where lagged prices respond only moderately to fundamentals. Finally,",
          "bbox": [
            64.08000183105469,
            298.6843566894531,
            549.2816162109375,
            309.505859375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.8214750289917,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "for this pattern to amount to price-trigger collusive behavior, a form of “punishment” following large",
          "bbox": [
            64.08000183105469,
            315.13616943359375,
            547.9189453125,
            325.93560791015625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "price responses to fundamentals is needed. Indeed, we observe that all algorithms shift to aggressive",
          "bbox": [
            63.75299835205078,
            331.5514221191406,
            547.9222412109375,
            342.37841796875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.826972007751465,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "trading following such a price response. This occurs because the algorithms recognize the pattern that",
          "bbox": [
            64.08000183105469,
            348.00616455078125,
            547.918701171875,
            358.80560302734375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "when prices respond strongly to fundamentals, trading aggressively is still the best option. Overall,\nthe trading behavior thus exhibits mostly conservative trading with moderate price reactions but\nthere are occasional reversions to punishment phases characterized by aggressive trading behavior.",
          "bbox": [
            63.62200164794922,
            364.3507995605469,
            549.8280639648438,
            408.1570129394531
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.925451278686523,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "This pattern emerges even though the algorithms lack the strategic sophistication of the fully rational\ninformed speculators in the model. This is why we refer to it as AI collusion through “artificial",
          "bbox": [
            63.742000579833984,
            413.7421875,
            547.9249267578125,
            441.0423278808594
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.80496597290039,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "intelligence.”\nImportantly, the convergence to this pattern relies on the informativeness of prices. In envi-\nronments with high noise trading risk or a limited presence of information-insensitive investors,\nboth of which result in low price informativeness, the price-trigger mechanism breaks down. This\nis because the link between the fundamental value, the action, and the price becomes too noisy\nfor the RL process to reliably distinguish patterns where conservative behavior leads to moderate\nprice responses to fundamentals from those where aggressive behavior leads to strong responses.",
          "bbox": [
            63.75299835205078,
            446.53851318359375,
            549.8258056640625,
            556.0883178710938
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Interestingly, we find that across a wide range of such settings, AI collusion still emerges, but through",
          "bbox": [
            64.08000183105469,
            561.6631469726562,
            547.9188232421875,
            572.462646484375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "a learning bias that systematically over-prunes aggressive strategies.\nThe intuition for this particular form of learning bias lies in the asymmetry of estimated Q-\nvalue updates in response to noise trading shocks, a feature inherent to RL due to its reliance on\nexploitation. When noise traders happen to trade in the same direction as the algorithm’s trade,\nalgorithms submitting aggressive trades incur large losses, which become more severe as noise\ntrading risk increases. The algorithm then sharply lowers the estimated Q-value of that strategy,",
          "bbox": [
            63.775001525878906,
            578.01953125,
            549.7301635742188,
            671.1343383789062
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "treating it as a very poor action. This discourages the algorithm from revisiting the strategy, thereby\nlocking in the downward bias on its estimated value. Conversely, when noise traders happen to\ntrade in the opposite direction of the algorithm’s trade, the algorithm earns large profits and may",
          "bbox": [
            64.08000183105469,
            676.6530151367188,
            548.3502197265625,
            720.4403076171875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.876322746276855,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "initially overestimate the Q-value. However, because exploitation leads to frequent reuse of strategies",
          "bbox": [
            64.08000183105469,
            726.0062255859375,
            547.9207153320312,
            736.8167114257812
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.810471534729004,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "5",
          "bbox": [
            303.27301025390625,
            765.1044921875,
            308.7275695800781,
            776.0136108398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        }
      ]
    },
    {
      "page_number": 8,
      "text": "with high estimated Q-values, the algorithm continually revisits this action, allowing the estimated\nQ-value to be eventually corrected through sufficient further updates. In environments where trading\noutcomes are dominated by random noise rather than informed trading, this asymmetry in the\nexploitation process becomes especially pronounced and cannot be effectively corrected through\nexploration. Aggressive trading strategies, being more exposed to noise trading shocks, are more\nlikely to be prematurely pruned. This asymmetry causes the algorithm to develop a biased value\nsystem that consistently favors conservative trading strategies. Given the nature of competition\namong algorithms, they end up collectively benefiting from this bias, leading to a collusive outcome.\nThis is why we refer to the behavior as AI collusion through “artificial stupidity.”\nThe pervasiveness of AI collusion in our simulation experiments has first-order implications for\nmarket outcomes, and so is highly relevant for the purpose of market regulation. We show that\na greater extent of collusion, characterized by higher supra-competitive profits for the algorithms,\nleads to lower market liquidity, lower price informativeness, and higher mispricing, regardless of\nwhich algorithmic mechanism the AI collusion is based on. To better understand the drivers of AI\ncollusion, we conduct extensive simulation experiments by varying different market parameters. In\nprice-trigger AI collusion, collusion capacity increases when the number of informed speculators falls,\nnoise trading risk decreases, or the subjective discount factor increases. In contrast, over-pruning\nAI collusion shows different patterns: fewer informed speculators have similar effects, but lower\nnoise trading risk reduces collusion, and the subjective discount factor has little impact. These results\nalign with the underlying algorithmic mechanisms explained above and are strongly consistent\nwith what we would expect given their theoretical underpinnings. We also examine the role of RL\nhyperparameters, including the weight put on recent experience relative to past information in the\nupdating process and the rate of exploration decay. Across a broad range of values, collusive behavior\nand supra-competitive profits remain robust under both algorithmic mechanisms for AI collusion.\nContributions and Related Literature.\nThis article uncovers the economic foundations and algo-\nrithmic mechanisms of AI collusion in securities trading, focusing on its effects on price formation\nand market efficiency. These issues are central to current regulatory uncertainty, as AI represents a\nfundamentally different form of intelligence. Unlike humans, whose decisions reflect logic, emotion,\nand beliefs about others’ beliefs, AI relies on pattern recognition and optimization. As a result,\nexisting frameworks based on human behavior may not capture the strategic dynamics or equilibrium\nbehavior of AI traders, highlighting the need to study the algorithmic behavior — or “psychology” —\nof machines (Goldstein, Spatt and Ye, 2021).\nOur work follows recent work on AI collusion in retail markets (e.g., Calvano et al., 2020, 2021;\nJohnson, Rhodes and Wildenbeest, 2023). The financial-market setting is fundamentally different as it\nexhibits asymmetric information, noise trading, and a price-setting mechanism that is facilitated by\nmarket makers who consider the details of the environment. Hence, we extend the simulation-based\nAI experimental framework from the retail-market environment to the financial-market environment\nby replacing assumptions of near-perfect information and fixed demand curves with a setting\ncharacterized by substantial asymmetric information and strategically adaptive demand curves\nshaped by market makers’ price discovery. As discussed above, our setting is characterized by two\nkey parameters: the level of noise trading risk and the extent of information-insensitive investor\n6\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "with high estimated Q-values, the algorithm continually revisits this action, allowing the estimated",
          "bbox": [
            63.62200164794922,
            52.07111740112305,
            547.9180908203125,
            63.01289749145508
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.941778182983398,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Q-value to be eventually corrected through sufficient further updates. In environments where trading\noutcomes are dominated by random noise rather than informed trading, this asymmetry in the\nexploitation process becomes especially pronounced and cannot be effectively corrected through\nexploration. Aggressive trading strategies, being more exposed to noise trading shocks, are more\nlikely to be prematurely pruned. This asymmetry causes the algorithm to develop a biased value\nsystem that consistently favors conservative trading strategies. Given the nature of competition",
          "bbox": [
            64.08000183105469,
            68.60916137695312,
            547.9188232421875,
            161.64532470703125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "among algorithms, they end up collectively benefiting from this bias, leading to a collusive outcome.",
          "bbox": [
            64.08000183105469,
            167.171875,
            549.8283081054688,
            178.03724670410156
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.865375518798828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "This is why we refer to the behavior as AI collusion through “artificial stupidity.”",
          "bbox": [
            63.742000579833984,
            183.5755157470703,
            459.85150146484375,
            194.48460388183594
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "The pervasiveness of AI collusion in our simulation experiments has first-order implications for\nmarket outcomes, and so is highly relevant for the purpose of market regulation. We show that\na greater extent of collusion, characterized by higher supra-competitive profits for the algorithms,\nleads to lower market liquidity, lower price informativeness, and higher mispricing, regardless of\nwhich algorithmic mechanism the AI collusion is based on. To better understand the drivers of AI",
          "bbox": [
            63.62200164794922,
            199.99981689453125,
            549.284912109375,
            276.6852111816406
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.925451278686523,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "collusion, we conduct extensive simulation experiments by varying different market parameters. In",
          "bbox": [
            64.08000183105469,
            282.1787109375,
            547.9151611328125,
            293.0987243652344
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.920002937316895,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "price-trigger AI collusion, collusion capacity increases when the number of informed speculators falls,\nnoise trading risk decreases, or the subjective discount factor increases. In contrast, over-pruning\nAI collusion shows different patterns: fewer informed speculators have similar effects, but lower",
          "bbox": [
            63.65399932861328,
            298.7001647949219,
            549.2808837890625,
            342.4323425292969
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "noise trading risk reduces collusion, and the subjective discount factor has little impact. These results\nalign with the underlying algorithmic mechanisms explained above and are strongly consistent\nwith what we would expect given their theoretical underpinnings. We also examine the role of RL\nhyperparameters, including the weight put on recent experience relative to past information in the",
          "bbox": [
            63.62200164794922,
            348.00616455078125,
            548.2544555664062,
            408.1570129394531
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "updating process and the rate of exploration decay. Across a broad range of values, collusive behavior",
          "bbox": [
            64.08000183105469,
            413.74615478515625,
            548.143310546875,
            424.54559326171875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "and supra-competitive profits remain robust under both algorithmic mechanisms for AI collusion.",
          "bbox": [
            64.08000183105469,
            430.1025085449219,
            541.036865234375,
            441.0116271972656
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Contributions and Related Literature.\nThis article uncovers the economic foundations and algo-\nrithmic mechanisms of AI collusion in securities trading, focusing on its effects on price formation\nand market efficiency. These issues are central to current regulatory uncertainty, as AI represents a",
          "bbox": [
            64.08000183105469,
            462.8387145996094,
            549.7268676757812,
            506.95947265625
          ],
          "font_info": {
            "font": "URWPalladioL-BoldItal",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 22
          }
        },
        {
          "text": "fundamentally different form of intelligence. Unlike humans, whose decisions reflect logic, emotion,\nand beliefs about others’ beliefs, AI relies on pattern recognition and optimization. As a result,",
          "bbox": [
            64.08000183105469,
            512.4990234375,
            549.2889404296875,
            539.8463134765625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.870850563049316,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "existing frameworks based on human behavior may not capture the strategic dynamics or equilibrium",
          "bbox": [
            64.08000183105469,
            545.4201049804688,
            547.9188232421875,
            556.2196044921875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "behavior of AI traders, highlighting the need to study the algorithmic behavior — or “psychology” —",
          "bbox": [
            64.08000183105469,
            561.8561401367188,
            550.0997314453125,
            572.6556396484375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "of machines (Goldstein, Spatt and Ye, 2021).\nOur work follows recent work on AI collusion in retail markets (e.g., Calvano et al., 2020, 2021;",
          "bbox": [
            64.08000183105469,
            578.2125244140625,
            549.2887573242188,
            605.5812377929688
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Johnson, Rhodes and Wildenbeest, 2023). The financial-market setting is fundamentally different as it",
          "bbox": [
            63.89400100708008,
            611.1611328125,
            547.9252319335938,
            621.9606323242188
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 856203,
            "flags": 4
          }
        },
        {
          "text": "exhibits asymmetric information, noise trading, and a price-setting mechanism that is facilitated by",
          "bbox": [
            64.08000183105469,
            627.5018920898438,
            548.3443603515625,
            638.4328002929688
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.930895805358887,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "market makers who consider the details of the environment. Hence, we extend the simulation-based",
          "bbox": [
            64.08000183105469,
            643.9996337890625,
            547.923828125,
            654.8430786132812
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.843446731567383,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "AI experimental framework from the retail-market environment to the financial-market environment\nby replacing assumptions of near-perfect information and fixed demand curves with a setting\ncharacterized by substantial asymmetric information and strategically adaptive demand curves\nshaped by market makers’ price discovery. As discussed above, our setting is characterized by two\nkey parameters: the level of noise trading risk and the extent of information-insensitive investor",
          "bbox": [
            63.65399932861328,
            660.4385375976562,
            548.138916015625,
            737.068359375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.837958335876465,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "6",
          "bbox": [
            303.27301025390625,
            765.1044921875,
            308.7275695800781,
            776.0136108398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        }
      ]
    },
    {
      "page_number": 9,
      "text": "presence. We identify two distinct algorithmic mechanisms through which AI collusion can occur and\nsystematically characterize when each of them arises as a function of these parameters and others.\nOur model results present novel contribution to the theoretical literature on financial-market trading,\nand our simulation-based experimental results have no parallel in the emerging literature on AI\ncollusion mentioned above.\nWhile the price-trigger collusion is shown in the simpler setting of Calvano et al. (2020, 2021),\nwe show that it only holds when there is small noise trading risk and strong information-insensitive\ninvestor presence. Yet, when this mechanism fails, AI collusion typically arises through a distinct\nchannel: a learning bias driven by the over-pruning of aggressive strategies. In the terminology of\nCalvano et al. (2020), this latter channel may not count as collusion, as it arises from a learning bias,\neven though it satisfies the two defining features of a collusive equilibrium described above. However,\nit is important to note that it is equally robust and has largely the same implications for trading\nprofits, market liquidity, price informativeness, and mispricing. Hence, understanding how and\nwhen the two mechanisms emerge is of equally high importance. Others have studied algorithmic\nmechanisms, which generate supra-competitive profits without the punishment trigger (e.g., Waltman\nand Kaymak, 2008; Hansen, Misra and Pai, 2021; Abada and Lambin, 2023; Asker, Fershtman and\nPakes, 2024; Banchio and Mantegazza, 2024; Dolgopolov, 2024; Lambin, 2024), but they largely rely\non simplifying restrictions on the algorithmic capacity. We provide a detailed discussion of these\nworks in Online Appendix 1. On the other hand, the over-pruning bias we uncover arises in a highly\nsophisticated environment, complementing the range of parameters where price-trigger collusion\narises, and points to a pervasive feature of the RL framework: the asymmetric effect of exploitation,\nwhereby adverse and beneficial shocks influence learning differently.\nThere are a few early works that investigate the effects that related algorithms may have on\nfinancial or money markets (e.g., Marimon, McGrattan and Sargent, 1990; Routledge, 1999, 2001).\nHowever, they either explore adaptive learning algorithms or more basic RL algorithms than ours.\nThey do not develop implications such as we develop here regarding collusion and its effects on\nmarket efficiency. A related contemporaneous work, Colliard, Foucault and Lovo (2025), studies\ninteractions among Q-learning algorithms but focuses on stateless AI market makers. In contrast, we\nstudy AI-powered informed speculators using Q-learning with endogenous state variables, such as\npast prices. Unlike them, we uncover the different algorithmic mechanisms that drive AI collusion\nand characterize when they dominate. Cartea et al. (2022b) also analyze stateless RL in market making\nusing a multi-armed bandit algorithm.\nFurthermore, our paper contributes to the rapid growing literature on the impact of AI and\nbig data on the efficiency and functioning of financial markets (e.g., Goldstein, Spatt and Ye, 2021;\nFarboodi and Veldkamp, 2023, for literature review). Recent studies theoretically examine how data\nabundance and advances in information processing technologies affect price informativeness and\nmarket liquidity (e.g., Dugast and Foucault, 2018; Farboodi and Veldkamp, 2020; Dugast and Foucault,\n2024). Another strand of the literature demonstrates that advanced machine learning techniques can\neffectively extract predictive signals or latent economic structures from high-dimensional public data,\nwhich are otherwise difficult to detect using traditional methods (e.g., Kaniel et al., 2023; Cao et al.,\n2024; Chen, Kelly and Xiu, 2024; Gao, Xiong and Yuan, 2024; Kelly, Malamud and Zhou, 2024; Chen\net al., 2025). In contrast, our paper focuses on understanding the behavior of AI agents that replace\n7\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "presence. We identify two distinct algorithmic mechanisms through which AI collusion can occur and\nsystematically characterize when each of them arises as a function of these parameters and others.",
          "bbox": [
            63.75299835205078,
            52.17318344116211,
            549.8330688476562,
            79.46727752685547
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Our model results present novel contribution to the theoretical literature on financial-market trading,\nand our simulation-based experimental results have no parallel in the emerging literature on AI",
          "bbox": [
            64.08000183105469,
            85.02442169189453,
            549.280517578125,
            112.34032440185547
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.826972007751465,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "collusion mentioned above.\nWhile the price-trigger collusion is shown in the simpler setting of Calvano et al. (2020, 2021),",
          "bbox": [
            64.08000183105469,
            117.83551788330078,
            549.2852783203125,
            145.2103271484375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "we show that it only holds when there is small noise trading risk and strong information-insensitive\ninvestor presence. Yet, when this mechanism fails, AI collusion typically arises through a distinct\nchannel: a learning bias driven by the over-pruning of aggressive strategies. In the terminology of",
          "bbox": [
            63.62200164794922,
            150.73294067382812,
            547.9247436523438,
            194.51072692871094
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.870850563049316,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Calvano et al. (2020), this latter channel may not count as collusion, as it arises from a learning bias,",
          "bbox": [
            64.08000183105469,
            200.0154571533203,
            549.2893676757812,
            210.91909790039062
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.903643608093262,
            "color": 856203,
            "flags": 4
          }
        },
        {
          "text": "even though it satisfies the two defining features of a collusive equilibrium described above. However,\nit is important to note that it is equally robust and has largely the same implications for trading\nprofits, market liquidity, price informativeness, and mispricing. Hence, understanding how and\nwhen the two mechanisms emerge is of equally high importance. Others have studied algorithmic",
          "bbox": [
            63.62200164794922,
            216.52517700195312,
            549.2872924804688,
            276.6836853027344
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "mechanisms, which generate supra-competitive profits without the punishment trigger (e.g., Waltman\nand Kaymak, 2008; Hansen, Misra and Pai, 2021; Abada and Lambin, 2023; Asker, Fershtman and",
          "bbox": [
            64.08000183105469,
            282.2651672363281,
            547.918701171875,
            309.56134033203125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Pakes, 2024; Banchio and Mantegazza, 2024; Dolgopolov, 2024; Lambin, 2024), but they largely rely\non simplifying restrictions on the algorithmic capacity. We provide a detailed discussion of these",
          "bbox": [
            64.08000183105469,
            315.0340881347656,
            548.3433227539062,
            342.4323425292969
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.941778182983398,
            "color": 856203,
            "flags": 4
          }
        },
        {
          "text": "works in Online Appendix 1. On the other hand, the over-pruning bias we uncover arises in a highly\nsophisticated environment, complementing the range of parameters where price-trigger collusion",
          "bbox": [
            63.62200164794922,
            347.98248291015625,
            548.3473510742188,
            375.3023376464844
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.832467079162598,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "arises, and points to a pervasive feature of the RL framework: the asymmetric effect of exploitation,",
          "bbox": [
            64.08000183105469,
            380.7936096191406,
            549.2887573242188,
            391.7081604003906
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.91455364227295,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "whereby adverse and beneficial shocks influence learning differently.\nThere are a few early works that investigate the effects that related algorithms may have on\nfinancial or money markets (e.g., Marimon, McGrattan and Sargent, 1990; Routledge, 1999, 2001).\nHowever, they either explore adaptive learning algorithms or more basic RL algorithms than ours.\nThey do not develop implications such as we develop here regarding collusion and its effects on\nmarket efficiency. A related contemporaneous work, Colliard, Foucault and Lovo (2025), studies",
          "bbox": [
            63.62200164794922,
            397.2325134277344,
            549.8328857421875,
            490.34832763671875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "interactions among Q-learning algorithms but focuses on stateless AI market makers. In contrast, we",
          "bbox": [
            64.08000183105469,
            495.90240478515625,
            547.9161376953125,
            506.7294006347656
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.826972007751465,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "study AI-powered informed speculators using Q-learning with endogenous state variables, such as\npast prices. Unlike them, we uncover the different algorithmic mechanisms that drive AI collusion",
          "bbox": [
            63.75299835205078,
            512.2589721679688,
            547.91650390625,
            539.642578125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.936338424682617,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "and characterize when they dominate. Cartea et al. (2022b) also analyze stateless RL in market making",
          "bbox": [
            64.08000183105469,
            545.0399169921875,
            547.9210815429688,
            556.026611328125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "using a multi-armed bandit algorithm.\nFurthermore, our paper contributes to the rapid growing literature on the impact of AI and\nbig data on the efficiency and functioning of financial markets (e.g., Goldstein, Spatt and Ye, 2021;",
          "bbox": [
            64.08000183105469,
            561.5845336914062,
            549.2849731445312,
            605.3943481445312
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Farboodi and Veldkamp, 2023, for literature review). Recent studies theoretically examine how data\nabundance and advances in information processing technologies affect price informativeness and",
          "bbox": [
            64.08000183105469,
            610.9013061523438,
            547.9163208007812,
            638.2643432617188
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.89272403717041,
            "color": 856203,
            "flags": 4
          }
        },
        {
          "text": "market liquidity (e.g., Dugast and Foucault, 2018; Farboodi and Veldkamp, 2020; Dugast and Foucault,",
          "bbox": [
            64.08000183105469,
            643.838134765625,
            549.287353515625,
            654.6376342773438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "2024). Another strand of the literature demonstrates that advanced machine learning techniques can",
          "bbox": [
            64.08000183105469,
            660.2297973632812,
            547.9226684570312,
            671.0897216796875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.85989761352539,
            "color": 856203,
            "flags": 4
          }
        },
        {
          "text": "effectively extract predictive signals or latent economic structures from high-dimensional public data,",
          "bbox": [
            64.08000183105469,
            676.7002563476562,
            549.28125,
            687.5107421875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.810471534729004,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "which are otherwise difficult to detect using traditional methods (e.g., Kaniel et al., 2023; Cao et al.,",
          "bbox": [
            63.62200164794922,
            693.0459594726562,
            549.2785034179688,
            703.9822998046875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.936338424682617,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "2024; Chen, Kelly and Xiu, 2024; Gao, Xiong and Yuan, 2024; Kelly, Malamud and Zhou, 2024; Chen",
          "bbox": [
            64.08000183105469,
            709.5161743164062,
            547.9193115234375,
            720.4034423828125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.887259483337402,
            "color": 856203,
            "flags": 4
          }
        },
        {
          "text": "et al., 2025). In contrast, our paper focuses on understanding the behavior of AI agents that replace",
          "bbox": [
            64.08000183105469,
            725.9198608398438,
            547.9170532226562,
            736.8507690429688
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.930895805358887,
            "color": 856203,
            "flags": 4
          }
        },
        {
          "text": "7",
          "bbox": [
            303.27301025390625,
            765.1044921875,
            308.7275695800781,
            776.0136108398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        }
      ]
    },
    {
      "page_number": 10,
      "text": "humans. We examine the resulting AI equilibrium, shaped by algorithmic interactions, highlighting\nthe importance of examining this equilibrium when assessing the overall impact of AI adoption on\nmarket efficiency.\nFinally, our paper is closely related to the literature on imperfect competition in financial markets.\nRostek and Yoon (2024) provide a recent review of the theory of imperfectly competitive financial\nmarkets, covering influential early contributions such as Kyle (1989) and Vayanos (1999), which focus\non non-collusive equilibria. Theoretical works that study the effect of coordination or collusion among\nmajor market participants on market microstructure dynamics under a repeated game framework\ninclude Dutta and Madhavan (1997), Carlin, Lobo and Viswanathan (2007), and Hörner, Lovo and\nTomala (2018), among others. The common feature of these models is that supra-competitive trading\nprofits are sustained through the threat of punishment. In addition to these models that focus on\nmarket microstructure dynamics, there are other papers that theoretically analyze collusion in financial\nmarkets due to FinTech (e.g., Cong and He, 2019). Several papers provide supporting evidence for\ncollusion in financial markets across various settings (e.g., Christie and Schultz, 1994, 1995; Christie,\nHarris and Schultz, 1994; Chen and Ritter, 2000; Dou, Wang and Wang, 2023; Bryzgalova, Pavlova and\nSikorskaya, 2025; Lehar and Parlour, 2025). We provide new theoretical results characterizing when\ncollusion can be sustained in financial-market environments and contribute further by showing that\nautonomous, self-interested AI-powered trading algorithms can learn to coordinate, even without\nany agreement, communication, or intention.\n2\nAI-Powered Trading Algorithms\nWhile RL encompasses different variants (e.g., Watkins and Dayan, 1992; Sutton and Barto, 2018),\nwe choose to focus on Q-learning for several reasons. First, Q-learning serves as a foundational\nframework for numerous dynamically sophisticated RL algorithms, upon which many recent AI\nbreakthroughs are built.5 Second, it is widely adopted in practice. Third, it is valued for its simplicity,\ntransparency, and economic interpretability.\n2.1\nBellman Equation and Q-Function\nIn a multi-agent Markov decision process environment, there are I agents, indexed by i = 1, · · · , I.\nThe state of the environment is represented by a vector s, which evolves according to a Markov\nprocess. Each agent makes decisions based on the current state, which in turn evolves partly due\nto the collective actions of all agents within the system. Agent i’s intertemporal optimization is\ncharacterized by the Bellman equation and solved recursively via dynamic programming:\nVi(s) = max\nxi∈X\n\b\nE [πi|s, xi] + ρE\n\u0002\nVi(s′)|s, xi\n\u0003\t\n,\n(2.1)\nwhere xi ∈X is the action taken by agent i, with X denoting the set of available actions, πi is the\npayoff received by agent i that depends on the chosen action xi as well as the actions of other agents,\n5Q-learning and other dynamically sophisticated RL algorithms take into account the possibility that actions lead to\nstate transitions and internalize that an action taken in a given state can affect future states and rewards. In contrast,\nmulti-armed bandit algorithms, a class of stateless RL methods, are not dynamically sophisticated: they do not incorporate\nany notion of state and therefore ignore the possibility that actions influence future decision-making environments.\n8\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "humans. We examine the resulting AI equilibrium, shaped by algorithmic interactions, highlighting",
          "bbox": [
            64.08000183105469,
            52.102378845214844,
            547.9219360351562,
            63.00056457519531
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.898184776306152,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "the importance of examining this equilibrium when assessing the overall impact of AI adoption on",
          "bbox": [
            64.08000183105469,
            68.50318908691406,
            547.9239501953125,
            79.45040893554688
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.94721508026123,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "market efficiency.",
          "bbox": [
            64.08000183105469,
            84.96552276611328,
            148.77825927734375,
            95.87462615966797
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Finally, our paper is closely related to the literature on imperfect competition in financial markets.\nRostek and Yoon (2024) provide a recent review of the theory of imperfectly competitive financial",
          "bbox": [
            64.08000183105469,
            101.47520446777344,
            549.8310546875,
            128.77532958984375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.80496597290039,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "markets, covering influential early contributions such as Kyle (1989) and Vayanos (1999), which focus",
          "bbox": [
            64.08000183105469,
            134.34519958496094,
            547.92041015625,
            145.15016174316406
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.80496597290039,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "on non-collusive equilibria. Theoretical works that study the effect of coordination or collusion among\nmajor market participants on market microstructure dynamics under a repeated game framework\ninclude Dutta and Madhavan (1997), Carlin, Lobo and Viswanathan (2007), and Hörner, Lovo and",
          "bbox": [
            64.08000183105469,
            150.78414916992188,
            548.2203369140625,
            194.51377868652344
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Tomala (2018), among others. The common feature of these models is that supra-competitive trading\nprofits are sustained through the threat of punishment. In addition to these models that focus on",
          "bbox": [
            63.742000579833984,
            200.06256103515625,
            547.9251708984375,
            227.3863525390625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.837958335876465,
            "color": 856203,
            "flags": 4
          }
        },
        {
          "text": "market microstructure dynamics, there are other papers that theoretically analyze collusion in financial\nmarkets due to FinTech (e.g., Cong and He, 2019). Several papers provide supporting evidence for",
          "bbox": [
            64.08000183105469,
            232.96017456054688,
            548.1434936523438,
            260.2456359863281
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "collusion in financial markets across various settings (e.g., Christie and Schultz, 1994, 1995; Christie,",
          "bbox": [
            64.08000183105469,
            265.7593688964844,
            549.2826538085938,
            276.6575622558594
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.898184776306152,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Harris and Schultz, 1994; Chen and Ritter, 2000; Dou, Wang and Wang, 2023; Bryzgalova, Pavlova and",
          "bbox": [
            64.08000183105469,
            282.2651672363281,
            547.9188842773438,
            293.06463623046875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 856203,
            "flags": 4
          }
        },
        {
          "text": "Sikorskaya, 2025; Lehar and Parlour, 2025). We provide new theoretical results characterizing when",
          "bbox": [
            64.08000183105469,
            298.62152099609375,
            547.9204711914062,
            309.5306396484375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 856203,
            "flags": 4
          }
        },
        {
          "text": "collusion can be sustained in financial-market environments and contribute further by showing that\nautonomous, self-interested AI-powered trading algorithms can learn to coordinate, even without",
          "bbox": [
            64.08000183105469,
            315.0732116699219,
            547.9193115234375,
            342.4323425292969
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.887259483337402,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "any agreement, communication, or intention.",
          "bbox": [
            64.08000183105469,
            347.9275207519531,
            283.27655029296875,
            358.8366394042969
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "2\nAI-Powered Trading Algorithms",
          "bbox": [
            64.08000183105469,
            384.3937683105469,
            298.4108581542969,
            398.739990234375
          ],
          "font_info": {
            "font": "URWPalladioL-Bold",
            "size": 14.346199989318848,
            "color": 0,
            "flags": 20
          }
        },
        {
          "text": "While RL encompasses different variants (e.g., Watkins and Dayan, 1992; Sutton and Barto, 2018),\nwe choose to focus on Q-learning for several reasons. First, Q-learning serves as a foundational\nframework for numerous dynamically sophisticated RL algorithms, upon which many recent AI",
          "bbox": [
            63.534000396728516,
            415.1236572265625,
            549.2843627929688,
            459.0113220214844
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "breakthroughs are built.5 Second, it is widely adopted in practice. Third, it is valued for its simplicity,",
          "bbox": [
            64.08000183105469,
            460.6251525878906,
            549.2886352539062,
            475.38458251953125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "transparency, and economic interpretability.",
          "bbox": [
            64.08000183105469,
            480.9415283203125,
            277.134765625,
            491.85064697265625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "2.1\nBellman Equation and Q-Function",
          "bbox": [
            64.08000183105469,
            513.0337524414062,
            280.0506591796875,
            524.9889526367188
          ],
          "font_info": {
            "font": "URWPalladioL-Bold",
            "size": 11.9552001953125,
            "color": 0,
            "flags": 20
          }
        },
        {
          "text": "In a multi-agent Markov decision process environment, there are I agents, indexed by i = 1, · · · , I.\nThe state of the environment is represented by a vector s, which evolves according to a Markov\nprocess. Each agent makes decisions based on the current state, which in turn evolves partly due\nto the collective actions of all agents within the system. Agent i’s intertemporal optimization is",
          "bbox": [
            63.742000579833984,
            536.802734375,
            549.8289184570312,
            598.25537109375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.996026039123535,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "characterized by the Bellman equation and solved recursively via dynamic programming:",
          "bbox": [
            64.08000183105469,
            603.75048828125,
            499.778564453125,
            614.6596069335938
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Vi(s) = max\nxi∈X",
          "bbox": [
            198.79100036621094,
            632.4180908203125,
            258.224365234375,
            651.994140625
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "\b\nE [πi|s, xi] + ρE\n\u0002\nVi(s′)|s, xi\n\u0003\t\n,\n(2.1)",
          "bbox": [
            260.17901611328125,
            630.1988525390625,
            549.010986328125,
            645.3361206054688
          ],
          "font_info": {
            "font": "CMEX10",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "where xi ∈X is the action taken by agent i, with X denoting the set of available actions, πi is the",
          "bbox": [
            63.62200164794922,
            664.7057495117188,
            547.9181518554688,
            678.7713623046875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "payoff received by agent i that depends on the chosen action xi as well as the actions of other agents,",
          "bbox": [
            63.75299835205078,
            682.159423828125,
            549.2824096679688,
            695.1585693359375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.848934173583984,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "5Q-learning and other dynamically sophisticated RL algorithms take into account the possibility that actions lead to\nstate transitions and internalize that an action taken in a given state can affect future states and rewards. In contrast,\nmulti-armed bandit algorithms, a class of stateless RL methods, are not dynamically sophisticated: they do not incorporate\nany notion of state and therefore ignore the possibility that actions influence future decision-making environments.",
          "bbox": [
            64.08000183105469,
            701.90771484375,
            549.0414428710938,
            745.5771484375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 6.973800182342529,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "8",
          "bbox": [
            303.27301025390625,
            765.1044921875,
            308.7275695800781,
            776.0136108398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        }
      ]
    },
    {
      "page_number": 11,
      "text": "and s, s′ ∈S represent the states in the current and the next period, respectively, with S denoting the\nset of states. The state vector s may depend on agent-specific conditions and private signals faced by\neach agent i, for all i. The first term on the right-hand side, E [πi|s, xi], is agent i’s expected payoff\nin the current period, and the second term, ρE [Vi(s′)|s, xi], is agent i’s continuation value, with ρ\ncapturing the subjective discount factor.\nEquation (2.1) represents the recursive formulation of dynamic control problems (e.g., Bellman,\n1954; Ljungqvist and Sargent, 2012). It characterizes behavior along the equilibrium path, where\nthe optimal value function Vi(s) depends only on the current state s. In contrast, the Q function,\ndenoted by Qi(s, xi), extends the value function to each possible state-action pair, allowing evaluation\nof outcomes not only on the equilibrium path but also for counterfactual or off-path actions. By\ndefinition, the Q-function value for a given (s, xi) corresponds to the right-hand side of equation (2.1):\nQi(s, xi) = E [πi|s, xi] + ρE\n\u0002\nVi(s′)|s, xi\n\u0003\n.\n(2.2)\nIntuitively, the Q-function value, Qi(s, xi), can be interpreted as the quality of action xi in state s. The\noptimal value of a state, Vi(s), is the maximum of all the possible Q-function values of state s. That\nis, Vi(s) ≡maxx′∈X Qi(s, x′). By substituting Vi(s′) with maxx′∈X Qi(s′, x′) in equation (2.2), we can\nestablish a recursive formula for the Q-function as follows:\nQi(s, xi) = E\n\u0014\nπi + ρ max\nx′∈X Qi(s′, x′)\n\f\f\f\fs, xi\n\u0015\n.\n(2.3)\nWhen both |S| and |X| are finite, the Q-function can be represented as an |S| × |X| matrix, which\nis often referred to as the Q-matrix.\n2.2\nQ-Learning Algorithm\nIf agent i possessed knowledge of its Q-matrix, determining the optimal actions for any given state\ns would be straightforward. In essence, Q-learning estimates the Q-matrix when the conditional\ndistribution E [·|s, xi] and off-equilibrium observations (s, xi) are limited. By design, the Q-learning\nalgorithm addresses both challenges simultaneously: it uses the law of large numbers to learn the\nunderlying distribution from repeated experiences, while its trial-and-error experiments generates\ncounterfactual outcomes for state-action pairs that may not occur along the equilibrium path.\nAgent i’s iterative experimentation begins with an arbitrary initial estimated Q-matrix, bQi,0, and\nrecursively updates it from bQi,t to bQi,t+1 in iteration t + 1 as follows:\nbQi,t+1(st, xi,t) = (1 −α) bQi,t(st, xi,t)\n|\n{z\n}\nPast knowledge\n+ α\n\u0014\nπi,t + ρ max\nx′∈X\nbQi,t(st+1, x′)\n\u0015\n,\n|\n{z\n}\nNew information from experimentation\n(2.4)\nwhere α ∈[0, 1] captures the forgetting rate.6 Upon agent i choosing action xi,t in state st and\nobserving the payoff πi,t, the update from bQi,t to bQi,t+1 at the pair (st, xi,t) occurs immediately after\n6The forgetting rate α determines how quickly past experiments are discounted. For consistent learning, α must decay\nto zero to ensure convergence of the estimated Q-matrix bQi,t as t grows large. A smaller α improves asymptotic accuracy\nbut slows convergence, reflecting a higher learning capacity at the expense of greater computational cost.\n9\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "and s, s′ ∈S represent the states in the current and the next period, respectively, with S denoting the",
          "bbox": [
            64.08000183105469,
            46.92678451538086,
            547.917724609375,
            62.986637115478516
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.848934173583984,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "set of states. The state vector s may depend on agent-specific conditions and private signals faced by\neach agent i, for all i. The first term on the right-hand side, E [πi|s, xi], is agent i’s expected payoff\nin the current period, and the second term, ρE [Vi(s′)|s, xi], is agent i’s continuation value, with ρ",
          "bbox": [
            64.08000183105469,
            68.34142303466797,
            548.3422241210938,
            113.2582015991211
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.843446731567383,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "capturing the subjective discount factor.\nEquation (2.1) represents the recursive formulation of dynamic control problems (e.g., Bellman,\n1954; Ljungqvist and Sargent, 2012). It characterizes behavior along the equilibrium path, where\nthe optimal value function Vi(s) depends only on the current state s. In contrast, the Q function,",
          "bbox": [
            63.534000396728516,
            117.83551788330078,
            549.2891235351562,
            178.99818420410156
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "denoted by Qi(s, xi), extends the value function to each possible state-action pair, allowing evaluation\nof outcomes not only on the equilibrium path but also for counterfactual or off-path actions. By",
          "bbox": [
            64.08000183105469,
            182.51507568359375,
            548.350341796875,
            210.95135498046875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "definition, the Q-function value for a given (s, xi) corresponds to the right-hand side of equation (2.1):",
          "bbox": [
            64.08000183105469,
            215.3861083984375,
            549.2884521484375,
            228.30421447753906
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Qi(s, xi) = E [πi|s, xi] + ρE\n\u0002\nVi(s′)|s, xi\n\u0003\n.\n(2.2)",
          "bbox": [
            209.1820068359375,
            242.89486694335938,
            549.0062866210938,
            258.0322570800781
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "Intuitively, the Q-function value, Qi(s, xi), can be interpreted as the quality of action xi in state s. The",
          "bbox": [
            64.08000183105469,
            274.84210205078125,
            547.9176025390625,
            288.6986083984375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "optimal value of a state, Vi(s), is the maximum of all the possible Q-function values of state s. That\nis, Vi(s) ≡maxx′∈X Qi(s, x′). By substituting Vi(s′) with maxx′∈X Qi(s′, x′) in equation (2.2), we can",
          "bbox": [
            64.08000183105469,
            291.277099609375,
            547.9231567382812,
            321.49853515625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.941778182983398,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "establish a recursive formula for the Q-function as follows:",
          "bbox": [
            64.08000183105469,
            325.2085266113281,
            349.8220520019531,
            336.1176452636719
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Qi(s, xi) = E\n\u0014\nπi + ρ max\nx′∈X Qi(s′, x′)\n\f\f\f\fs, xi",
          "bbox": [
            206.8350067138672,
            348.4342041015625,
            394.1897888183594,
            378.9793395996094
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "\u0015\n.\n(2.3)",
          "bbox": [
            394.9801025390625,
            348.865234375,
            549.0068969726562,
            368.0196838378906
          ],
          "font_info": {
            "font": "CMEX10",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "When both |S| and |X| are finite, the Q-function can be represented as an |S| × |X| matrix, which",
          "bbox": [
            81.01599884033203,
            389.0867919921875,
            547.9207153320312,
            401.1866149902344
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.848934173583984,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "is often referred to as the Q-matrix.",
          "bbox": [
            64.08000183105469,
            406.7295227050781,
            235.85467529296875,
            417.6386413574219
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "2.2\nQ-Learning Algorithm",
          "bbox": [
            64.08000183105469,
            439.4087829589844,
            215.22958374023438,
            451.3639831542969
          ],
          "font_info": {
            "font": "URWPalladioL-Bold",
            "size": 11.9552001953125,
            "color": 0,
            "flags": 20
          }
        },
        {
          "text": "If agent i possessed knowledge of its Q-matrix, determining the optimal actions for any given state",
          "bbox": [
            64.08000183105469,
            464.1964416503906,
            547.9190673828125,
            475.30389404296875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.941778182983398,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "s would be straightforward. In essence, Q-learning estimates the Q-matrix when the conditional",
          "bbox": [
            64.21600341796875,
            480.6314392089844,
            547.9186401367188,
            491.7603454589844
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "distribution E [·|s, xi] and off-equilibrium observations (s, xi) are limited. By design, the Q-learning\nalgorithm addresses both challenges simultaneously: it uses the law of large numbers to learn the\nunderlying distribution from repeated experiences, while its trial-and-error experiments generates",
          "bbox": [
            64.08000183105469,
            496.04779052734375,
            547.9244384765625,
            541.0571899414062
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.925451278686523,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "counterfactual outcomes for state-action pairs that may not occur along the equilibrium path.",
          "bbox": [
            64.08000183105469,
            546.5615234375,
            517.4405517578125,
            557.4706420898438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Agent i’s iterative experimentation begins with an arbitrary initial estimated Q-matrix, bQi,0, and",
          "bbox": [
            81.01599884033203,
            562.8074340820312,
            547.9193725585938,
            581.0473022460938
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.91455364227295,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "recursively updates it from bQi,t to bQi,t+1 in iteration t + 1 as follows:",
          "bbox": [
            64.08000183105469,
            578.37109375,
            395.53753662109375,
            597.4822998046875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "bQi,t+1(st, xi,t) = (1 −α) bQi,t(st, xi,t)\n|\n{z\n}\nPast knowledge",
          "bbox": [
            139.59793090820312,
            611.4707641601562,
            309.4562072753906,
            640.7662963867188
          ],
          "font_info": {
            "font": "CMEX10",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "+ α\n\u0014\nπi,t + ρ max\nx′∈X\nbQi,t(st+1, x′)\n\u0015\n,\n|\n{z\n}\nNew information from experimentation",
          "bbox": [
            311.4110107421875,
            604.4331665039062,
            472.64739990234375,
            647.9793090820312
          ],
          "font_info": {
            "font": "CMR10",
            "size": 11.367300033569336,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "(2.4)",
          "bbox": [
            528.1090087890625,
            612.6795043945312,
            549.0108642578125,
            623.588623046875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "where α ∈[0, 1] captures the forgetting rate.6 Upon agent i choosing action xi,t in state st and",
          "bbox": [
            63.62200164794922,
            660.9666748046875,
            547.9204711914062,
            677.8623046875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "observing the payoff πi,t, the update from bQi,t to bQi,t+1 at the pair (st, xi,t) occurs immediately after",
          "bbox": [
            64.08000183105469,
            680.3790893554688,
            548.1396484375,
            699.4902954101562
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.941778182983398,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "6The forgetting rate α determines how quickly past experiments are discounted. For consistent learning, α must decay\nto zero to ensure convergence of the estimated Q-matrix bQi,t as t grows large. A smaller α improves asymptotic accuracy\nbut slows convergence, reflecting a higher learning capacity at the expense of greater computational cost.",
          "bbox": [
            64.08000183105469,
            702.2026977539062,
            548.2678833007812,
            736.0731201171875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 6.973800182342529,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "9",
          "bbox": [
            303.27301025390625,
            765.1044921875,
            308.7275695800781,
            776.0136108398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        }
      ]
    },
    {
      "page_number": 12,
      "text": "the next state st+1 is drawn from the Markov transition distribution at the beginning of iteration t + 1,\nconditional on the state st, the chosen action xi,t, and the collective actions of all agents in iteration t.\nEquation (2.4) indicates that for agent i in iteration t + 1, only the value of the estimated Q-\nmatrix bQi,t(s, x) corresponding to the state-action pair (st, xi,t) is updated to bQi,t+1(st, xi,t). All other\nstate-action pairs remain unchanged. In other words, bQi,t+1(s, x) = bQi,t(s, x) for cases where s ̸= st\nor x ̸= xi,t. The updated value bQi,t+1(st, xi,t) is computed as a weighted average of accumulated\nknowledge based on the previous experiments, bQi,t(st, xi,t), and learning based on a new experiment,\nπi,t + ρ maxx′∈X bQi,t(st+1, x′). A key distinction between the Q-learning recursive algorithm (2.4)\nand the Bellman recursive equation (2.1) lies in how they treat expectations for future payoffs and\ncontinuation Q-values. Q-learning algorithm (2.4) does not form expectations about the continuation\nvalue because the Markovian transition probabilities from st to st+1 are unknown. Instead, it updates\nthe Q-value using the actual realized payoff and the maximum Q-value of the randomly realized\nstate st+1 at the beginning of iteration t + 1.\nIt is crucial to note that the forgetting rate α plays a significant role in the Q-learning algorithm,\nbalancing past knowledge with new information from experimentation. A higher α not only indicates\na greater impact of present learning on the Q-value update but also implies that the algorithm forgets\npast knowledge more quickly, potentially leading to biased learning. To elaborate intuitively, let τ be\nthe number of times that the Q-value of the state-action pair (s, x) has been updated in the past. As\nτ →∞, the estimated Q-value of (s, x) is approximately equal to\nbQi,tτ+1(s, x) ≈\nτ−1\n∑\nh=0\nα(1 −α)h\n\u0014\nπi,tτ−h + ρ max\nx′∈X\nbQi,tτ−h\n\u0000stτ−h+1, x′\u0001\u0015\n,\n(2.5)\nwhere th represents the period in which the estimated Q-value of (s, x) receives the h-th update.\nClearly, when α is not close to 0, the weights α(1 −α)h decay rapidly as τ increases, diminishing\nthe influence of past data. This weakens the applicability of the law of large numbers, leading to\nsubstantial bias in estimating E[·|s, xi] for future payoffs and continuation Q-values. Conversely,\na smaller α slows the decay, preserving more past information and reducing bias. However, this\nrequires significantly more iterations to achieve convergence, increasing computational costs.\n2.3\nExperimentation\nUpon state st being realized at the beginning of iteration t, agent i chooses an action xi,t, at the end of\nthe iteration, according to either an exploitation or exploration mode, as follows:\nxi,t =\n(\nargmaxx∈X bQi,t(st, x),\nwith prob. 1 −εt,\n(exploitation)\nex ∼uniform distribution on X,\nwith prob. εt.\n(exploration)\n(2.6)\nTo determine the mode, we employ the simple ε-greedy method. As outlined in equation (2.6), after\nthe state st is realized in iteration t, agent i follows either the exploration or exploitation mode with\nexogenous probabilities εt and 1 −εt, respectively. In the exploitation mode, agent i chooses its action\nto maximize the estimated Q-value based on st in iteration t, given by xi,t = argmaxx∈X bQi,t(st, x). In\ncontrast, in the exploration mode, agent i randomly chooses its action ex from the set of all possible\n10\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "the next state st+1 is drawn from the Markov transition distribution at the beginning of iteration t + 1,",
          "bbox": [
            64.08000183105469,
            51.03412628173828,
            549.2837524414062,
            64.78361511230469
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "conditional on the state st, the chosen action xi,t, and the collective actions of all agents in iteration t.\nEquation (2.4) indicates that for agent i in iteration t + 1, only the value of the estimated Q-",
          "bbox": [
            64.08000183105469,
            68.34142303466797,
            549.7312622070312,
            95.90532684326172
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.870850563049316,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "matrix bQi,t(s, x) corresponding to the state-action pair (st, xi,t) is updated to bQi,t+1(st, xi,t). All other\nstate-action pairs remain unchanged. In other words, bQi,t+1(s, x) = bQi,t(s, x) for cases where s ̸= st\nor x ̸= xi,t. The updated value bQi,t+1(st, xi,t) is computed as a weighted average of accumulated",
          "bbox": [
            64.08000183105469,
            100.34009552001953,
            548.1341552734375,
            152.32127380371094
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.91455364227295,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "knowledge based on the previous experiments, bQi,t(st, xi,t), and learning based on a new experiment,",
          "bbox": [
            64.08000183105469,
            149.64508056640625,
            549.2835693359375,
            168.7562713623047
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.810471534729004,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "πi,t + ρ maxx′∈X bQi,t(st+1, x′). A key distinction between the Q-learning recursive algorithm (2.4)\nand the Bellman recursive equation (2.1) lies in how they treat expectations for future payoffs and",
          "bbox": [
            64.08000183105469,
            164.40579223632812,
            549.0084838867188,
            194.51531982421875
          ],
          "font_info": {
            "font": "PazoMath-Italic",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "continuation Q-values. Q-learning algorithm (2.4) does not form expectations about the continuation",
          "bbox": [
            64.08000183105469,
            200.06649780273438,
            547.9234008789062,
            210.8989715576172
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.832467079162598,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "value because the Markovian transition probabilities from st to st+1 are unknown. Instead, it updates\nthe Q-value using the actual realized payoff and the maximum Q-value of the randomly realized",
          "bbox": [
            63.775001525878906,
            216.25743103027344,
            547.92236328125,
            243.82135009765625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.815974235534668,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "state st+1 at the beginning of iteration t + 1.",
          "bbox": [
            64.08000183105469,
            248.256103515625,
            275.9388427734375,
            262.03564453125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "It is crucial to note that the forgetting rate α plays a significant role in the Q-learning algorithm,",
          "bbox": [
            81.01599884033203,
            265.7242126464844,
            549.281005859375,
            277.54718017578125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.94721508026123,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "balancing past knowledge with new information from experimentation. A higher α not only indicates",
          "bbox": [
            64.08000183105469,
            282.2651672363281,
            547.9241943359375,
            293.982177734375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "a greater impact of present learning on the Q-value update but also implies that the algorithm forgets",
          "bbox": [
            64.08000183105469,
            298.7001647949219,
            547.9188232421875,
            309.4996337890625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "past knowledge more quickly, potentially leading to biased learning. To elaborate intuitively, let τ be",
          "bbox": [
            63.75299835205078,
            315.11248779296875,
            547.9195556640625,
            326.8531799316406
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.832467079162598,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "the number of times that the Q-value of the state-action pair (s, x) has been updated in the past. As",
          "bbox": [
            64.08000183105469,
            330.4320983886719,
            547.9220581054688,
            342.40008544921875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.903643608093262,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "τ →∞, the estimated Q-value of (s, x) is approximately equal to",
          "bbox": [
            64.21600341796875,
            346.71978759765625,
            378.1546325683594,
            359.7231750488281
          ],
          "font_info": {
            "font": "PazoMath-Italic",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "bQi,tτ+1(s, x) ≈\nτ−1\n∑\nh=0\nα(1 −α)h\n\u0014\nπi,tτ−h + ρ max\nx′∈X\nbQi,tτ−h\n\u0000\nstτ−h+1, x′\u0001\u0015\n,\n(2.5)",
          "bbox": [
            153.88999938964844,
            373.1828308105469,
            549.010009765625,
            405.58734130859375
          ],
          "font_info": {
            "font": "CMEX10",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "where th represents the period in which the estimated Q-value of (s, x) receives the h-th update.\nClearly, when α is not close to 0, the weights α(1 −α)h decay rapidly as τ increases, diminishing\nthe influence of past data. This weakens the applicability of the law of large numbers, leading to\nsubstantial bias in estimating E[·|s, xi] for future payoffs and continuation Q-values. Conversely,\na smaller α slows the decay, preserving more past information and reducing bias. However, this",
          "bbox": [
            63.62200164794922,
            418.4870910644531,
            549.8291015625,
            497.08416748046875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "requires significantly more iterations to achieve convergence, increasing computational costs.",
          "bbox": [
            64.08000183105469,
            501.7235107421875,
            516.1312255859375,
            512.6326293945312
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "2.3\nExperimentation",
          "bbox": [
            64.08000183105469,
            534.4037475585938,
            182.20932006835938,
            546.3589477539062
          ],
          "font_info": {
            "font": "URWPalladioL-Bold",
            "size": 11.9552001953125,
            "color": 0,
            "flags": 20
          }
        },
        {
          "text": "Upon state st being realized at the beginning of iteration t, agent i chooses an action xi,t, at the end of",
          "bbox": [
            64.08000183105469,
            559.1904296875,
            547.9176025390625,
            571.8945922851562
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "the iteration, according to either an exploitation or exploration mode, as follows:",
          "bbox": [
            64.08000183105469,
            575.8155517578125,
            455.9894104003906,
            586.7246704101562
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "xi,t =",
          "bbox": [
            119.89199829101562,
            611.2940673828125,
            145.25177001953125,
            624.5794067382812
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "(\nargmaxx∈X bQi,t(st, x),\nwith prob. 1 −εt,\n(exploitation)\nex ∼uniform distribution on X,\nwith prob. εt.\n(exploration)\n(2.6)",
          "bbox": [
            148.5469970703125,
            600.836181640625,
            549.0108642578125,
            639.0242919921875
          ],
          "font_info": {
            "font": "CMEX10",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "To determine the mode, we employ the simple ε-greedy method. As outlined in equation (2.6), after",
          "bbox": [
            63.742000579833984,
            648.2562866210938,
            548.1363525390625,
            660.0401611328125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.89272403717041,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "the state st is realized in iteration t, agent i follows either the exploration or exploitation mode with",
          "bbox": [
            64.08000183105469,
            664.4904174804688,
            547.9242553710938,
            677.224609375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "exogenous probabilities εt and 1 −εt, respectively. In the exploitation mode, agent i chooses its action",
          "bbox": [
            64.08000183105469,
            679.90673828125,
            547.9183959960938,
            693.6286010742188
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "to maximize the estimated Q-value based on st in iteration t, given by xi,t = argmaxx∈X bQi,t(st, x). In\ncontrast, in the exploration mode, agent i randomly chooses its action ex from the set of all possible",
          "bbox": [
            64.08000183105469,
            696.4890747070312,
            547.9248046875,
            732.0352783203125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.854416847229004,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "10",
          "bbox": [
            300.5450134277344,
            765.1044921875,
            311.4541320800781,
            776.0136108398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        }
      ]
    },
    {
      "page_number": 13,
      "text": "values in X, each with equal probability.7 Exploration enables the algorithm to experiment with\nactions that appear suboptimal under the estimated Q-values, bQi,t, in iteration t. Sufficient exploration\nis crucial for accurately approximating the true Q-matrix and mitigating learning bias, as it ensures\nthat all state-action pairs are sufficiently sampled, especially in complex environments. However, this\ncomes with a tradeoff: while it enhances learning accuracy, it also increases computational burden\nand introduces noise, which can hinder convergence in multi-agent settings. To manage this tradeoff,\nthe exploration probability εt is set to decrease monotonically toward zero as t increases.\nWe focus on asynchronous learning, defined by (2.4) and (2.6), which requires no knowledge of the\nunderlying economic environment or information structure. In contrast, model-based synchronous\nlearning updates all (s, x) pairs simultaneously in each iteration, assuming precise knowledge of the\nenvironment’s structure, such as transition probabilities and payoff functions (e.g., Asker, Fershtman\nand Pakes, 2022, 2024). Model-based approaches are typically vulnerable to misspecification.\n3\nModel and Laboratory Design\nTo set up the laboratory for our simulation experiments, we develop a model that incorporates only the\nminimal set of ingredients necessary to capture the economic context of securities trading and reveal\nkey insights. Our model builds on the influential framework of Kyle (1985), highlighting financial\nmarkets as mechanisms for information aggregation, facilitated by market makers’ price discovery.\nThis mechanism compels informed speculators to trade conservatively on private signals, thereby\nkeeping price informativeness sufficiently low to preserve information rents. This informational\nperspective, central to financial market competition, goes beyond the traditional focus on product\nmarket competition among pricing algorithms (e.g., Calvano et al., 2020).\nSpecifically, our model introduces two deviations from the Kyle (1985) baseline framework. First,\nwe consider a setting with oligopolistic informed speculators in a repeated trading environment,\nengaging in trading different short-lived assets from one period to the next, rather than a single in-\nformed speculator operating in a one-period market.8 Second, we incorporate information-insensitive\ninvestors (e.g., Kyle and Xiong, 2001; Vayanos and Vila, 2021) and market makers with inventory cost\nconsiderations. Together, these elements expand upon the efficient pricing baseline model of Kyle\n(1985) by introducing potential price inefficiencies.\n3.1\nEconomic Environment\nModel Setup.\nTime is discrete, indexed by t = 1, 2, ..., and runs forever. There are I ≥2 risk-neutral\ninformed speculators, indexed by i ∈{1, · · · , I}, a representative noise trader, a representative\ninformation-insensitive investor, and a representative market maker. The environment is stationary,\nand all exogenous shocks are independent and identically distributed across periods.\nIn each period t, a short-lived asset is traded, reaching expiration at the end of the period with\nits fundamental value vt realized. The fundamental value vt is distributed as N(v, σ2\nv), where we\n7For simplicity, we use a uniform distribution, though smarter choices could improve Q-learning.\n8Our repeated trading setup is distinct from a multi-round dynamic trading framework involving a long-term asset\ntraded within a relatively prolonged period (e.g., Kyle, 1985; Holden and Subrahmanyam, 1992; Rostek and Weretka, 2015).\n11\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "values in X, each with equal probability.7 Exploration enables the algorithm to experiment with",
          "bbox": [
            63.775001525878906,
            48.05668258666992,
            547.9232788085938,
            63.03435516357422
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "actions that appear suboptimal under the estimated Q-values, bQi,t, in iteration t. Sufficient exploration",
          "bbox": [
            64.08000183105469,
            68.34142303466797,
            547.924072265625,
            86.58128356933594
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "is crucial for accurately approximating the true Q-matrix and mitigating learning bias, as it ensures",
          "bbox": [
            64.08000183105469,
            84.96161651611328,
            547.9237670898438,
            95.87616729736328
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.91455364227295,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "that all state-action pairs are sufficiently sampled, especially in complex environments. However, this\ncomes with a tradeoff: while it enhances learning accuracy, it also increases computational burden",
          "bbox": [
            64.08000183105469,
            101.47520446777344,
            547.92236328125,
            128.76461791992188
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.80496597290039,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "and introduces noise, which can hinder convergence in multi-agent settings. To manage this tradeoff,",
          "bbox": [
            64.08000183105469,
            134.33335876464844,
            549.2815551757812,
            145.1548309326172
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.8214750289917,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "the exploration probability εt is set to decrease monotonically toward zero as t increases.",
          "bbox": [
            64.08000183105469,
            150.5164031982422,
            494.8924865722656,
            163.2516326904297
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "We focus on asynchronous learning, defined by (2.4) and (2.6), which requires no knowledge of the",
          "bbox": [
            81.01599884033203,
            167.21914672851562,
            547.9203491210938,
            178.0186004638672
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "underlying economic environment or information structure. In contrast, model-based synchronous",
          "bbox": [
            64.08000183105469,
            183.5520782470703,
            547.9151611328125,
            194.4938507080078
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.941778182983398,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "learning updates all (s, x) pairs simultaneously in each iteration, assuming precise knowledge of the",
          "bbox": [
            64.08000183105469,
            198.95111083984375,
            547.9182739257812,
            210.90518188476562
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.854416847229004,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "environment’s structure, such as transition probabilities and payoff functions (e.g., Asker, Fershtman",
          "bbox": [
            64.08000183105469,
            216.49362182617188,
            547.9237060546875,
            227.33706665039062
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.843446731567383,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "and Pakes, 2022, 2024). Model-based approaches are typically vulnerable to misspecification.",
          "bbox": [
            64.08000183105469,
            232.8815460205078,
            515.4005126953125,
            243.79063415527344
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 856203,
            "flags": 4
          }
        },
        {
          "text": "3\nModel and Laboratory Design",
          "bbox": [
            64.08000183105469,
            269.9357604980469,
            285.1119384765625,
            284.281982421875
          ],
          "font_info": {
            "font": "URWPalladioL-Bold",
            "size": 14.346199989318848,
            "color": 0,
            "flags": 20
          }
        },
        {
          "text": "To set up the laboratory for our simulation experiments, we develop a model that incorporates only the",
          "bbox": [
            63.742000579833984,
            300.8221435546875,
            547.9229736328125,
            311.62158203125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "minimal set of ingredients necessary to capture the economic context of securities trading and reveal\nkey insights. Our model builds on the influential framework of Kyle (1985), highlighting financial\nmarkets as mechanisms for information aggregation, facilitated by market makers’ price discovery.\nThis mechanism compels informed speculators to trade conservatively on private signals, thereby\nkeeping price informativeness sufficiently low to preserve information rents. This informational\nperspective, central to financial market competition, goes beyond the traditional focus on product",
          "bbox": [
            63.742000579833984,
            317.22955322265625,
            549.834228515625,
            410.2943420410156
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.837958335876465,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "market competition among pricing algorithms (e.g., Calvano et al., 2020).",
          "bbox": [
            64.08000183105469,
            415.7895202636719,
            419.19305419921875,
            426.6986389160156
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Specifically, our model introduces two deviations from the Kyle (1985) baseline framework. First,\nwe consider a setting with oligopolistic informed speculators in a repeated trading environment,\nengaging in trading different short-lived assets from one period to the next, rather than a single in-",
          "bbox": [
            63.62200164794922,
            432.2558898925781,
            549.7323608398438,
            476.01849365234375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.865375518798828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "formed speculator operating in a one-period market.8 Second, we incorporate information-insensitive",
          "bbox": [
            64.08000183105469,
            477.649169921875,
            547.9176025390625,
            492.40863037109375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "investors (e.g., Kyle and Xiong, 2001; Vayanos and Vila, 2021) and market makers with inventory cost\nconsiderations. Together, these elements expand upon the efficient pricing baseline model of Kyle",
          "bbox": [
            64.08000183105469,
            498.0441589355469,
            547.9202270507812,
            525.3388061523438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "(1985) by introducing potential price inefficiencies.",
          "bbox": [
            63.720001220703125,
            530.8355102539062,
            309.44744873046875,
            541.74462890625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "3.1\nEconomic Environment",
          "bbox": [
            64.08000183105469,
            563.5157470703125,
            219.31826782226562,
            575.470947265625
          ],
          "font_info": {
            "font": "URWPalladioL-Bold",
            "size": 11.9552001953125,
            "color": 0,
            "flags": 20
          }
        },
        {
          "text": "Model Setup.\nTime is discrete, indexed by t = 1, 2, ..., and runs forever. There are I ≥2 risk-neutral\ninformed speculators, indexed by i ∈{1, · · · , I}, a representative noise trader, a representative",
          "bbox": [
            64.08000183105469,
            587.2837524414062,
            547.9238891601562,
            615.8673095703125
          ],
          "font_info": {
            "font": "URWPalladioL-BoldItal",
            "size": 10.854416847229004,
            "color": 0,
            "flags": 22
          }
        },
        {
          "text": "information-insensitive investor, and a representative market maker. The environment is stationary,",
          "bbox": [
            64.08000183105469,
            621.346923828125,
            549.2863159179688,
            632.27783203125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.930895805358887,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "and all exogenous shocks are independent and identically distributed across periods.\nIn each period t, a short-lived asset is traded, reaching expiration at the end of the period with\nits fundamental value vt realized. The fundamental value vt is distributed as N(v, σ2\nv), where we",
          "bbox": [
            64.08000183105469,
            637.7974853515625,
            547.9241333007812,
            683.3021240234375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "7For simplicity, we use a uniform distribution, though smarter choices could improve Q-learning.\n8Our repeated trading setup is distinct from a multi-round dynamic trading framework involving a long-term asset\ntraded within a relatively prolonged period (e.g., Kyle, 1985; Holden and Subrahmanyam, 1992; Rostek and Weretka, 2015).",
          "bbox": [
            64.08000183105469,
            691.1327514648438,
            547.9226684570312,
            724.233642578125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 6.973800182342529,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "11",
          "bbox": [
            300.5450134277344,
            765.1044921875,
            311.4541320800781,
            776.0136108398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        }
      ]
    },
    {
      "page_number": 14,
      "text": "set v ≡σv ≡1 for simplicity.9 The noise trader’s order flow ut is distributed as N(0, σ2\nu), where σu\ndenotes the magnitude of noise trading risk.\nEach informed speculator i knows vt perfectly but does not observe the noise trader’s order flow\nut when submitting a trade. Speculators understand that their order flow xi,t influences the market\nprice pt by altering the total order flow, thereby (i) shifting the market-clearing condition and (ii)\npartially revealing their private signals about vt to other participants in the asset market. Specifically,\ninformed speculator i solves:\nVi(st) = max\nxi,t E [(vt −pt)xi,t + ρVi(st+1)|st, xi,t] ,\n(3.1)\nwhere Vi(st) denotes the optimal value function of speculator i in state st, achieved by selecting\nthe best trading order flow xi,t. The term (vt −pt)xi,t represents the trading profit (or loss), while\nρVi(st+1) is the discounted continuation value for the next-period state st+1, with ρ ∈(0, 1) being the\nsubjective discount factor.\nIn equation (3.1), the state variable st encapsulates all relevant information required for informed\nspeculators’ decision-making. Specifically, st includes variables such as vt, vt−1, pt−1, yt−1, zt−1, as\nwell as other historical variables if necessary. The quantity yt ≡∑I\ni=1 xi,t + ut is the total order flow,\nconsisting of order flows from both informed speculators and noise traders. Although yt becomes\nobservable after all trades from informed speculators and noise traders are submitted in period t, its\ncomponents cannot be separately identified, making it impossible to distinguish the informed order\nflow from the noise trading flow. The quantity zt is the demand of information-insensitive investors,\nwhose collective demand curve is given by:\nzt = −ξ(pt −v), with ξ ≥0.\n(3.2)\nThe same specification is adopted by Kyle and Xiong (2001), who justify it through the optimal\nportfolio choice made by a rational yet information-insensitive investor under certain assumptions.10\nThese investors can be rational, even though they do not infer fundamental information from the\nmarket price pt or others’ trading behaviors, unlike the rational-expectations uninformed investors in\nthe models of Grossman and Stiglitz (1980) and Kyle (1989). As discussed in Kyle and Xiong (2001),\nthe logic behind specification (3.2) is straightforward: the information-insensitive investor, focusing\non the ex-ante expected fundamental value v, buys more as pt −v becomes more negative, perceiving\nthe asset as undervalued. Including information-insensitive investors in a noisy rational expectations\nframework is intended to capture relevant institutional frictions and rigid, technical-analysis-driven\ntrading responses to price reversal signals.11\nTrading occurs through the market maker, who sets the market price pt to absorb order flow while\nminimizing inventory costs and pricing errors. Specifically, the market maker observes the total order\n9For conciseness, the notations v and σv will be omitted in this manuscript when not needed for comprehension.\n10To derive the functional form of the aggregate demand curve of information-insensitive investors, one approach is to\nassume CARA utility maximization without any learning or strategic trading, as detailed in Online Appendix 2.1. Studies\nindicate that information-insensitive investors with low price elasticity of demand play an important role in shaping asset\nprices (e.g., Greenwood and Vayanos, 2014; Vayanos and Vila, 2021; Greenwood et al., 2023).\n11This approach has been commonly adopted in the literature (e.g., Hellwig, Mukherji and Tsyvinski, 2006; Goldstein,\nOzdenoren and Yuan, 2013).\n12\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "set v ≡σv ≡1 for simplicity.9 The noise trader’s order flow ut is distributed as N(0, σ2\nu), where σu\ndenotes the magnitude of noise trading risk.",
          "bbox": [
            64.07998657226562,
            48.05668258666992,
            547.3223876953125,
            79.43968963623047
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Each informed speculator i knows vt perfectly but does not observe the noise trader’s order flow",
          "bbox": [
            81.01599884033203,
            84.77642059326172,
            548.3817138671875,
            97.49669647216797
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.85989761352539,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "ut when submitting a trade. Speculators understand that their order flow xi,t influences the market\nprice pt by altering the total order flow, thereby (i) shifting the market-clearing condition and (ii)",
          "bbox": [
            63.75299835205078,
            101.21141815185547,
            549.015869140625,
            130.41131591796875
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "partially revealing their private signals about vt to other participants in the asset market. Specifically,",
          "bbox": [
            63.75299835205078,
            134.08140563964844,
            549.2872924804688,
            146.79393005371094
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.832467079162598,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "informed speculator i solves:",
          "bbox": [
            64.08000183105469,
            150.5164031982422,
            204.3600311279297,
            161.61460876464844
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Vi(st) = max\nxi,t E [(vt −pt)xi,t + ρVi(st+1)|st, xi,t] ,\n(3.1)",
          "bbox": [
            192.3509979248047,
            179.22579956054688,
            549.0146484375,
            198.67083740234375
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "where Vi(st) denotes the optimal value function of speculator i in state st, achieved by selecting\nthe best trading order flow xi,t. The term (vt −pt)xi,t represents the trading profit (or loss), while",
          "bbox": [
            63.62200164794922,
            212.43609619140625,
            547.9213256835938,
            242.79034423828125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "ρVi(st+1) is the discounted continuation value for the next-period state st+1, with ρ ∈(0, 1) being the",
          "bbox": [
            64.21600341796875,
            245.15975952148438,
            547.9189453125,
            258.25531005859375
          ],
          "font_info": {
            "font": "PazoMath-Italic",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "subjective discount factor.",
          "bbox": [
            64.08000183105469,
            262.802490234375,
            189.3710174560547,
            273.71160888671875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "In equation (3.1), the state variable st encapsulates all relevant information required for informed\nspeculators’ decision-making. Specifically, st includes variables such as vt, vt−1, pt−1, yt−1, zt−1, as\nwell as other historical variables if necessary. The quantity yt ≡∑I\ni=1 xi,t + ut is the total order flow,\nconsisting of order flows from both informed speculators and noise traders. Although yt becomes",
          "bbox": [
            63.62200164794922,
            279.0484313964844,
            549.2797241210938,
            341.1177978515625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.843446731567383,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "observable after all trades from informed speculators and noise traders are submitted in period t, its",
          "bbox": [
            64.08000183105469,
            344.7894287109375,
            547.9251098632812,
            355.8721618652344
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.854416847229004,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "components cannot be separately identified, making it impossible to distinguish the informed order",
          "bbox": [
            64.08000183105469,
            361.42919921875,
            548.1365356445312,
            372.3164367675781
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.887259483337402,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "flow from the noise trading flow. The quantity zt is the demand of information-insensitive investors,",
          "bbox": [
            64.08000183105469,
            377.659423828125,
            549.2823486328125,
            390.3827819824219
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.870850563049316,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "whose collective demand curve is given by:",
          "bbox": [
            63.62200164794922,
            394.28350830078125,
            274.4621887207031,
            405.192626953125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "zt = −ξ(pt −v), with ξ ≥0.\n(3.2)",
          "bbox": [
            235.24398803710938,
            422.80377197265625,
            549.0166015625,
            435.95538330078125
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "The same specification is adopted by Kyle and Xiong (2001), who justify it through the optimal",
          "bbox": [
            63.742000579833984,
            453.6616516113281,
            547.92333984375,
            464.6793212890625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "portfolio choice made by a rational yet information-insensitive investor under certain assumptions.10",
          "bbox": [
            63.75299835205078,
            468.3232421875,
            547.422119140625,
            481.0660400390625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.843446731567383,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "These investors can be rational, even though they do not infer fundamental information from the",
          "bbox": [
            63.742000579833984,
            486.53265380859375,
            547.92333984375,
            497.5503234863281
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "market price pt or others’ trading behaviors, unlike the rational-expectations uninformed investors in",
          "bbox": [
            64.08000183105469,
            502.8564147949219,
            547.9188232421875,
            515.5596313476562
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "the models of Grossman and Stiglitz (1980) and Kyle (1989). As discussed in Kyle and Xiong (2001),",
          "bbox": [
            64.08000183105469,
            519.48828125,
            549.2825927734375,
            530.386474609375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.898184776306152,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "the logic behind specification (3.2) is straightforward: the information-insensitive investor, focusing",
          "bbox": [
            64.08000183105469,
            535.90380859375,
            547.916748046875,
            546.8292846679688
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.925451278686523,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "on the ex-ante expected fundamental value v, buys more as pt −v becomes more negative, perceiving",
          "bbox": [
            64.08000183105469,
            551.1427612304688,
            547.919189453125,
            564.1470336914062
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "the asset as undervalued. Including information-insensitive investors in a noisy rational expectations",
          "bbox": [
            64.08000183105469,
            568.848388671875,
            547.9182739257812,
            579.6698608398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.8214750289917,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "framework is intended to capture relevant institutional frictions and rigid, technical-analysis-driven",
          "bbox": [
            64.08000183105469,
            585.2254028320312,
            547.9160766601562,
            596.1290893554688
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.903643608093262,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "trading responses to price reversal signals.11",
          "bbox": [
            64.08000183105469,
            599.8042602539062,
            278.60211181640625,
            612.5656127929688
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Trading occurs through the market maker, who sets the market price pt to absorb order flow while",
          "bbox": [
            81.01599884033203,
            617.9024047851562,
            547.9171142578125,
            630.6056518554688
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "minimizing inventory costs and pricing errors. Specifically, the market maker observes the total order",
          "bbox": [
            64.08000183105469,
            634.6051025390625,
            548.1433715820312,
            645.4046020507812
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "9For conciseness, the notations v and σv will be omitted in this manuscript when not needed for comprehension.\n10To derive the functional form of the aggregate demand curve of information-insensitive investors, one approach is to\nassume CARA utility maximization without any learning or strategic trading, as detailed in Online Appendix 2.1. Studies\nindicate that information-insensitive investors with low price elasticity of demand play an important role in shaping asset\nprices (e.g., Greenwood and Vayanos, 2014; Vayanos and Vila, 2021; Greenwood et al., 2023).\n11This approach has been commonly adopted in the literature (e.g., Hellwig, Mukherji and Tsyvinski, 2006; Goldstein,\nOzdenoren and Yuan, 2013).",
          "bbox": [
            63.81100082397461,
            655.2317504882812,
            549.0380859375,
            732.610107421875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 6.973800182342529,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "12",
          "bbox": [
            300.54498291015625,
            765.1044921875,
            311.4541015625,
            776.0136108398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        }
      ]
    },
    {
      "page_number": 15,
      "text": "flow, yt, from informed speculators and the noise trader, as well as the order flow schedule, zt, of\ninformation-insensitive investors, which is a deterministic function of the market price pt, specified\nin (3.2). Given this information, the market maker sets pt to minimize inventory costs and pricing\nerrors, solving the following objective function:\nmin\npt E\n\u0014\n(yt + zt)2 + θ(pt −vt)2\n\f\f\f\fyt\n\u0015\n,\n(3.3)\nwhere θ > 0 represents the weight that the market maker places on minimizing pricing errors. Here,\nE [·|yt] denotes the market maker’s expectation over vt, conditioned on the observed combined order\nflow yt and its understanding of the behavior of informed speculators in equilibrium.\nTo clear the market, the market maker assumes the position −(yt + zt), incurring quadratic\ninventory costs, (yt + zt)2, consistent with the existing literature, such as Mildenstein and Schleef\n(1983). The term θ(pt −vt)2 reflects the market maker’s attempt to minimize pricing errors due\nto asymmetric information. The parameter θ acts as a reduced-form measure of the benefits from\nreducing these errors, such as attracting greater trading flows. The first-order condition leads to\npt =\nξ\nξ2 + θ yt +\nξ2\nξ2 + θ v +\nθ\nξ2 + θ E [vt|yt] .\n(3.4)\nIn our analyses, we treat θ as a universally fixed, positive constant with a tiny magnitude. By fixing\nθ, we exclude it from the comparative-static analysis. With a positive constant θ, our model gains\nconceptual coherence by offering two meaningful extreme benchmarks. As ξ approaches infinity, the\nprice pt converges to v + ξ−1yt, determined by the market clearing condition yt + zt = 0, as in Kyle\nand Xiong (2001). Conversely, as ξ decreases towards zero, pt shifts to the efficient price E[vt|yt],\nas in Kyle (1985).12 Incorporating the market maker captures financial markets as mechanisms for\naggregating information, where sophisticated players infer fundamental values from the collective\nactions of others, integrating this information into the market price, as highlighted by Kyle (1985).\nInterpreting the Model through a Specific Market Setting.\nOur model reflects realistic market\nenvironments, particularly those involving quantitative hedge funds and proprietary trading firms\noperating at increasingly short horizons. While the theoretical framework applies broadly to real-\nworld settings, we anchor our simulation experiments in a concrete example to illustrate the economic\nrelevance of AI-driven trading algorithms. In each period t, a new short-lived security is introduced\nand traded, such as a close-to-maturity option or futures contract. These contracts expire at the end\nof the period, with their payoff equal to the fundamental value vt. Close-to-maturity derivatives are\namong the most actively traded across the maturity spectrum, making them a natural focal point for\nstudying algorithmic trading behavior.\nBelow, we elaborate on each of the four types of market participants in this concrete real-world\nexample. First, informed speculators, such as quantitative hedge funds and proprietary trading firms,\nspecialize in extracting private signals about the final payoff of close-to-maturity options and futures,\nvt, using proprietary or public data powered by advanced technologies.13 These informed speculators\n12Further discussions are provided in Online Appendix 2.1.\n13Conceptually, “private signals” here include not only information derived from proprietary sources but also predictive\n13\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "flow, yt, from informed speculators and the noise trader, as well as the order flow schedule, zt, of",
          "bbox": [
            64.08000183105469,
            51.90544509887695,
            547.9238891601562,
            63.671226501464844
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "information-insensitive investors, which is a deterministic function of the market price pt, specified\nin (3.2). Given this information, the market maker sets pt to minimize inventory costs and pricing",
          "bbox": [
            64.08000183105469,
            68.34142303466797,
            547.9185791015625,
            97.54131317138672
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.925451278686523,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "errors, solving the following objective function:",
          "bbox": [
            64.08000183105469,
            101.40052032470703,
            293.6838073730469,
            112.30962371826172
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "min\npt E\n\u0014\n(yt + zt)2 + θ(pt −vt)2\n\f\f\f\fyt",
          "bbox": [
            220.96600341796875,
            126.48120880126953,
            379.86907958984375,
            157.02732849121094
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "\u0015\n,\n(3.3)",
          "bbox": [
            380.60302734375,
            126.91230010986328,
            549.0079956054688,
            146.06675720214844
          ],
          "font_info": {
            "font": "CMEX10",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "where θ > 0 represents the weight that the market maker places on minimizing pricing errors. Here,",
          "bbox": [
            63.62200164794922,
            167.20611572265625,
            549.283203125,
            180.0622100830078
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.865375518798828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "E [·|yt] denotes the market maker’s expectation over vt, conditioned on the observed combined order",
          "bbox": [
            64.08000183105469,
            183.49380493164062,
            548.1414794921875,
            196.2771759033203
          ],
          "font_info": {
            "font": "PazoMathBlackboardBold",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 20
          }
        },
        {
          "text": "flow yt and its understanding of the behavior of informed speculators in equilibrium.\nTo clear the market, the market maker assumes the position −(yt + zt), incurring quadratic\ninventory costs, (yt + zt)2, consistent with the existing literature, such as Mildenstein and Schleef\n(1983). The term θ(pt −vt)2 reflects the market maker’s attempt to minimize pricing errors due\nto asymmetric information. The parameter θ acts as a reduced-form measure of the benefits from",
          "bbox": [
            63.720001220703125,
            200.9474334716797,
            547.9244384765625,
            278.67315673828125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "reducing these errors, such as attracting greater trading flows. The first-order condition leads to",
          "bbox": [
            64.08000183105469,
            283.3125,
            530.8040771484375,
            294.22161865234375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "pt =\nξ\nξ2 + θ yt +\nξ2",
          "bbox": [
            205.05599975585938,
            308.2402648925781,
            303.16802978515625,
            336.7571716308594
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "ξ2 + θ v +\nθ\nξ2 + θ E [vt|yt] .\n(3.4)",
          "bbox": [
            284.260009765625,
            310.9790954589844,
            549.0076904296875,
            336.7571716308594
          ],
          "font_info": {
            "font": "PazoMath-Italic",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "In our analyses, we treat θ as a universally fixed, positive constant with a tiny magnitude. By fixing",
          "bbox": [
            64.08000183105469,
            349.61346435546875,
            547.9175415039062,
            361.4051818847656
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.903643608093262,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "θ, we exclude it from the comparative-static analysis. With a positive constant θ, our model gains",
          "bbox": [
            64.21600341796875,
            365.9666748046875,
            547.9254760742188,
            377.8401794433594
          ],
          "font_info": {
            "font": "PazoMath-Italic",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "conceptual coherence by offering two meaningful extreme benchmarks. As ξ approaches infinity, the",
          "bbox": [
            64.08000183105469,
            382.5305480957031,
            547.9224853515625,
            394.2751770019531
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.837958335876465,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "price pt converges to v + ξ−1yt, determined by the market clearing condition yt + zt = 0, as in Kyle\nand Xiong (2001). Conversely, as ξ decreases towards zero, pt shifts to the efficient price E[vt|yt],\nas in Kyle (1985).12 Incorporating the market maker captures financial markets as mechanisms for\naggregating information, where sophisticated players infer fundamental values from the collective",
          "bbox": [
            63.75299835205078,
            396.1798400878906,
            549.2838134765625,
            459.1511535644531
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.94721508026123,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "actions of others, integrating this information into the market price, as highlighted by Kyle (1985).",
          "bbox": [
            64.08000183105469,
            464.655517578125,
            540.9713745117188,
            475.56463623046875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Interpreting the Model through a Specific Market Setting.\nOur model reflects realistic market\nenvironments, particularly those involving quantitative hedge funds and proprietary trading firms\noperating at increasingly short horizons. While the theoretical framework applies broadly to real-",
          "bbox": [
            64.08000183105469,
            497.3907165527344,
            549.7300415039062,
            541.5283203125
          ],
          "font_info": {
            "font": "URWPalladioL-BoldItal",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 22
          }
        },
        {
          "text": "world settings, we anchor our simulation experiments in a concrete example to illustrate the economic",
          "bbox": [
            63.62200164794922,
            547.1021118164062,
            547.9202270507812,
            557.901611328125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "relevance of AI-driven trading algorithms. In each period t, a new short-lived security is introduced",
          "bbox": [
            64.08000183105469,
            563.2704467773438,
            547.9199829101562,
            574.359375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.876322746276855,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "and traded, such as a close-to-maturity option or futures contract. These contracts expire at the end",
          "bbox": [
            64.08000183105469,
            579.8984375,
            547.9160766601562,
            590.8021240234375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.903643608093262,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "of the period, with their payoff equal to the fundamental value vt. Close-to-maturity derivatives are",
          "bbox": [
            64.08000183105469,
            596.1404418945312,
            547.917236328125,
            607.9051513671875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.898184776306152,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "among the most actively traded across the maturity spectrum, making them a natural focal point for",
          "bbox": [
            64.08000183105469,
            612.8037719726562,
            548.1362915039062,
            623.6581420898438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.854416847229004,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "studying algorithmic trading behavior.\nBelow, we elaborate on each of the four types of market participants in this concrete real-world",
          "bbox": [
            64.08000183105469,
            629.1995239257812,
            547.9219970703125,
            656.560546875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "example. First, informed speculators, such as quantitative hedge funds and proprietary trading firms,",
          "bbox": [
            64.08000183105469,
            662.1481323242188,
            549.2872314453125,
            672.9476318359375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "specialize in extracting private signals about the final payoff of close-to-maturity options and futures,",
          "bbox": [
            64.08000183105469,
            678.5673828125,
            549.28173828125,
            689.3888549804688
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.8214750289917,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "vt, using proprietary or public data powered by advanced technologies.13 These informed speculators",
          "bbox": [
            64.21600341796875,
            691.0591430664062,
            547.9249267578125,
            706.5161743164062
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "12Further discussions are provided in Online Appendix 2.1.\n13Conceptually, “private signals” here include not only information derived from proprietary sources but also predictive",
          "bbox": [
            72.74700164794922,
            715.6447143554688,
            547.9215087890625,
            737.7940063476562
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 6.973800182342529,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "13",
          "bbox": [
            300.5450134277344,
            765.1044921875,
            311.4541320800781,
            776.0136108398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        }
      ]
    },
    {
      "page_number": 16,
      "text": "typically operate with two teams: (i) a research team that generates private signals about vt, and (ii)\nan execution team that converts trading signals into strategically executed orders to maximize trading\nprofits. Like the structure of Kyle models, our framework assumes that valuable private signals\nare already available, while focusing on the strategic execution of trades based on these signals. In\nother words, the AI-powered trading algorithms analyzed in this article are those employed by the\nexecution team to convert private signals into strategic trading orders. These algorithms operate\nafter the research team has generated the signals and focus on optimizing execution based on their\ninformational content.\nSecond, information-insensitive investors, such as retail investors employing technical analysis\nand institutional investors seeking hold-to-maturity positions to hedge short-term risks, typically\nremain unresponsive to real-time fundamental information related to the terminal payoff vt of close-\nto-maturity options and futures. Retail investors using technical analysis base their trades strictly on\nobserved price patterns in the market (e.g., Lo and MacKinlay, 1999; Lo, Mamaysky and Wang, 2000;\nChen, Peng and Zhou, 2024). The demand specification (3.2) captures the essence of certain technical\nanalysis strategies, assuming that a positive spread pt −v indicates overbought conditions with prices\nlikely to fall, whereas a negative spread pt −v indicates oversold conditions with prices likely to rise.\nSpecifically, the demand specification captures technical analysis tools that provide signals for likely\nprice reversals. Additionally, information-insensitive investors include institutions such as pension\nfunds, insurance companies, and mutual funds, which may purchase close-to-maturity derivatives\nand hold them to expiration as hedges against near-term risks. These investors tend to increase long\npositions when the hedge cost pt is lower.\nThird, noise traders, by contrast, make trading decisions unrelated to fundamental information\nor technical analysis. Instead, their trades are driven by factors such as liquidity needs, portfolio\nrebalancing, market sentiment, or rumors.\nFourth, market makers in close-to-maturity options and futures markets play a critical role by\nproviding liquidity, facilitating trades, and enhancing price discovery. Market makers are sophisticated\nindividuals and institutions that use advanced algorithms and robust risk management techniques.\nTheir primary function in our model is to support price discovery by integrating information from\nother market participants’ trading behaviors into the market price.\n3.2\nTheoretical Benchmarks\nWe consider three theoretical benchmarks to characterize the steady-state behavior of informed\nspeculators: the non-collusive Nash equilibrium, the perfect cartel, and the collusive equilibrium,\ndenoted by N, M, and C in the superscripts of variable notations, respectively.\nBenchmark I: Non-Collusive Nash Equilibrium.\nThis describes the one-shot Nash equilibrium in\nthe stage game of repeated trading, where each informed speculator i, leveraging private signal vt,\ntrading signals extracted from vast amounts of public data using advanced technologies such as machine learning (ML)\nand large language models (LLMs). While the underlying data may be publicly available, the ability to process and extract\nvaluable predictive trading signals from it remains beyond the reach of most investors.\n14\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "typically operate with two teams: (i) a research team that generates private signals about vt, and (ii)",
          "bbox": [
            64.08000183105469,
            51.90544509887695,
            549.0099487304688,
            63.671226501464844
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.903643608093262,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "an execution team that converts trading signals into strategically executed orders to maximize trading\nprofits. Like the structure of Kyle models, our framework assumes that valuable private signals\nare already available, while focusing on the strategic execution of trades based on these signals. In\nother words, the AI-powered trading algorithms analyzed in this article are those employed by the\nexecution team to convert private signals into strategic trading orders. These algorithms operate",
          "bbox": [
            63.75299835205078,
            68.60916137695312,
            547.9230346679688,
            145.2103271484375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "after the research team has generated the signals and focus on optimizing execution based on their",
          "bbox": [
            64.08000183105469,
            150.6781768798828,
            548.1437377929688,
            161.62539672851562
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.94721508026123,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "informational content.\nSecond, information-insensitive investors, such as retail investors employing technical analysis\nand institutional investors seeking hold-to-maturity positions to hedge short-term risks, typically",
          "bbox": [
            64.08000183105469,
            167.14051818847656,
            548.350341796875,
            210.95135498046875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "remain unresponsive to real-time fundamental information related to the terminal payoff vt of close-",
          "bbox": [
            64.08000183105469,
            216.25743103027344,
            549.7264404296875,
            228.98236083984375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.876322746276855,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "to-maturity options and futures. Retail investors using technical analysis base their trades strictly on",
          "bbox": [
            64.08000183105469,
            232.9246826171875,
            547.9172973632812,
            243.77362060546875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.848934173583984,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "observed price patterns in the market (e.g., Lo and MacKinlay, 1999; Lo, Mamaysky and Wang, 2000;",
          "bbox": [
            64.08000183105469,
            249.36361694335938,
            549.2817993164062,
            260.2070617675781
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.843446731567383,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Chen, Peng and Zhou, 2024). The demand specification (3.2) captures the essence of certain technical",
          "bbox": [
            64.08000183105469,
            265.8104248046875,
            547.9161987304688,
            276.6374206542969
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.826972007751465,
            "color": 856203,
            "flags": 4
          }
        },
        {
          "text": "analysis strategies, assuming that a positive spread pt −v indicates overbought conditions with prices",
          "bbox": [
            64.08000183105469,
            280.9787902832031,
            547.9168090820312,
            293.98309326171875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "likely to fall, whereas a negative spread pt −v indicates oversold conditions with prices likely to rise.",
          "bbox": [
            64.08000183105469,
            297.4137878417969,
            549.8236694335938,
            310.4180908203125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.8214750289917,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Specifically, the demand specification captures technical analysis tools that provide signals for likely\nprice reversals. Additionally, information-insensitive investors include institutions such as pension\nfunds, insurance companies, and mutual funds, which may purchase close-to-maturity derivatives",
          "bbox": [
            63.75299835205078,
            315.0810546875,
            548.3462524414062,
            358.85662841796875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.876322746276855,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "and hold them to expiration as hedges against near-term risks. These investors tend to increase long",
          "bbox": [
            64.08000183105469,
            364.4017333984375,
            547.9203491210938,
            375.25616455078125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.854416847229004,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "positions when the hedge cost pt is lower.\nThird, noise traders, by contrast, make trading decisions unrelated to fundamental information\nor technical analysis. Instead, their trades are driven by factors such as liquidity needs, portfolio",
          "bbox": [
            63.75299835205078,
            380.6084289550781,
            547.9220581054688,
            424.6073303222656
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "rebalancing, market sentiment, or rumors.\nFourth, market makers in close-to-maturity options and futures markets play a critical role by",
          "bbox": [
            64.08000183105469,
            430.1025085449219,
            548.3505249023438,
            457.47833251953125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "providing liquidity, facilitating trades, and enhancing price discovery. Market makers are sophisticated",
          "bbox": [
            63.75299835205078,
            463.0521545410156,
            547.9232177734375,
            473.85162353515625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "individuals and institutions that use advanced algorithms and robust risk management techniques.\nTheir primary function in our model is to support price discovery by integrating information from",
          "bbox": [
            63.742000579833984,
            479.3811950683594,
            549.8244018554688,
            506.76953125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.94721508026123,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "other market participants’ trading behaviors into the market price.",
          "bbox": [
            64.08000183105469,
            512.2785034179688,
            387.480224609375,
            523.1876220703125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "3.2\nTheoretical Benchmarks",
          "bbox": [
            64.08000183105469,
            544.958740234375,
            223.95687866210938,
            556.9139404296875
          ],
          "font_info": {
            "font": "URWPalladioL-Bold",
            "size": 11.9552001953125,
            "color": 0,
            "flags": 20
          }
        },
        {
          "text": "We consider three theoretical benchmarks to characterize the steady-state behavior of informed\nspeculators: the non-collusive Nash equilibrium, the perfect cartel, and the collusive equilibrium,",
          "bbox": [
            63.534000396728516,
            569.856689453125,
            549.2850341796875,
            597.310302734375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "denoted by N, M, and C in the superscripts of variable notations, respectively.",
          "bbox": [
            64.08000183105469,
            602.616455078125,
            444.4361877441406,
            613.7146606445312
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Benchmark I: Non-Collusive Nash Equilibrium.\nThis describes the one-shot Nash equilibrium in\nthe stage game of repeated trading, where each informed speculator i, leveraging private signal vt,",
          "bbox": [
            64.08000183105469,
            635.552734375,
            549.2837524414062,
            663.879150390625
          ],
          "font_info": {
            "font": "URWPalladioL-BoldItal",
            "size": 11.001436233520508,
            "color": 0,
            "flags": 22
          }
        },
        {
          "text": "trading signals extracted from vast amounts of public data using advanced technologies such as machine learning (ML)\nand large language models (LLMs). While the underlying data may be publicly available, the ability to process and extract\nvaluable predictive trading signals from it remains beyond the reach of most investors.",
          "bbox": [
            63.82899856567383,
            674.3729248046875,
            548.8160400390625,
            705.3021240234375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 9.028946876525879,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "14",
          "bbox": [
            300.5450134277344,
            765.1044921875,
            311.4541320800781,
            776.0136108398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        }
      ]
    },
    {
      "page_number": 17,
      "text": "maximizes its expected profit by solving:\nxN(vt) = argmax\nxi∈X\nE[(vt −pN(yt))xi|vt],\nunder the assumption that other speculators adhere to the equilibrium strategy xN(vt). Here, pN(yt)\ndenotes the equilibrium market price as a function of the total flow yt. Specifically, speculator i chooses\noptimal xi, while accounting for its effect on the equilibrium price, expressed as pN(yt) = v + λNyt,\nwhere yt = xi + (I −1)xN(vt) + ut. Speculators recognize that λN is dependent on market parameters\nand focus on the linear strategy xN(vt) ≡χN(vt −v) in equilibrium. That is, each informed speculator\nmaximizes its current-period payoff given others’ actions, without considering how current actions\nmay affect future payoffs or behavior. In this equilibrium, no one can profitably deviate. Details are\nin Online Appendix 2.1.\nBenchmark II: Perfect Cartel Benchmark.\nThis benchmark describes a scenario where informed\nspeculators operate as a monopolistic cartel. The cartel, leveraging private signal vt, maximizes its\nexpected profit by solving:\nxM(vt) = argmax\nx∈X\nE[(vt −pM(yt))x|vt],\nfully accounting for the impact of trading flow x on the equilibrium price pM(yt) = v + λMyt, where\nyt = Ix + ut. Speculators recognize that λM is determined by market parameters and focus on the\nlinear strategy xM(vt) ≡χM(vt −v) in equilibrium. Details are in Online Appendix 2.1.\nBenchmark III: Collusive Equilibrium.\nBelow, we define the economic concept of collusive equilib-\nrium in terms of agents’ behaviors, rather than the intent typically emphasized in legal definitions.\nDefinition 3.1 (Collusive Equilibrium). A collusive equilibrium is characterized by two key properties:\n(i) agents achieve collective supra-competitive profits that exceed those obtained in the non-collusive Nash\nequilibrium, and (ii) agents have the option to deviate from equilibrium actions for short-term gains, and such\ndeviations impose costs on others.\nIn our model, two distinct economic mechanisms can theoretically sustain a collusive equilib-\nrium: the collusive Nash equilibrium via price-trigger strategies and the collusive experience-based\nequilibrium via learning bias. We explore their existence and theoretical properties in Section 3.3.\n3.3\nTwo Mechanisms Underlying Collusive Equilibrium\nCollusive Nash Equilibrium Sustained by Price-Trigger Strategies.\nWith sufficiently high price\ninformativeness, informed speculators can imperfectly infer order flows of others from market prices,\nenabling tacit collusion.14 Price-trigger collusion was introduced by Green and Porter (1984) and\nAbreu, Pearce and Stacchetti (1986).15 We formalize this theoretical concept below.\n14Under certain conditions, prices can even reveal others’ private values in equilibrium (Rostek and Weretka, 2012), and\nact as a sufficient statistic for inferring others’ behavior following unilateral deviations (Rostek and Yoon, 2021).\n15The study of tacit collusion via grim-trigger strategies with observable actions, initiated by Fudenberg and Maskin\n(1986) and Rotemberg and Saloner (1986), has been further developed in recent finance research, including asset pricing\n15\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "maximizes its expected profit by solving:",
          "bbox": [
            64.08000183105469,
            52.09455490112305,
            263.11651611328125,
            63.00365447998047
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "xN(vt) = argmax\nxi∈X\nE[(vt −pN(yt))xi|vt],",
          "bbox": [
            212.1280059814453,
            79.28712463378906,
            400.1943359375,
            103.24015045166016
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "under the assumption that other speculators adhere to the equilibrium strategy xN(vt). Here, pN(yt)",
          "bbox": [
            64.08000183105469,
            116.74702453613281,
            548.7368774414062,
            130.3141632080078
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.848934173583984,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "denotes the equilibrium market price as a function of the total flow yt. Specifically, speculator i chooses",
          "bbox": [
            64.08000183105469,
            134.98338317871094,
            547.9202270507812,
            146.74916076660156
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "optimal xi, while accounting for its effect on the equilibrium price, expressed as pN(yt) = v + λNyt,",
          "bbox": [
            64.08000183105469,
            149.61708068847656,
            549.2841796875,
            163.46620178222656
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.930895805358887,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "where yt = xi + (I −1)xN(vt) + ut. Speculators recognize that λN is dependent on market parameters",
          "bbox": [
            63.62200164794922,
            164.16213989257812,
            547.921142578125,
            180.2684326171875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "and focus on the linear strategy xN(vt) ≡χN(vt −v) in equilibrium. That is, each informed speculator",
          "bbox": [
            64.08000183105469,
            182.48805236816406,
            548.1433715820312,
            196.27418518066406
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "maximizes its current-period payoff given others’ actions, without considering how current actions",
          "bbox": [
            64.08000183105469,
            200.8861846923828,
            547.9240112304688,
            211.83340454101562
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.94721508026123,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "may affect future payoffs or behavior. In this equilibrium, no one can profitably deviate. Details are",
          "bbox": [
            64.08000183105469,
            217.3446044921875,
            547.9238891601562,
            228.25917053222656
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.91455364227295,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "in Online Appendix 2.1.",
          "bbox": [
            64.08000183105469,
            233.7835235595703,
            180.98190307617188,
            244.69261169433594
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Benchmark II: Perfect Cartel Benchmark.\nThis benchmark describes a scenario where informed\nspeculators operate as a monopolistic cartel. The cartel, leveraging private signal vt, maximizes its",
          "bbox": [
            64.08000183105469,
            266.0686950683594,
            547.925537109375,
            294.40716552734375
          ],
          "font_info": {
            "font": "URWPalladioL-BoldItal",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 22
          }
        },
        {
          "text": "expected profit by solving:",
          "bbox": [
            64.08000183105469,
            299.2665100097656,
            193.4073486328125,
            310.1756286621094
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "xM(vt) = argmax\nx∈X\nE[(vt −pM(yt))x|vt],",
          "bbox": [
            212.33399963378906,
            326.45904541015625,
            399.9883117675781,
            349.4291687011719
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "fully accounting for the impact of trading flow x on the equilibrium price pM(yt) = v + λMyt, where",
          "bbox": [
            64.08000183105469,
            362.67706298828125,
            547.9252319335938,
            376.4631652832031
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.826972007751465,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "yt = Ix + ut. Speculators recognize that λM is determined by market parameters and focus on the",
          "bbox": [
            64.21600341796875,
            377.065673828125,
            547.921630859375,
            393.04638671875
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "linear strategy xM(vt) ≡χM(vt −v) in equilibrium. Details are in Online Appendix 2.1.",
          "bbox": [
            64.08000183105469,
            395.5480651855469,
            489.74261474609375,
            409.33416748046875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Benchmark III: Collusive Equilibrium.\nBelow, we define the economic concept of collusive equilib-",
          "bbox": [
            64.08000183105469,
            429.9070739746094,
            549.727783203125,
            441.0580749511719
          ],
          "font_info": {
            "font": "URWPalladioL-BoldItal",
            "size": 10.903643608093262,
            "color": 0,
            "flags": 22
          }
        },
        {
          "text": "rium in terms of agents’ behaviors, rather than the intent typically emphasized in legal definitions.",
          "bbox": [
            64.08000183105469,
            446.58551025390625,
            544.5061645507812,
            457.49462890625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Definition 3.1 (Collusive Equilibrium). A collusive equilibrium is characterized by two key properties:\n(i) agents achieve collective supra-competitive profits that exceed those obtained in the non-collusive Nash",
          "bbox": [
            63.3489990234375,
            469.523681640625,
            548.735107421875,
            496.976318359375
          ],
          "font_info": {
            "font": "URWPalladioL-Bold",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 20
          }
        },
        {
          "text": "equilibrium, and (ii) agents have the option to deviate from equilibrium actions for short-term gains, and such",
          "bbox": [
            64.08000183105469,
            502.49346923828125,
            547.921875,
            513.375244140625
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.881793022155762,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "deviations impose costs on others.",
          "bbox": [
            64.08000183105469,
            518.908447265625,
            213.06558227539062,
            529.8175659179688
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "In our model, two distinct economic mechanisms can theoretically sustain a collusive equilib-",
          "bbox": [
            81.01599884033203,
            542.2266845703125,
            549.7304077148438,
            553.2443237304688
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "rium: the collusive Nash equilibrium via price-trigger strategies and the collusive experience-based",
          "bbox": [
            64.08000183105469,
            558.731689453125,
            547.9151611328125,
            569.6516723632812
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.920002937316895,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "equilibrium via learning bias. We explore their existence and theoretical properties in Section 3.3.",
          "bbox": [
            64.08000183105469,
            575.175537109375,
            537.6222534179688,
            586.0846557617188
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "3.3\nTwo Mechanisms Underlying Collusive Equilibrium",
          "bbox": [
            64.08000183105469,
            607.4037475585938,
            380.39068603515625,
            619.3589477539062
          ],
          "font_info": {
            "font": "URWPalladioL-Bold",
            "size": 11.9552001953125,
            "color": 0,
            "flags": 20
          }
        },
        {
          "text": "Collusive Nash Equilibrium Sustained by Price-Trigger Strategies.\nWith sufficiently high price",
          "bbox": [
            64.08000183105469,
            632.052734375,
            547.9151000976562,
            643.3203125
          ],
          "font_info": {
            "font": "URWPalladioL-BoldItal",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 22
          }
        },
        {
          "text": "informativeness, informed speculators can imperfectly infer order flows of others from market prices,\nenabling tacit collusion.14 Price-trigger collusion was introduced by Green and Porter (1984) and",
          "bbox": [
            64.08000183105469,
            648.8902587890625,
            549.2796630859375,
            676.1903076171875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.80496597290039,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Abreu, Pearce and Stacchetti (1986).15 We formalize this theoretical concept below.",
          "bbox": [
            63.65399932861328,
            677.7255249023438,
            464.0975036621094,
            692.5946655273438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 856203,
            "flags": 4
          }
        },
        {
          "text": "14Under certain conditions, prices can even reveal others’ private values in equilibrium (Rostek and Weretka, 2012), and\nact as a sufficient statistic for inferring others’ behavior following unilateral deviations (Rostek and Yoon, 2021).\n15The study of tacit collusion via grim-trigger strategies with observable actions, initiated by Fudenberg and Maskin\n(1986) and Rotemberg and Saloner (1986), has been further developed in recent finance research, including asset pricing",
          "bbox": [
            63.784000396728516,
            701.49169921875,
            547.9185791015625,
            745.5923461914062
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 6.973800182342529,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "15",
          "bbox": [
            300.5450134277344,
            765.1044921875,
            311.4541320800781,
            776.0136108398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        }
      ]
    },
    {
      "page_number": 18,
      "text": "Definition 3.2 (Collusive Nash Equilibrium through Price-Trigger Strategies). A collusive equilibrium\nin trading, sustained by price-trigger strategies, is a subgame perfect Nash equilibrium with two regimes: the\ncollusive regime and the punishment regime. In the collusive regime, informed speculators implicitly coordinate\nby submitting less aggressive order flows than in the non-collusive Nash equilibrium. If prices cross a critical\nthreshold, signaling a suspected deviation, the system shifts to the punishment regime, characterized by the\nnon-collusive equilibrium, where profits are significantly lower than in the collusive regime.\nIn the collusive regime, informed speculators adopt a trading strategy, xC(vt) ≡χC(vt −v) in\nperiod t, which is less aggressive than that in the non-collusive Nash equilibrium (i.e., χC < χN).\nWhen selecting χC, they anticipate the corresponding equilibrium market price to be\npC\nt = v + φC(vt −v) + λCut,\n(3.5)\nwhere φC and λC measure the market price’s sensitivity to vt −v and ut, respectively. This reflects\ninformed speculators’ understanding of how φC and λC depend on market parameters and the\nequilibrium trading strategy xC(vt). If vt > v and the observed market price pt exceeds the critical\nthreshold for the price-trigger strategy, defined as qC\n+(vt) ≡E\n\u0002\npC\nt |vt\n\u0003 + λCσuω, i.e., pt > qC\n+(vt), then\nspeculators revert to the punishment regime, characterized by the non-collusive Nash equilibrium,\nin period t + 1 with probability η. Likewise, if vt < v and pt falls below the lower threshold,\nqC\n−(vt) ≡E[pC\nt |vt] −λCσuω, i.e., pt < qC\n−(vt), then they may also revert to the punishment regime\nin period t + 1 with probability η. Upon entering the punishment regime at t + 1, they will remain\nthere with the same probability η in each period until t + T. Thus, the triple (η, ω, T) characterizes\nan implicit coordination scheme among informed speculators. The space of price-trigger strategies is\nΩ≡{(η, ω, T) : η ∈[0, 1], ω ∈[0, ¯ω], T ∈N}.\nWe now explain why it is sufficient, without loss of generality, to restrict attention to the strategy\nspace Ωwith a sufficiently large but finite upper bound ¯ω in our analysis of the collusive Nash\nequilibrium. First, Sannikov and Skrzypacz (2007, Lemma 3) show that a tail test with a bang-bang\nproperty is the optimal mechanism for maximizing expected continuation payoffs while maintaining\nincentives against single-period deviations. Building on this insight, we focus on price-trigger\nstrategies that serve as tail tests with bang-bang properties in our trading setting and support the\ncollusive Nash equilibrium. Second, for a price-trigger strategy to be effective in deterring deviations\n(that is, to function as a powerful tail test), the associated test must have non-negligible test size (type\nI error). This requirement, grounded in the Neyman-Pearson lemma, implies that if the test size\n(type I error) is too small, the strategy becomes ineffective at detecting deviations and thus fails to\ndiscipline behavior. In particular, as long as the upper bound ¯ω is set sufficiently high, the test size\nbecomes nearly zero for all ω > ¯ω,16 making the strategy incapable of sustaining tacit collusion at\nsuch high ω values. Therefore, no meaningful strategy is omitted by focusing on Ωwith a sufficiently\nlarge but finite ¯ω. Additional technical details are provided in Online Appendix 2.1.\nCollusive Experience-Based Equilibrium Sustained by Learning Bias.\nCollusive trading behavior,\nas outlined in Definition 3.1, can also emerge as an outcome of an experience-based equilibrium\nstudies (e.g., Opp, Parlour and Walden, 2014; Dou, Ji and Wu, 2021a,b; Chen et al., 2023, 2024).\n16e.g., 1 −Φ( ¯ω) < 10−15 when ¯ω = 8.\n16\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "Definition 3.2 (Collusive Nash Equilibrium through Price-Trigger Strategies). A collusive equilibrium",
          "bbox": [
            64.08000183105469,
            51.909454345703125,
            547.923095703125,
            63.00210952758789
          ],
          "font_info": {
            "font": "URWPalladioL-Bold",
            "size": 10.903643608093262,
            "color": 0,
            "flags": 20
          }
        },
        {
          "text": "in trading, sustained by price-trigger strategies, is a subgame perfect Nash equilibrium with two regimes: the",
          "bbox": [
            64.08000183105469,
            68.33741760253906,
            547.923828125,
            79.25196838378906
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.91455364227295,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "collusive regime and the punishment regime. In the collusive regime, informed speculators implicitly coordinate",
          "bbox": [
            64.08000183105469,
            84.85694885253906,
            547.9187622070312,
            95.65640258789062
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "by submitting less aggressive order flows than in the non-collusive Nash equilibrium. If prices cross a critical\nthreshold, signaling a suspected deviation, the system shifts to the punishment regime, characterized by the",
          "bbox": [
            64.08000183105469,
            101.20741271972656,
            547.9238891601562,
            128.58433532714844
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.91455364227295,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "non-collusive equilibrium, where profits are significantly lower than in the collusive regime.",
          "bbox": [
            64.08000183105469,
            134.08140563964844,
            469.8329162597656,
            144.99050903320312
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "In the collusive regime, informed speculators adopt a trading strategy, xC(vt) ≡χC(vt −v) in\nperiod t, which is less aggressive than that in the non-collusive Nash equilibrium (i.e., χC < χN).",
          "bbox": [
            63.75299835205078,
            157.68202209472656,
            549.8291625976562,
            187.90321350097656
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "When selecting χC, they anticipate the corresponding equilibrium market price to be",
          "bbox": [
            63.534000396728516,
            190.5520782470703,
            475.2827453613281,
            204.3382110595703
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "pC\nt = v + φC(vt −v) + λCut,\n(3.5)",
          "bbox": [
            238.656005859375,
            219.7350616455078,
            549.0076904296875,
            235.2724609375
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "where φC and λC measure the market price’s sensitivity to vt −v and ut, respectively. This reflects\ninformed speculators’ understanding of how φC and λC depend on market parameters and the\nequilibrium trading strategy xC(vt). If vt > v and the observed market price pt exceeds the critical",
          "bbox": [
            63.62200164794922,
            247.97230529785156,
            547.9208984375,
            297.4391784667969
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 11.001436233520508,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "threshold for the price-trigger strategy, defined as qC\n+(vt) ≡E\n\u0002\npC\nt |vt\n\u0003 + λCσuω, i.e., pt > qC\n+(vt), then\nspeculators revert to the punishment regime, characterized by the non-collusive Nash equilibrium,\nin period t + 1 with probability η. Likewise, if vt < v and pt falls below the lower threshold,",
          "bbox": [
            64.08000183105469,
            291.4021301269531,
            549.2850341796875,
            346.75030517578125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "qC\n−(vt) ≡E[pC\nt |vt] −λCσuω, i.e., pt < qC\n−(vt), then they may also revert to the punishment regime\nin period t + 1 with probability η. Upon entering the punishment regime at t + 1, they will remain\nthere with the same probability η in each period until t + T. Thus, the triple (η, ω, T) characterizes",
          "bbox": [
            64.08000183105469,
            348.61907958984375,
            547.9232177734375,
            395.2751770019531
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "an implicit coordination scheme among informed speculators. The space of price-trigger strategies is",
          "bbox": [
            64.08000183105469,
            399.9704895019531,
            547.9232788085938,
            410.8029479980469
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.832467079162598,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Ω≡{(η, ω, T) : η ∈[0, 1], ω ∈[0, ¯ω], T ∈N}.",
          "bbox": [
            64.21600341796875,
            415.1427917480469,
            295.5552673339844,
            428.14617919921875
          ],
          "font_info": {
            "font": "PazoMath",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "We now explain why it is sufficient, without loss of generality, to restrict attention to the strategy\nspace Ωwith a sufficiently large but finite upper bound ¯ω in our analysis of the collusive Nash",
          "bbox": [
            64.08000183105469,
            432.82867431640625,
            548.3456420898438,
            461.0161437988281
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.848934173583984,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "equilibrium. First, Sannikov and Skrzypacz (2007, Lemma 3) show that a tail test with a bang-bang",
          "bbox": [
            64.08000183105469,
            465.632080078125,
            547.9151000976562,
            476.5738830566406
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.941778182983398,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "property is the optimal mechanism for maximizing expected continuation payoffs while maintaining\nincentives against single-period deviations. Building on this insight, we focus on price-trigger\nstrategies that serve as tail tests with bang-bang properties in our trading setting and support the",
          "bbox": [
            63.75299835205078,
            482.1376037597656,
            548.1389770507812,
            525.9003295898438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.843446731567383,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "collusive Nash equilibrium. Second, for a price-trigger strategy to be effective in deterring deviations",
          "bbox": [
            64.08000183105469,
            531.4672241210938,
            547.9205932617188,
            542.2777099609375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.810471534729004,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "(that is, to function as a powerful tail test), the associated test must have non-negligible test size (type\nI error). This requirement, grounded in the Neyman-Pearson lemma, implies that if the test size\n(type I error) is too small, the strategy becomes ineffective at detecting deviations and thus fails to",
          "bbox": [
            63.720001220703125,
            547.91015625,
            547.9223022460938,
            591.63525390625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "discipline behavior. In particular, as long as the upper bound ¯ω is set sufficiently high, the test size\nbecomes nearly zero for all ω > ¯ω,16 making the strategy incapable of sustaining tacit collusion at",
          "bbox": [
            64.08000183105469,
            596.978515625,
            547.91748046875,
            625.3671875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.936338424682617,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "such high ω values. Therefore, no meaningful strategy is omitted by focusing on Ωwith a sufficiently",
          "bbox": [
            64.08000183105469,
            629.1027221679688,
            548.348876953125,
            641.8021850585938
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "large but finite ¯ω. Additional technical details are provided in Online Appendix 2.1.",
          "bbox": [
            64.08000183105469,
            646.2835083007812,
            473.5860595703125,
            658.2381591796875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Collusive Experience-Based Equilibrium Sustained by Learning Bias.\nCollusive trading behavior,\nas outlined in Definition 3.1, can also emerge as an outcome of an experience-based equilibrium",
          "bbox": [
            64.08000183105469,
            679.1937255859375,
            549.2821655273438,
            706.8803100585938
          ],
          "font_info": {
            "font": "URWPalladioL-BoldItal",
            "size": 10.996026039123535,
            "color": 0,
            "flags": 22
          }
        },
        {
          "text": "studies (e.g., Opp, Parlour and Walden, 2014; Dou, Ji and Wu, 2021a,b; Chen et al., 2023, 2024).\n16e.g., 1 −Φ( ¯ω) < 10−15 when ¯ω = 8.",
          "bbox": [
            64.08000183105469,
            717.8992919921875,
            441.10699462890625,
            739.1598510742188
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 8.966400146484375,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "16",
          "bbox": [
            300.54498291015625,
            765.1044921875,
            311.4541015625,
            776.0136108398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        }
      ]
    },
    {
      "page_number": 19,
      "text": "defined by Fershtman and Pakes (2012), which is closely related to the concept of self-confirming\nequilibrium (e.g., Fudenberg and Levine, 1993; Battigalli et al., 2015).17 Specifically, an experience-\nbased equilibrium is characterized by: (i) a recurrent Markovian state process, (ii) an optimization\ncondition requiring strategies to be optimized based on potentially incorrect outcome evaluations,\nand (iii) a consistency condition requiring that expected discounted net cash flows under the true\ndistribution, generated by optimal strategies on the equilibrium path, align with on-path evaluations.\nCrucially, this condition applies only to on-path outcomes. Players’ beliefs or evaluations about\noff-path outcomes need not align with expected discounted cash flows under the true distribution,\nallowing for significant biases. In sum, as long as on-path evaluations match historically observed\noutcomes, these biases can persist and, in turn, sustain the equilibrium path.\nWe formalize the theoretical concept of collusive experience-based equilibrium sustained by\nlearning bias below.\nDefinition 3.3 (Collusive Experience-Based Equilibrium through Learning Bias). A collusive equilibrium\nin trading, sustained by learning bias, is an experience-based equilibrium in which informed speculators\nsystematically undervalue aggressive trading strategies due to an incorrect outcome evaluation system. This\nsystem remains uncorrected as learning is confined to outcomes observed along the equilibrium path. A notable\ncase of such an equilibrium arises from a specific form of learning bias — over-perceived aversion to noise\ntrading risk. In this case, the outcome evaluation system is biased solely by the perceived disutility associated\nwith aversion to noise trading risk: −ς\n2χ2σ2\nu, where ς > 0 represents the degree of over-perceived aversion and\nχ > 0 reflects the aggressiveness of the trading strategy x(vt) ≡χ(vt −v).\n3.4\nExistence of Collusive Equilibrium\nExistence of Collusive Nash Equilibrium Sustained by Price-Trigger Strategies.\nSustaining coordina-\ntion through price-trigger strategies hinges critically on high price informativeness to enable effective\nmonitoring. Proposition 3.1 below demonstrates the impossibility of sustaining a collusive Nash\nequilibrium via price-trigger strategies in a financial market when noise trading risk, captured by σu,\nis large or when the presence of information-insensitive investors, captured by ξ, is small relative to\nθ, defined in Equation (3.3).\nWhen noise trading risk σu is large, noise trading flow ut dominates price fluctuations, as shown\nin (3.5), overshadowing informed trading and reducing price informativeness. This situation parallels\noligopolistic product market competition with latent random price shocks (as in Abreu, Milgrom and\nPearce, 1991; Sannikov and Skrzypacz, 2007). Applying the same economic logic, high noise trading\nrisk in financial markets undermines market prices as a monitoring tool, making it impossible to\nsustain a collusive trading equilibrium through price-trigger strategies in financial markets.\nMore importantly, our paper provides new insights into the conditions that enable or prevent tacit\ncollusion in financial market trading, which can be fundamentally distinct from tacit collusion in\nproduct pricing in goods markets, as studied by Abreu, Milgrom and Pearce (1991) and Sannikov\nand Skrzypacz (2007). Specifically, when ξ is small relative to θ, reflecting a minimal presence of\ninformation-insensitive investors, the market maker’s objective in (3.3) focuses on price discovery, with\n17See also Fudenberg and Kreps (1988), Fudenberg and Kreps (1995), Cho, Williams and Sargent (2002), and Cho and\nSargent (2008) for influential early contributions.\n17\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "defined by Fershtman and Pakes (2012), which is closely related to the concept of self-confirming\nequilibrium (e.g., Fudenberg and Levine, 1993; Battigalli et al., 2015).17 Specifically, an experience-\nbased equilibrium is characterized by: (i) a recurrent Markovian state process, (ii) an optimization\ncondition requiring strategies to be optimized based on potentially incorrect outcome evaluations,\nand (iii) a consistency condition requiring that expected discounted net cash flows under the true",
          "bbox": [
            64.08000183105469,
            52.01670455932617,
            549.7294311523438,
            128.77532958984375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "distribution, generated by optimal strategies on the equilibrium path, align with on-path evaluations.\nCrucially, this condition applies only to on-path outcomes. Players’ beliefs or evaluations about\noff-path outcomes need not align with expected discounted cash flows under the true distribution,\nallowing for significant biases. In sum, as long as on-path evaluations match historically observed",
          "bbox": [
            64.08000183105469,
            134.3294219970703,
            549.82861328125,
            194.5122528076172
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.826972007751465,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "outcomes, these biases can persist and, in turn, sustain the equilibrium path.\nWe formalize the theoretical concept of collusive experience-based equilibrium sustained by",
          "bbox": [
            64.08000183105469,
            200.0115509033203,
            548.3505249023438,
            227.3863525390625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "learning bias below.",
          "bbox": [
            64.08000183105469,
            232.8815460205078,
            160.92010498046875,
            243.79063415527344
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Definition 3.3 (Collusive Experience-Based Equilibrium through Learning Bias). A collusive equilibrium\nin trading, sustained by learning bias, is an experience-based equilibrium in which informed speculators\nsystematically undervalue aggressive trading strategies due to an incorrect outcome evaluation system. This",
          "bbox": [
            64.08000183105469,
            258.1739501953125,
            547.9213256835938,
            301.8908386230469
          ],
          "font_info": {
            "font": "URWPalladioL-Bold",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 20
          }
        },
        {
          "text": "system remains uncorrected as learning is confined to outcomes observed along the equilibrium path. A notable\ncase of such an equilibrium arises from a specific form of learning bias — over-perceived aversion to noise",
          "bbox": [
            64.08000183105469,
            307.4637756347656,
            547.9183349609375,
            334.7723083496094
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.8214750289917,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "trading risk. In this case, the outcome evaluation system is biased solely by the perceived disutility associated",
          "bbox": [
            64.08000183105469,
            340.2494201660156,
            547.9164428710938,
            351.1857604980469
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.936338424682617,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "with aversion to noise trading risk: −ς",
          "bbox": [
            64.08000183105469,
            351.9330749511719,
            236.23463439941406,
            367.5917053222656
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.826972007751465,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "2χ2σ2\nu, where ς > 0 represents the degree of over-perceived aversion and",
          "bbox": [
            230.96600341796875,
            355.041259765625,
            547.9208984375,
            373.1806335449219
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "χ > 0 reflects the aggressiveness of the trading strategy x(vt) ≡χ(vt −v).",
          "bbox": [
            64.21600341796875,
            372.12078857421875,
            400.3882751464844,
            385.1250915527344
          ],
          "font_info": {
            "font": "PazoMath-Italic",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "3.4\nExistence of Collusive Equilibrium",
          "bbox": [
            64.08001708984375,
            406.0087890625,
            283.9480895996094,
            417.9639892578125
          ],
          "font_info": {
            "font": "URWPalladioL-Bold",
            "size": 11.9552001953125,
            "color": 0,
            "flags": 20
          }
        },
        {
          "text": "Existence of Collusive Nash Equilibrium Sustained by Price-Trigger Strategies.\nSustaining coordina-",
          "bbox": [
            64.08000183105469,
            430.81915283203125,
            549.726806640625,
            441.86358642578125
          ],
          "font_info": {
            "font": "URWPalladioL-BoldItal",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 22
          }
        },
        {
          "text": "tion through price-trigger strategies hinges critically on high price informativeness to enable effective\nmonitoring. Proposition 3.1 below demonstrates the impossibility of sustaining a collusive Nash",
          "bbox": [
            64.08000183105469,
            447.49517822265625,
            547.92041015625,
            474.7953186035156
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.80496597290039,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "equilibrium via price-trigger strategies in a financial market when noise trading risk, captured by σu,",
          "bbox": [
            64.08000183105469,
            480.3376159667969,
            549.2835083007812,
            492.086181640625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.843446731567383,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "is large or when the presence of information-insensitive investors, captured by ξ, is small relative to",
          "bbox": [
            64.08000183105469,
            496.7372741699219,
            547.9166870117188,
            508.52117919921875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.89272403717041,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "θ, defined in Equation (3.3).",
          "bbox": [
            64.21600341796875,
            513.1605224609375,
            198.6768341064453,
            524.9561767578125
          ],
          "font_info": {
            "font": "PazoMath-Italic",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "When noise trading risk σu is large, noise trading flow ut dominates price fluctuations, as shown",
          "bbox": [
            81.01599884033203,
            529.4064331054688,
            547.9231567382812,
            542.130859375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.870850563049316,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "in (3.5), overshadowing informed trading and reducing price informativeness. This situation parallels",
          "bbox": [
            64.08000183105469,
            546.110107421875,
            547.9188232421875,
            556.9096069335938
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "oligopolistic product market competition with latent random price shocks (as in Abreu, Milgrom and",
          "bbox": [
            64.08000183105469,
            562.5451049804688,
            547.918701171875,
            573.3446044921875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Pearce, 1991; Sannikov and Skrzypacz, 2007). Applying the same economic logic, high noise trading\nrisk in financial markets undermines market prices as a monitoring tool, making it impossible to",
          "bbox": [
            64.08000183105469,
            578.9249877929688,
            547.9232788085938,
            606.2763671875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.876322746276855,
            "color": 856203,
            "flags": 4
          }
        },
        {
          "text": "sustain a collusive trading equilibrium through price-trigger strategies in financial markets.",
          "bbox": [
            64.08000183105469,
            611.771484375,
            508.6912841796875,
            622.6806030273438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "More importantly, our paper provides new insights into the conditions that enable or prevent tacit\ncollusion in financial market trading, which can be fundamentally distinct from tacit collusion in\nproduct pricing in goods markets, as studied by Abreu, Milgrom and Pearce (1991) and Sannikov\nand Skrzypacz (2007). Specifically, when ξ is small relative to θ, reflecting a minimal presence of",
          "bbox": [
            63.75299835205078,
            628.28515625,
            548.2236938476562,
            689.3081665039062
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "information-insensitive investors, the market maker’s objective in (3.3) focuses on price discovery, with",
          "bbox": [
            64.08000183105469,
            694.026123046875,
            547.9188842773438,
            704.8256225585938
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "17See also Fudenberg and Kreps (1988), Fudenberg and Kreps (1995), Cho, Williams and Sargent (2002), and Cho and\nSargent (2008) for influential early contributions.",
          "bbox": [
            64.08000183105469,
            714.6527099609375,
            547.923095703125,
            736.4031372070312
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 6.973800182342529,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "17",
          "bbox": [
            300.54498291015625,
            765.1044921875,
            311.4541015625,
            776.0136108398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        }
      ]
    },
    {
      "page_number": 20,
      "text": "minimal emphasis on inventory cost minimization. This environment closely aligns with the standard\nKyle (1985) benchmark, which conceptualizes financial markets as mechanisms for information\naggregation, where sophisticated participants infer fundamental values from the collective actions\nof others and incorporate this information into prices. In such an environment, informed investors,\nunderstanding how financial markets aggregate information into prices, must trade strategically and\ncautiously on private signals to secure meaningful information rents. This deliberate and restrained\ntrading reduces price informativeness, weakening prices as effective monitoring tools. As a result,\nit becomes impossible to sustain a collusive trading equilibrium through price-trigger strategies in\nfinancial markets, regardless of the level of noise trading risk σu.\nProposition 3.1 (Feasibility of Price-Trigger Strategies). With all other parameters held constant, a collusive\nNash equilibrium sustained by price-trigger strategies is not feasible if ξ is small relative to θ or if σu is large.\nConversely, such an equilibrium exists only if ξ is sufficiently large relative to θ and σu is sufficiently small.\nThe detailed proof is provided in Online Appendix 2.3.\nExistence of Collusive Experience-Based Equilibrium Sustained by Learning Bias.\nIn contrast to\nthe collusive Nash equilibrium sustained by price-trigger strategies in Proposition 3.1, a collusive\nequilibrium driven by learning bias, especially through the self-confirming learning process, can\nrobustly arise as an experience-based equilibrium, as shown in Proposition 3.2.\nProposition 3.2 (Existence of Collusion Through Learning Bias). A collusive experience-based equilibrium\nsustained by learning bias, with any trading strategy χC ∈[χM, χN), exists for all ξ ≥0 and σu ≥0. In\nthis equilibrium, informed speculators uniformly undervalue aggressive trading strategies due to an incorrect\noutcome evaluation system, which remains uncorrected as learning is based solely on observed outcomes along\nthe equilibrium path. In particular, such a collusive experience-based equilibrium can be sustained by learning\nbias induced by over-perceived aversion to noise trading risk, characterized by the over-perceived aversion\ncoefficient ς, as introduced in Definition 3.3, with an equilibrium trading strategy χC ∈[χM, χN).\nThe detailed proof is provided in Online Appendix 2.4.\n3.5\nThe Impact of Collusive Informed Trading on Market Efficiency\nTo assess, based on the simulation experimental outcomes, whether informed AI speculators engage\nin tacitly collusive trading through price-trigger strategies or learning bias, we derive testable\ntheoretical properties of the collusive equilibrium corresponding to each of these two distinct\neconomic mechanisms.\nProposition 3.3 (Supra-Competitive Nature of Collusion). Let πM, πC, and πN represent the expected\nprofits of informed speculators in the perfect cartel benchmark, the collusive equilibrium (sustained either by\nprice-trigger strategies or learning bias), and the non-collusive equilibrium, respectively. These profits satisfy:\n∆C ≡πC −πN\nπM −πN ∈(0, 1].\n(3.6)\nwhere ∆C represents the normalized trading profitability of informed speculators in the collusive equilibrium.\n18\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "minimal emphasis on inventory cost minimization. This environment closely aligns with the standard\nKyle (1985) benchmark, which conceptualizes financial markets as mechanisms for information\naggregation, where sophisticated participants infer fundamental values from the collective actions",
          "bbox": [
            64.08000183105469,
            52.17318344116211,
            547.9254760742188,
            95.89921569824219
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "of others and incorporate this information into prices. In such an environment, informed investors,",
          "bbox": [
            64.08000183105469,
            101.37709045410156,
            549.2868041992188,
            112.31886291503906
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.941778182983398,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "understanding how financial markets aggregate information into prices, must trade strategically and",
          "bbox": [
            64.08000183105469,
            117.8904800415039,
            547.9232788085938,
            128.7229461669922
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.832467079162598,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "cautiously on private signals to secure meaningful information rents. This deliberate and restrained\ntrading reduces price informativeness, weakening prices as effective monitoring tools. As a result,\nit becomes impossible to sustain a collusive trading equilibrium through price-trigger strategies in",
          "bbox": [
            64.08000183105469,
            134.28225708007812,
            549.284912109375,
            178.06961059570312
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.89272403717041,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "financial markets, regardless of the level of noise trading risk σu.",
          "bbox": [
            64.08000183105469,
            183.5755157470703,
            377.5102844238281,
            195.3711700439453
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Proposition 3.1 (Feasibility of Price-Trigger Strategies). With all other parameters held constant, a collusive",
          "bbox": [
            64.08000183105469,
            208.8689727783203,
            547.9241943359375,
            219.8556365966797
          ],
          "font_info": {
            "font": "URWPalladioL-Bold",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 20
          }
        },
        {
          "text": "Nash equilibrium sustained by price-trigger strategies is not feasible if ξ is small relative to θ or if σu is large.",
          "bbox": [
            64.08000183105469,
            225.2194366455078,
            549.2798461914062,
            237.7699737548828
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.91455364227295,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "Conversely, such an equilibrium exists only if ξ is sufficiently large relative to θ and σu is sufficiently small.",
          "bbox": [
            63.720001220703125,
            241.65843200683594,
            542.247802734375,
            254.20455932617188
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "The detailed proof is provided in Online Appendix 2.3.",
          "bbox": [
            81.01602172851562,
            267.24951171875,
            349.630859375,
            278.15863037109375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Existence of Collusive Experience-Based Equilibrium Sustained by Learning Bias.\nIn contrast to\nthe collusive Nash equilibrium sustained by price-trigger strategies in Proposition 3.1, a collusive\nequilibrium driven by learning bias, especially through the self-confirming learning process, can",
          "bbox": [
            64.08000183105469,
            299.9847106933594,
            547.9241333007812,
            344.1223449707031
          ],
          "font_info": {
            "font": "URWPalladioL-BoldItal",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 22
          }
        },
        {
          "text": "robustly arise as an experience-based equilibrium, as shown in Proposition 3.2.",
          "bbox": [
            64.08000183105469,
            349.6175231933594,
            448.14581298828125,
            360.5266418457031
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Proposition 3.2 (Existence of Collusion Through Learning Bias). A collusive experience-based equilibrium\nsustained by learning bias, with any trading strategy χC ∈[χM, χN), exists for all ξ ≥0 and σu ≥0. In",
          "bbox": [
            64.08000183105469,
            374.9109191894531,
            547.9169921875,
            403.25018310546875
          ],
          "font_info": {
            "font": "URWPalladioL-Bold",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 20
          }
        },
        {
          "text": "this equilibrium, informed speculators uniformly undervalue aggressive trading strategies due to an incorrect",
          "bbox": [
            64.08000183105469,
            407.6964111328125,
            547.923828125,
            418.6109619140625
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.91455364227295,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "outcome evaluation system, which remains uncorrected as learning is based solely on observed outcomes along",
          "bbox": [
            64.08000183105469,
            424.16351318359375,
            547.9242553710938,
            435.03436279296875
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.870850563049316,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "the equilibrium path. In particular, such a collusive experience-based equilibrium can be sustained by learning\nbias induced by over-perceived aversion to noise trading risk, characterized by the over-perceived aversion",
          "bbox": [
            64.08000183105469,
            440.6025390625,
            547.9237060546875,
            467.9443359375
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.865375518798828,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "coefficient ς, as introduced in Definition 3.3, with an equilibrium trading strategy χC ∈[χM, χN).",
          "bbox": [
            64.08000183105469,
            468.4627990722656,
            501.9102783203125,
            485.4261779785156
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "The detailed proof is provided in Online Appendix 2.4.",
          "bbox": [
            81.01602172851562,
            499.0315246582031,
            349.630859375,
            509.9406433105469
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "3.5\nThe Impact of Collusive Informed Trading on Market Efficiency",
          "bbox": [
            64.08001708984375,
            531.7117309570312,
            443.3587951660156,
            543.6669311523438
          ],
          "font_info": {
            "font": "URWPalladioL-Bold",
            "size": 11.9552001953125,
            "color": 0,
            "flags": 20
          }
        },
        {
          "text": "To assess, based on the simulation experimental outcomes, whether informed AI speculators engage\nin tacitly collusive trading through price-trigger strategies or learning bias, we derive testable\ntheoretical properties of the collusive equilibrium corresponding to each of these two distinct",
          "bbox": [
            63.742000579833984,
            556.7237548828125,
            547.9198608398438,
            600.4983520507812
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.85989761352539,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "economic mechanisms.",
          "bbox": [
            64.08000183105469,
            605.9935302734375,
            175.87644958496094,
            616.9026489257812
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Proposition 3.3 (Supra-Competitive Nature of Collusion). Let πM, πC, and πN represent the expected\nprofits of informed speculators in the perfect cartel benchmark, the collusive equilibrium (sustained either by",
          "bbox": [
            64.08000183105469,
            627.1895141601562,
            547.9251708984375,
            658.5721435546875
          ],
          "font_info": {
            "font": "URWPalladioL-Bold",
            "size": 10.985198020935059,
            "color": 0,
            "flags": 20
          }
        },
        {
          "text": "price-trigger strategies or learning bias), and the non-collusive equilibrium, respectively. These profits satisfy:",
          "bbox": [
            64.08000183105469,
            664.076416015625,
            548.6185302734375,
            674.9855346679688
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "∆C ≡πC −πN",
          "bbox": [
            247.76699829101562,
            685.9727783203125,
            320.8587341308594,
            709.2310791015625
          ],
          "font_info": {
            "font": "PazoMath",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "πM −πN ∈(0, 1].\n(3.6)",
          "bbox": [
            277.8399963378906,
            697.86376953125,
            549.0057983398438,
            719.6841430664062
          ],
          "font_info": {
            "font": "PazoMath-Italic",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "where ∆C represents the normalized trading profitability of informed speculators in the collusive equilibrium.",
          "bbox": [
            64.07998657226562,
            728.5414428710938,
            545.9627075195312,
            743.4105224609375
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "18",
          "bbox": [
            300.54498291015625,
            765.1044921875,
            311.4541015625,
            776.0136108398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        }
      ]
    },
    {
      "page_number": 21,
      "text": "The detailed proof is provided in Online Appendix 2.5.\nDefinition 3.4. The price informativeness, market liquidity, and mispricing are measured, respectively, by\nI ≡var(xt)\nvar(ut),\nL ≡\n\u0014∂|mt|\n∂ut\n\u0015−1\n,\nand\nE ≡|E[pt|vt] −vt| ,\n(3.7)\nwhere xt, zt, ut, and mt ≡−(yt + zt) denote the total order flow of informed speculators, information-\ninsensitive investors, noise traders, and market makers, respectively, and pt denotes the market price.\nNext, we examine how ∆C, IC, LC, and E C vary across different market structures and information\nenvironments within the collusive equilibrium, driven by two distinct mechanisms.\nProposition 3.4 (Market Structures and Collusive Trading: Consequences for Market Efficiency). The\ntwo collusion mechanisms yield similar implications when I changes, differing implications when ρ varies, and\nopposing implications when σu changes:\n(i) If a collusive Nash equilibrium sustained by price-trigger strategies exists, the following holds in this\nequilibrium when I is sufficiently large:\nρ ↓,\nσu ↑,\nor\nI ↑\n=⇒\n∆C ↓\n(i.e., collusion capacity ↓)\n=⇒\nIC/I M ↑,\nLC/LM ↑,\nand\nE C/E M ↓\n(i.e., market efficiency ↑),\n(3.8)\nwhere C and M represent the collusive Nash equilibrium and the perfect cartel benchmark, respectively.\n(ii) If a collusive experience-based equilibrium sustained by over-perceived aversion to noise trading risk\nexists, the following holds in this equilibrium:\nσu ↓,\nor\nI ↑\n=⇒\n∆C ↓\n(i.e., collusion capacity ↓)\n=⇒\nIC/I M ↑,\nLC/LM ↑,\nand\nE C/E M ↓\n(i.e., market efficiency ↑),\n(3.9)\nwhere C and M represent the collusive experience-based equilibrium and the perfect cartel benchmark,\nrespectively. The result for LC/LM holds when ξ is sufficiently large. Importantly, ρ does not affect ∆C,\nIC/I M, LC/LM, or E C/E M in this equilibrium.\nThe detailed proof is provided in Online Appendix 2.6.\n4\nSimulation Experiments on AI Trading Algorithms\nAs a proof of concept, this section presents simulation experiments to test whether informed AI\nspeculators, equipped with autonomous model-free Q-learning algorithms, can achieve and sustain\ncollusive behavior under asymmetric information and an adaptive asset demand curve that endoge-\nnously responds to their trading strategies. We specifically examine whether such collusive behavior\nby AI speculators can arise without explicit agreement, communication, or pre-programmed intent.\n19\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "The detailed proof is provided in Online Appendix 2.5.",
          "bbox": [
            81.01599884033203,
            52.09455490112305,
            349.630859375,
            63.00365447998047
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Definition 3.4. The price informativeness, market liquidity, and mispricing are measured, respectively, by",
          "bbox": [
            64.08000183105469,
            77.30742645263672,
            536.7448120117188,
            88.29928588867188
          ],
          "font_info": {
            "font": "URWPalladioL-Bold",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 20
          }
        },
        {
          "text": "I ≡var(xt)",
          "bbox": [
            165.65802001953125,
            104.75409698486328,
            223.46688842773438,
            123.35908508300781
          ],
          "font_info": {
            "font": "CMSY10",
            "size": 11.367300033569336,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "var(ut),\nL ≡\n\u0014∂|mt|",
          "bbox": [
            189.1739959716797,
            104.60678100585938,
            293.55108642578125,
            132.25917053222656
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "∂ut",
          "bbox": [
            273.9049987792969,
            120.49443817138672,
            288.446044921875,
            132.4792022705078
          ],
          "font_info": {
            "font": "PazoMath-Italic",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "\u0015−1\n,\nand\nE ≡|E[pt|vt] −vt| ,\n(3.7)",
          "bbox": [
            295.0119934082031,
            101.58480834960938,
            549.0128784179688,
            124.77620697021484
          ],
          "font_info": {
            "font": "CMEX10",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "where xt, zt, ut, and mt ≡−(yt + zt) denote the total order flow of informed speculators, information-",
          "bbox": [
            64.08000183105469,
            145.17080688476562,
            549.7344360351562,
            158.3214111328125
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "insensitive investors, noise traders, and market makers, respectively, and pt denotes the market price.",
          "bbox": [
            64.08000183105469,
            162.6244354248047,
            510.2627868652344,
            175.16952514648438
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "Next, we examine how ∆C, IC, LC, and E C vary across different market structures and information",
          "bbox": [
            81.01599884033203,
            184.33316040039062,
            547.9153442382812,
            199.09263610839844
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "environments within the collusive equilibrium, driven by two distinct mechanisms.",
          "bbox": [
            64.08000183105469,
            204.64955139160156,
            468.6003112792969,
            215.5586395263672
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Proposition 3.4 (Market Structures and Collusive Trading: Consequences for Market Efficiency). The",
          "bbox": [
            64.08000183105469,
            229.90660095214844,
            547.919677734375,
            240.943603515625
          ],
          "font_info": {
            "font": "URWPalladioL-Bold",
            "size": 10.848934173583984,
            "color": 0,
            "flags": 20
          }
        },
        {
          "text": "two collusion mechanisms yield similar implications when I changes, differing implications when ρ varies, and",
          "bbox": [
            64.08000183105469,
            246.2974090576172,
            547.9227294921875,
            258.28216552734375
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.826972007751465,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "opposing implications when σu changes:",
          "bbox": [
            64.08000183105469,
            262.732421875,
            241.58274841308594,
            275.2785339355469
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "(i) If a collusive Nash equilibrium sustained by price-trigger strategies exists, the following holds in this",
          "bbox": [
            75.60000610351562,
            288.0546875,
            547.9164428710938,
            299.07232666015625
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "equilibrium when I is sufficiently large:",
          "bbox": [
            91.35299682617188,
            304.5694274902344,
            267.022216796875,
            315.478515625
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "ρ ↓,\nσu ↑,\nor\nI ↑\n=⇒\n∆C ↓\n(i.e., collusion capacity ↓)",
          "bbox": [
            114.50799560546875,
            328.7737731933594,
            421.93988037109375,
            346.28216552734375
          ],
          "font_info": {
            "font": "PazoMath-Italic",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "=⇒\nIC/I M ↑,\nLC/LM ↑,\nand\nE C/E M ↓\n(i.e., market efficiency ↑),\n(3.8)",
          "bbox": [
            144.8330078125,
            351.8827819824219,
            549.0103149414062,
            368.504638671875
          ],
          "font_info": {
            "font": "CMR10",
            "size": 11.367300033569336,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "where C and M represent the collusive Nash equilibrium and the perfect cartel benchmark, respectively.",
          "bbox": [
            91.35302734375,
            387.1344299316406,
            548.7496337890625,
            398.04351806640625
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "(ii) If a collusive experience-based equilibrium sustained by over-perceived aversion to noise trading risk",
          "bbox": [
            72.56703186035156,
            412.4566955566406,
            547.91650390625,
            423.4743347167969
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "exists, the following holds in this equilibrium:",
          "bbox": [
            91.35299682617188,
            428.971435546875,
            294.22943115234375,
            439.8805236816406
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "σu ↓,\nor\nI ↑\n=⇒\n∆C ↓\n(i.e., collusion capacity ↓)",
          "bbox": [
            114.50799560546875,
            453.17578125,
            390.5498962402344,
            470.6850891113281
          ],
          "font_info": {
            "font": "PazoMath-Italic",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "=⇒\nIC/I M ↑,\nLC/LM ↑,\nand\nE C/E M ↓\n(i.e., market efficiency ↑),\n(3.9)",
          "bbox": [
            144.83302307128906,
            476.2847900390625,
            549.0103149414062,
            492.9066467285156
          ],
          "font_info": {
            "font": "CMR10",
            "size": 11.367300033569336,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "where C and M represent the collusive experience-based equilibrium and the perfect cartel benchmark,",
          "bbox": [
            91.35299682617188,
            511.4606628417969,
            549.2830200195312,
            522.472900390625
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 11.012248992919922,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "respectively. The result for LC/LM holds when ξ is sufficiently large. Importantly, ρ does not affect ∆C,\nIC/I M, LC/LM, or E C/E M in this equilibrium.",
          "bbox": [
            91.35299682617188,
            524.0687255859375,
            549.2840576171875,
            555.505615234375
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.832467079162598,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "The detailed proof is provided in Online Appendix 2.6.",
          "bbox": [
            81.01600646972656,
            569.9974975585938,
            349.630859375,
            580.9066162109375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "4\nSimulation Experiments on AI Trading Algorithms",
          "bbox": [
            64.08000183105469,
            607.0527954101562,
            421.874267578125,
            621.3989868164062
          ],
          "font_info": {
            "font": "URWPalladioL-Bold",
            "size": 14.346199989318848,
            "color": 0,
            "flags": 20
          }
        },
        {
          "text": "As a proof of concept, this section presents simulation experiments to test whether informed AI",
          "bbox": [
            63.65399932861328,
            637.78271484375,
            547.9241943359375,
            648.8003540039062
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "speculators, equipped with autonomous model-free Q-learning algorithms, can achieve and sustain",
          "bbox": [
            64.08000183105469,
            654.2955322265625,
            547.9205322265625,
            665.2046508789062
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "collusive behavior under asymmetric information and an adaptive asset demand curve that endoge-",
          "bbox": [
            64.08000183105469,
            670.7383422851562,
            549.7290649414062,
            681.6365356445312
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.898184776306152,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "nously responds to their trading strategies. We specifically examine whether such collusive behavior",
          "bbox": [
            64.08000183105469,
            687.2086791992188,
            548.1435546875,
            698.0576171875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.848934173583984,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "by AI speculators can arise without explicit agreement, communication, or pre-programmed intent.",
          "bbox": [
            64.08000183105469,
            703.6005249023438,
            547.3968505859375,
            714.5096435546875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "19",
          "bbox": [
            300.54498291015625,
            765.1044921875,
            311.4541015625,
            776.0136108398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        }
      ]
    },
    {
      "page_number": 22,
      "text": "4.1\nAlgorithms as Experimental Subjects\nInformed AI Speculators.\nWe now analyze the behavior of the algorithms as experimental subjects.\nSpecifically, these experiments replace the theoretical agents, referred to as “informed speculators” in\nthe model, as detailed in Section 3, with Q-learning algorithms, as described in Section 2.\nThe dimensionality of the state vector st directly impacts the learning capacity and efficiency\nof Q-learning algorithms. High-dimensional state spaces create computational challenges, often\nrequiring deep learning techniques for function approximation and effective exploration.18 To ensure\nnumerical tractability, transparency, and highlight key insights, we select a minimal set of state\nvariables, st ≡{pt−1, vt−1, vt}, which capture the information advantage of informed speculators and\nenable AI collusion through price-trigger strategies, akin to the theoretical benchmark of the collusive\nNash equilibrium in Definition 3.2.19 In this setup, informed AI speculators make trading decisions in\nperiod t based on the current private signal vt and a one-period memory of the previous fundamental\nvalue vt−1 and price pt−1. In our simulation experiments, we find that expanding the state variable st\nby incorporating additional variables, such as lagged order flows or extended histories of market\nprices and fundamental values, strengthens tacit collusion among informed AI speculators through\nprice-trigger strategies, resulting in higher trading profits. By limiting st to pt−1, vt−1, and vt, we\nimpose a stringent bar for Q-learning algorithms to achieve AI collusion sustained by price-trigger\nstrategies.\nAdaptive Market Maker.\nThe market maker does not know the distributions of randomness. It\nstores and analyzes historical data on the asset’s value and price, the order flows from information-\ninsensitive investors, and the combined order flows from informed AI speculators and the noise\ntrader, i.e., Dt ≡{vt−τ, pt−τ, zt−τ, yt−τ}Tm\nτ=1, where Tm is a large integer. The market maker estimates\nthe demand curve of information-insensitive investors and the conditional expectation of the asset’s\nvalue, E [vt|yt], using the following linear regression models, respectively:\nzt−τ = ξ0 −ξ1pt−τ + ϵz,t−τ, and vt−τ = γ0 + γ1yt−τ + ϵv,t−τ, where τ = 1, · · · , Tm.\n(4.1)\nHere, ϵz,t−τ and ϵv,t−τ represent the residual terms from linear regressions. The estimated coefficients\nbξ0,t, bξ1,t, bγ0,t, and bγ1,t are based on the rolling-window dataset Dt in period t. The pricing rule\nadaptively follows the optimal policy through a plug-in procedure:\nbpt(y) = bγ0,t + bλty with bλt = θbγ1,t + bξ1,t\nθ + bξ2\n1,t\n,\n(4.2)\nwhere θ is defined in (3.3).\nOur results remain robust even when the market maker employs\nQ-learning algorithms (see Online Appendix 4.11).\nProtocol for Simulation-Based Experiments.\nWe summarize the experimental protocol as follows.\nAt t = 0, each informed AI speculator i ∈{1, · · · , I} is assigned with an arbitrary initial Q-matrix\n18RL algorithms, augmented by deep learning techniques to address high-dimensionality challenges, form the backbone\nof many successful real-world AI applications, including “AlphaGo.”\n19Tracking both pt−1 and vt−1, rather than just pt−1, helps informed AI speculators assess potential deviations in period\nt −1 by comparing pt−1 against vt−1.\n20\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "4.1\nAlgorithms as Experimental Subjects",
          "bbox": [
            64.08000183105469,
            51.22780227661133,
            295.15008544921875,
            63.18300247192383
          ],
          "font_info": {
            "font": "URWPalladioL-Bold",
            "size": 11.9552001953125,
            "color": 0,
            "flags": 20
          }
        },
        {
          "text": "Informed AI Speculators.\nWe now analyze the behavior of the algorithms as experimental subjects.",
          "bbox": [
            64.08000183105469,
            75.96916961669922,
            549.824951171875,
            87.1090087890625
          ],
          "font_info": {
            "font": "URWPalladioL-BoldItal",
            "size": 10.89272403717041,
            "color": 0,
            "flags": 22
          }
        },
        {
          "text": "Specifically, these experiments replace the theoretical agents, referred to as “informed speculators” in",
          "bbox": [
            64.08000183105469,
            92.71421813964844,
            547.9205932617188,
            103.51918029785156
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.80496597290039,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "the model, as detailed in Section 3, with Q-learning algorithms, as described in Section 2.\nThe dimensionality of the state vector st directly impacts the learning capacity and efficiency\nof Q-learning algorithms. High-dimensional state spaces create computational challenges, often",
          "bbox": [
            64.08000183105469,
            109.07453155517578,
            548.3417358398438,
            152.88531494140625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "requiring deep learning techniques for function approximation and effective exploration.18 To ensure\nnumerical tractability, transparency, and highlight key insights, we select a minimal set of state",
          "bbox": [
            64.08000183105469,
            154.49127197265625,
            547.9192504882812,
            185.75531005859375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.810471534729004,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "variables, st ≡{pt−1, vt−1, vt}, which capture the information advantage of informed speculators and",
          "bbox": [
            63.775001525878906,
            190.04275512695312,
            547.9244995117188,
            203.1383056640625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.810471534729004,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "enable AI collusion through price-trigger strategies, akin to the theoretical benchmark of the collusive",
          "bbox": [
            64.08000183105469,
            207.76412963867188,
            547.9188232421875,
            218.56358337402344
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Nash equilibrium in Definition 3.2.19 In this setup, informed AI speculators make trading decisions in",
          "bbox": [
            64.08000183105469,
            220.23916625976562,
            547.91650390625,
            234.9985809326172
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "period t based on the current private signal vt and a one-period memory of the previous fundamental",
          "bbox": [
            63.75299835205078,
            240.36643981933594,
            547.921142578125,
            253.07066345214844
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "value vt−1 and price pt−1. In our simulation experiments, we find that expanding the state variable st\nby incorporating additional variables, such as lagged order flows or extended histories of market",
          "bbox": [
            63.775001525878906,
            256.80242919921875,
            547.916259765625,
            284.3663330078125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "prices and fundamental values, strengthens tacit collusion among informed AI speculators through\nprice-trigger strategies, resulting in higher trading profits. By limiting st to pt−1, vt−1, and vt, we\nimpose a stringent bar for Q-learning algorithms to achieve AI collusion sustained by price-trigger",
          "bbox": [
            63.75299835205078,
            289.85369873046875,
            548.1361694335938,
            333.65753173828125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.920002937316895,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "strategies.",
          "bbox": [
            64.08000183105469,
            339.16650390625,
            112.62548828125,
            350.07562255859375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Adaptive Market Maker.\nThe market maker does not know the distributions of randomness. It",
          "bbox": [
            64.08000183105469,
            371.0277099609375,
            547.9251708984375,
            382.2953186035156
          ],
          "font_info": {
            "font": "URWPalladioL-BoldItal",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 22
          }
        },
        {
          "text": "stores and analyzes historical data on the asset’s value and price, the order flows from information-\ninsensitive investors, and the combined order flows from informed AI speculators and the noise",
          "bbox": [
            64.08000183105469,
            387.77880859375,
            549.733154296875,
            415.16632080078125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.925451278686523,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "trader, i.e., Dt ≡{vt−τ, pt−τ, zt−τ, yt−τ}Tm\nτ=1, where Tm is a large integer. The market maker estimates",
          "bbox": [
            64.08000183105469,
            417.3240051269531,
            547.9226684570312,
            434.802001953125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.898184776306152,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "the demand curve of information-insensitive investors and the conditional expectation of the asset’s",
          "bbox": [
            64.08000183105469,
            437.1082763671875,
            547.9153442382812,
            448.0010070800781
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.89272403717041,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "value, E [vt|yt], using the following linear regression models, respectively:",
          "bbox": [
            63.775001525878906,
            452.32379150390625,
            423.36114501953125,
            465.107177734375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "zt−τ = ξ0 −ξ1pt−τ + ϵz,t−τ, and vt−τ = γ0 + γ1yt−τ + ϵv,t−τ, where τ = 1, · · · , Tm.\n(4.1)",
          "bbox": [
            92.23300170898438,
            482.0517578125,
            549.0086669921875,
            495.62200927734375
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "Here, ϵz,t−τ and ϵv,t−τ represent the residual terms from linear regressions. The estimated coefficients\nbξ0,t, bξ1,t, bγ0,t, and bγ1,t are based on the rolling-window dataset Dt in period t. The pricing rule",
          "bbox": [
            64.08000183105469,
            513.066162109375,
            547.9243774414062,
            547.4743041992188
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "adaptively follows the optimal policy through a plug-in procedure:",
          "bbox": [
            64.08000183105469,
            545.8585205078125,
            390.5347900390625,
            556.7676391601562
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "bpt(y) = bγ0,t + bλty with bλt = θbγ1,t + bξ1,t",
          "bbox": [
            206.50900268554688,
            572.6961059570312,
            401.70709228515625,
            599.1932983398438
          ],
          "font_info": {
            "font": "CMEX10",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "θ + bξ2\n1,t\n,\n(4.2)",
          "bbox": [
            360.7669982910156,
            581.1425170898438,
            549.0164794921875,
            608.5142822265625
          ],
          "font_info": {
            "font": "PazoMath-Italic",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "where θ is defined in (3.3).\nOur results remain robust even when the market maker employs",
          "bbox": [
            63.62200164794922,
            617.3516845703125,
            547.9234619140625,
            629.2251586914062
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Q-learning algorithms (see Online Appendix 4.11).",
          "bbox": [
            64.08000183105469,
            633.864501953125,
            310.3965759277344,
            644.7736206054688
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Protocol for Simulation-Based Experiments.\nWe summarize the experimental protocol as follows.\nAt t = 0, each informed AI speculator i ∈{1, · · · , I} is assigned with an arbitrary initial Q-matrix",
          "bbox": [
            63.65399932861328,
            665.77783203125,
            549.823974609375,
            693.4283447265625
          ],
          "font_info": {
            "font": "URWPalladioL-BoldItal",
            "size": 10.94721508026123,
            "color": 0,
            "flags": 22
          }
        },
        {
          "text": "18RL algorithms, augmented by deep learning techniques to address high-dimensionality challenges, form the backbone\nof many successful real-world AI applications, including “AlphaGo.”\n19Tracking both pt−1 and vt−1, rather than just pt−1, helps informed AI speculators assess potential deviations in period\nt −1 by comparing pt−1 against vt−1.",
          "bbox": [
            64.08000183105469,
            701.49169921875,
            547.9241333007812,
            747.360107421875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 6.973800182342529,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "20",
          "bbox": [
            300.5450134277344,
            765.1044921875,
            311.4541320800781,
            776.0136108398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        }
      ]
    },
    {
      "page_number": 23,
      "text": "bQi,0 and state s0. Then, the economy evolves from t to t + 1 according to the following steps:\n(1) In period t, each informed AI speculator i independently enters exploration with probability εt\nor exploitation with probability 1 −εt, submitting order flow xi,t, as in (2.6).\n(2) The noise trader submits its order flow ut, which is randomly drawn from N(0, σ2\nu).\n(3) The market maker analyzes the historical data Dt ≡{vt−τ, pt−τ, zt−τ, yt−τ}Tm\nτ=1 to estimate bpt(y)\naccording to (4.2). Upon observing yt = ∑I\ni=1 xi,t + ut, the market price is set at pt = bpt(yt).\n(4) Observing pt, information-insensitive investors submit their aggregate order flow zt in accor-\ndance with (3.2). Each informed AI speculator i realizes its profits πi,t = (vt −pt)xi,t.\n(5) At the start of period t + 1, the state variable transitions from st = {pt−1, vt−1, vt} to st+1 =\n{pt, vt, vt+1}, where vt+1 is independently drawn from N(v, σ2\nv). Each informed AI speculator i\nupdates its Q-value for (st, xi,t) using the recursive rule in (2.4).\nMerits of Simulation-Based Experiments for Algorithms.\nThe interaction among (i) AI speculators\nusing Q-learning with lagged prices as endogenous state variables, (ii) an adaptive market maker\nlearning from historical data, and (iii) randomness from noise traders and stochastic asset values\nmakes it extremely difficult, if not impossible, to prove general results on convergence or long-run\nbehavior. As in prior work (e.g., Calvano et al., 2020), our simulation-based approach is well-suited to\nstudy algorithmic behavior, strategic interaction, and resulting equilibrium outcomes. First, no general\nconvergence results exist for environments of this complexity, let alone closed-form characterizations\nof their asymptotic behavior.\nSecond, although stochastic approximation theorems can, in principle, establish convergence in\ncertain simplified settings, they are generally not applicable to settings of this complexity. Moreover,\nthey rely on strict regularity conditions for the algorithms, such as decaying hyperparameters over\ntime, which are rarely satisfied in practice. For example, hyperparameters are often held constant\nin real-world applications.\nAs a result, the steady-state behavior observed through numerical\nconvergence may be more practically relevant than the theoretical limit derived under idealized\nconditions.20 In real-world applications, particularly in robotics and securities trading, RL algorithms\noperating in multi-agent environments face several practical challenges. These include the absence\nof theoretical guarantees on convergence and decriptions of equilibrium properties, the need for\ncostly exploration, the inherently slow pace of learning, and the high cost and limited availability\nof real-world data. These factors make real-time training impractical. Consequently, training RL\nalgorithms in simulation-based synthetic environments has become a widely adopted approach in\npractice. This aligns closely with the spirit of our simulation-based experiments. For example, hedge\nfunds often use simulated financial markets to train RL-based execution strategies before deploying\nthem in live trading, just as autonomous vehicles are first trained in virtual environments using\nsimulated data before operating in the real world.\nThird, even if a theoretical analysis of a multi-agent system with Q-learning algorithms in a\nrepeated game setting like ours were feasible, despite being widely regarded as intractable, the\n20Simulation-based algorithmic experiments fundamentally differ from numerical solutions of theoretical equilibria (e.g.,\nKubler and Schmedders, 2005; Dou et al., 2023; Duarte, Duarte and Silva, 2024; Hansen, Khorrami and Tourre, 2024).\n21\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "bQi,0 and state s0. Then, the economy evolves from t to t + 1 according to the following steps:",
          "bbox": [
            64.32500457763672,
            51.03406524658203,
            513.3358154296875,
            67.57627868652344
          ],
          "font_info": {
            "font": "CMEX10",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "(1) In period t, each informed AI speculator i independently enters exploration with probability εt\nor exploitation with probability 1 −εt, submitting order flow xi,t, as in (2.6).",
          "bbox": [
            73.17800903320312,
            76.65239715576172,
            547.3220825195312,
            105.2723388671875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "(2) The noise trader submits its order flow ut, which is randomly drawn from N(0, σ2\nu).",
          "bbox": [
            73.17807006835938,
            116.56420135498047,
            497.75732421875,
            131.0501251220703
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "(3) The market maker analyzes the historical data Dt ≡{vt−τ, pt−τ, zt−τ, yt−τ}Tm\nτ=1 to estimate bpt(y)",
          "bbox": [
            73.17807006835938,
            140.2180938720703,
            548.7368774414062,
            161.60630798339844
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "according to (4.2). Upon observing yt = ∑I\ni=1 xi,t + ut, the market price is set at pt = bpt(yt).",
          "bbox": [
            91.35299682617188,
            157.4001007080078,
            533.4013671875,
            178.0413055419922
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "(4) Observing pt, information-insensitive investors submit their aggregate order flow zt in accor-",
          "bbox": [
            73.17807006835938,
            184.94139099121094,
            549.7308349609375,
            197.69863891601562
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "dance with (3.2). Each informed AI speculator i realizes its profits πi,t = (vt −pt)xi,t.",
          "bbox": [
            91.35299682617188,
            200.35775756835938,
            503.4892883300781,
            213.7904052734375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "(5) At the start of period t + 1, the state variable transitions from st = {pt−1, vt−1, vt} to st+1 =\n{pt, vt, vt+1}, where vt+1 is independently drawn from N(v, σ2\nv). Each informed AI speculator i",
          "bbox": [
            73.17800903320312,
            225.49777221679688,
            547.790771484375,
            255.8363800048828
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "updates its Q-value for (st, xi,t) using the recursive rule in (2.4).",
          "bbox": [
            91.35299682617188,
            258.51507568359375,
            399.2193298339844,
            271.57135009765625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Merits of Simulation-Based Experiments for Algorithms.\nThe interaction among (i) AI speculators\nusing Q-learning with lagged prices as endogenous state variables, (ii) an adaptive market maker\nlearning from historical data, and (iii) randomness from noise traders and stochastic asset values\nmakes it extremely difficult, if not impossible, to prove general results on convergence or long-run",
          "bbox": [
            64.08000183105469,
            292.2691650390625,
            548.1388549804688,
            352.7386169433594
          ],
          "font_info": {
            "font": "URWPalladioL-BoldItal",
            "size": 10.89272403717041,
            "color": 0,
            "flags": 22
          }
        },
        {
          "text": "behavior. As in prior work (e.g., Calvano et al., 2020), our simulation-based approach is well-suited to",
          "bbox": [
            64.08000183105469,
            358.3231506347656,
            547.9188842773438,
            369.12261962890625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "study algorithmic behavior, strategic interaction, and resulting equilibrium outcomes. First, no general",
          "bbox": [
            64.08000183105469,
            374.7581481933594,
            547.9188232421875,
            385.5576171875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "convergence results exist for environments of this complexity, let alone closed-form characterizations",
          "bbox": [
            64.08000183105469,
            391.17340087890625,
            547.9160766601562,
            402.0003967285156
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.826972007751465,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "of their asymptotic behavior.\nSecond, although stochastic approximation theorems can, in principle, establish convergence in",
          "bbox": [
            64.08000183105469,
            407.5505065917969,
            547.9230346679688,
            434.9084777832031
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "certain simplified settings, they are generally not applicable to settings of this complexity. Moreover,\nthey rely on strict regularity conditions for the algorithms, such as decaying hyperparameters over\ntime, which are rarely satisfied in practice. For example, hyperparameters are often held constant\nin real-world applications.\nAs a result, the steady-state behavior observed through numerical\nconvergence may be more practically relevant than the theoretical limit derived under idealized",
          "bbox": [
            64.08000183105469,
            440.44403076171875,
            549.2786865234375,
            517.100341796875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.876322746276855,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "conditions.20 In real-world applications, particularly in robotics and securities trading, RL algorithms\noperating in multi-agent environments face several practical challenges. These include the absence\nof theoretical guarantees on convergence and decriptions of equilibrium properties, the need for\ncostly exploration, the inherently slow pace of learning, and the high cost and limited availability\nof real-world data. These factors make real-time training impractical. Consequently, training RL\nalgorithms in simulation-based synthetic environments has become a widely adopted approach in",
          "bbox": [
            64.08000183105469,
            518.711181640625,
            548.350341796875,
            615.7021484375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.80496597290039,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "practice. This aligns closely with the spirit of our simulation-based experiments. For example, hedge",
          "bbox": [
            63.75299835205078,
            621.2615356445312,
            547.9188232421875,
            632.093994140625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.832467079162598,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "funds often use simulated financial markets to train RL-based execution strategies before deploying\nthem in live trading, just as autonomous vehicles are first trained in virtual environments using",
          "bbox": [
            64.08000183105469,
            637.6532592773438,
            547.916259765625,
            665.017333984375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.89272403717041,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "simulated data before operating in the real world.\nThird, even if a theoretical analysis of a multi-agent system with Q-learning algorithms in a\nrepeated game setting like ours were feasible, despite being widely regarded as intractable, the",
          "bbox": [
            64.08000183105469,
            670.5125122070312,
            547.9165649414062,
            714.3223266601562
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "20Simulation-based algorithmic experiments fundamentally differ from numerical solutions of theoretical equilibria (e.g.,\nKubler and Schmedders, 2005; Dou et al., 2023; Duarte, Duarte and Silva, 2024; Hansen, Khorrami and Tourre, 2024).",
          "bbox": [
            64.08000183105469,
            723.8257446289062,
            549.0430297851562,
            745.5771484375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 6.973800182342529,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "21",
          "bbox": [
            300.54498291015625,
            765.1044921875,
            311.4541015625,
            776.0136108398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        }
      ]
    },
    {
      "page_number": 24,
      "text": "mathematical proofs would provide little insight into why or how algorithms reach a collusive\nequilibrium. This is because such analyses typically rely on stochastic approximation methods, which\nfocus on verifying high-level regularity conditions and technical details.21\nTo complement our simulation-based experiments across various trading environment specifica-\ntions in the general model, we provide clear intuitions and heuristic justifications for the numerical\nconvergence of multiple informed AI speculators using Q-learning algorithms, as well as for the\nsteady-state properties of the resulting AI trading equilibrium, within a simplified model. The results\nare presented in Sections 5 and 6, with heuristic justifications provided in Online Appendix 3.\n4.2\nNumerical Specifications\nWe detail the numerical setup of our simulations, including the discretization of state and action\nspaces, Q-matrix initialization, parameter selection, and convergence criteria.\nDiscretization of State and Action Spaces.\nWe approximate the distribution N(v, σv) using nv grid\npoints, V = {v1, · · · , vnv}, with equal probabilities assigned to each grid. The grid points are located\naccording to vk = v + σvΦ−1((2k −1)/(2nv)) for k = 1, · · · , nv, where Φ−1 is the inverse cumulative\ndensity function of the standard normal distribution.22 We discretize the choice space of informed AI\nspeculator i for order flow xi using grids based on the optimal trading strategies in two benchmarks:\nthe non-collusive Nash equilibrium, xN = (v −v)/[(I + 1)λ], and the perfect cartel benchmark,\nxM = (v −v)/(2Iλ). Specifically, we discretize the interval [xM −ι(xN −xM), xN + ι(xN −xM)] for\nv > v and [xN −ι(xM −xN), xM + ι(xM −xN)] for v < v into nx equally spaced grid points, denoted\nby X = {x1, · · · , xnx}. The parameter ι > 0 enables informed AI speculators to choose order flows\nthat exceed the boundaries set by the theoretical benchmarks xM and xN, offering flexibility to explore\nstrategies beyond these theoretical limits. The grid points of the market price p are determined\nsimilarly to those for xi, with adjustments to account for the noise trader’s impact on market prices.\nSpecifically, the upper bound is set at pH = v + λN \u0000I max{xM, xN} + 1.96σu\n\u0001\nand the lower bound\nat pL = v + λN \u0000I min{xM, xN} −1.96σu\n\u0001\n, corresponding to the 5% and 95% percentiles of the noise\ntrader’s order flow distribution, N(0, σu). The interval [pL −ι(pH −pL), pH + ι(pH −pL)] is then\ndiscretized into np grid points, denoted by P = {p1, · · · , pnp}.\nInitial Q-Matrix and States.\nWe initialize the Q-matrix at t = 0 with the discounted payoff that\ninformed AI speculator i would earn if other informed AI speculators randomize their actions\nuniformly over the grid points in X, and the noise trading flow is set to zero, which corresponds\nto the expected value of the distribution N(0, σ2\nu).23 Specifically, for each informed AI speculator\n21Recent studies have established convergence of Q-learning algorithms to (collusive) Nash equilibria in simplified\nmodels, typically in 2 × 2 Prisoner’s Dilemma settings (e.g., Cartea et al., 2022a; Possnig, 2024). These proofs rely heavily\non existing stochastic approximation results and focus on technical verification with little intuitive explanation of the\nalgorithmic mechanisms behind convergence.\n22The results remain robust under alternative discretization schemes.\n23Different initial values for the Q-matrix have minimal impact on the results. For example, assigning high initial values\nencourages Q-learning algorithms to explore all actions thoroughly in the early learning phase, as subsequent iterations\ngradually reduce these values toward their theoretical true levels. This approach accelerates the learning process and\neffectively facilitates thorough exploration early on and exploitation in later stages.\n22\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "mathematical proofs would provide little insight into why or how algorithms reach a collusive",
          "bbox": [
            64.08000183105469,
            52.01670455932617,
            547.9163818359375,
            63.03435516357422
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "equilibrium. This is because such analyses typically rely on stochastic approximation methods, which",
          "bbox": [
            64.08000183105469,
            68.60916137695312,
            547.9187622070312,
            79.40861511230469
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "focus on verifying high-level regularity conditions and technical details.21",
          "bbox": [
            64.08000183105469,
            83.11321258544922,
            421.58807373046875,
            95.87462615966797
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "To complement our simulation-based experiments across various trading environment specifica-",
          "bbox": [
            81.01599884033203,
            101.39661407470703,
            549.7357788085938,
            112.31116485595703
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.91455364227295,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "tions in the general model, we provide clear intuitions and heuristic justifications for the numerical\nconvergence of multiple informed AI speculators using Q-learning algorithms, as well as for the",
          "bbox": [
            64.08000183105469,
            117.81988525390625,
            547.9170532226562,
            145.2103271484375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.930895805358887,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "steady-state properties of the resulting AI trading equilibrium, within a simplified model. The results",
          "bbox": [
            64.08000183105469,
            150.78414916992188,
            547.9188842773438,
            161.58360290527344
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "are presented in Sections 5 and 6, with heuristic justifications provided in Online Appendix 3.",
          "bbox": [
            64.08000183105469,
            167.14051818847656,
            521.0840454101562,
            178.0496063232422
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "4.2\nNumerical Specifications",
          "bbox": [
            64.08000183105469,
            199.8207550048828,
            228.1650848388672,
            211.7759552001953
          ],
          "font_info": {
            "font": "URWPalladioL-Bold",
            "size": 11.9552001953125,
            "color": 0,
            "flags": 20
          }
        },
        {
          "text": "We detail the numerical setup of our simulations, including the discretization of state and action",
          "bbox": [
            63.534000396728516,
            224.7196502685547,
            547.9156494140625,
            235.7373046875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "spaces, Q-matrix initialization, parameter selection, and convergence criteria.",
          "bbox": [
            64.08000183105469,
            241.23255920410156,
            438.02203369140625,
            252.1416473388672
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Discretization of State and Action Spaces.\nWe approximate the distribution N(v, σv) using nv grid",
          "bbox": [
            64.08000183105469,
            273.2350769042969,
            547.9197998046875,
            286.8282165527344
          ],
          "font_info": {
            "font": "URWPalladioL-BoldItal",
            "size": 10.865375518798828,
            "color": 0,
            "flags": 22
          }
        },
        {
          "text": "points, V = {v1, · · · , vnv}, with equal probabilities assigned to each grid. The grid points are located",
          "bbox": [
            63.75299835205078,
            287.9858093261719,
            547.9215087890625,
            302.9731140136719
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.826972007751465,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "according to vk = v + σvΦ−1((2k −1)/(2nv)) for k = 1, · · · , nv, where Φ−1 is the inverse cumulative",
          "bbox": [
            64.08000183105469,
            303.2369079589844,
            547.9170532226562,
            319.52239990234375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.865375518798828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "density function of the standard normal distribution.22 We discretize the choice space of informed AI",
          "bbox": [
            64.08000183105469,
            319.7191467285156,
            547.9243774414062,
            334.4786376953125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "speculator i for order flow xi using grids based on the optimal trading strategies in two benchmarks:\nthe non-collusive Nash equilibrium, xN = (v −v)/[(I + 1)λ], and the perfect cartel benchmark,",
          "bbox": [
            64.08000183105469,
            339.847412109375,
            549.2882690429688,
            368.2671813964844
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.848934173583984,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "xM = (v −v)/(2Iλ). Specifically, we discretize the interval [xM −ι(xN −xM), xN + ι(xN −xM)] for",
          "bbox": [
            64.4020004272461,
            367.7388000488281,
            548.138671875,
            384.7021789550781
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "v > v and [xN −ι(xM −xN), xM + ι(xM −xN)] for v < v into nx equally spaced grid points, denoted\nby X = {x1, · · · , xnx}. The parameter ι > 0 enables informed AI speculators to choose order flows",
          "bbox": [
            64.08000183105469,
            384.1737976074219,
            547.92431640625,
            418.0191345214844
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "that exceed the boundaries set by the theoretical benchmarks xM and xN, offering flexibility to explore\nstrategies beyond these theoretical limits. The grid points of the market price p are determined",
          "bbox": [
            64.08000183105469,
            418.3301696777344,
            547.92333984375,
            449.5863342285156
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "similarly to those for xi, with adjustments to account for the noise trader’s impact on market prices.\nSpecifically, the upper bound is set at pH = v + λN \u0000\nI max{xM, xN} + 1.96σu\n\u0001\nand the lower bound",
          "bbox": [
            64.08000183105469,
            454.8934326171875,
            549.8292236328125,
            485.6083068847656
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "at pL = v + λN \u0000\nI min{xM, xN} −1.96σu\n\u0001\n, corresponding to the 5% and 95% percentiles of the noise\ntrader’s order flow distribution, N(0, σu). The interval [pL −ι(pH −pL), pH + ι(pH −pL)] is then",
          "bbox": [
            64.08000183105469,
            485.9620666503906,
            547.9197387695312,
            516.453369140625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.925451278686523,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "discretized into np grid points, denoted by P = {p1, · · · , pnp}.",
          "bbox": [
            64.08000183105469,
            518.0778198242188,
            365.4513244628906,
            533.3676147460938
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Initial Q-Matrix and States.\nWe initialize the Q-matrix at t = 0 with the discounted payoff that\ninformed AI speculator i would earn if other informed AI speculators randomize their actions\nuniformly over the grid points in X, and the noise trading flow is set to zero, which corresponds\nto the expected value of the distribution N(0, σ2\nu).23 Specifically, for each informed AI speculator",
          "bbox": [
            64.08000183105469,
            552.8250732421875,
            548.1337890625,
            615.8251342773438
          ],
          "font_info": {
            "font": "URWPalladioL-BoldItal",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 22
          }
        },
        {
          "text": "21Recent studies have established convergence of Q-learning algorithms to (collusive) Nash equilibria in simplified\nmodels, typically in 2 × 2 Prisoner’s Dilemma settings (e.g., Cartea et al., 2022a; Possnig, 2024). These proofs rely heavily\non existing stochastic approximation results and focus on technical verification with little intuitive explanation of the\nalgorithmic mechanisms behind convergence.\n22The results remain robust under alternative discretization schemes.\n23Different initial values for the Q-matrix have minimal impact on the results. For example, assigning high initial values\nencourages Q-learning algorithms to explore all actions thoroughly in the early learning phase, as subsequent iterations\ngradually reduce these values toward their theoretical true levels. This approach accelerates the learning process and\neffectively facilitates thorough exploration early on and exploitation in later stages.",
          "bbox": [
            64.08000183105469,
            623.896728515625,
            548.2693481445312,
            723.192138671875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 6.973800182342529,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "22",
          "bbox": [
            300.54498291015625,
            765.1044921875,
            311.4541015625,
            776.0136108398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        }
      ]
    },
    {
      "page_number": 25,
      "text": "i = 1, · · · , I, we set its initial Q-matrix bQi,0 at t = 0 as follows:\nbQi,0(s, x) =\n1\n(1 −ρ)nx ∑\nx−i∈X\nh\nv −(v + λN(x + (I −1)x−i))\ni\nx,\nfor s = (p, v, v) ∈P × V × V and x ∈X. The initial states of our simulation, s0 = {p−1, v−1, v0}, are\nrandomized uniformly over P × V × V.\nSpecification of Exploration Rates.\nWe consider the state-dependent ε-greedy scheme:\nεt(v) = e−βt(v),\n(4.3)\nwhere β > 0 governs the speed that informed AI speculators’ exploration rate diminishes over time\nand t(v) captures the number of times that the system visited v ∈V in the past.\nParameter Values.\nThe parameters used in our numerical experiments are categorized into four\ngroups based on their roles. First, “environment parameters” describe the underlying economic\nenvironment and, importantly, their values are unknown to both the informed AI speculators and\nthe market maker. In the baseline calibration, we set I = 2 and ξ = 500, and consider two different\nvalues for σu, which are σu = 10−1 and σu = 102, representing trading environments with low and\nhigh noise trading risk, respectively. Later, we examine the implications of varying these parameters.\nSecond, “preference parameters” include the subjective discount factor for informed AI specula-\ntors, ρ, and the market maker’s weight on the pricing error term, θ. We set ρ at a relatively high level,\nρ = 0.95, to reflect the high-frequency trading environment. We examine the implications of varying\nρ values in Section 6. We fix θ ≡0.1 as a universal constant throughout our simulation experiments.\nThird, “discretization parameters” detail the methods used to discretize the system for simulation\nexperiments. We set nv = 10. Under this discretization, the standard deviation of vt is bσv =\nq\nn−1\nv\n∑nv\nk=1(vk −v)2 = 0.938, which is close to the theoretical value σv = 1.24 We set ι = 0.1, nx = 15,\nand np = 31.25 We set Tm = 10, 000 for the market maker. Increasing Tm does not alter any results.\nLastly, “hyperparameters” consist of α and β. Like in any machine learning algorithms, hyperpa-\nrameters (or tuning parameters) are crucial for controlling the learning process of RL algorithms. In\nour baseline calibration, we set α = 0.01 and β = 5 × 10−7. All results are robust to choosing different\nvalues of α and β so long as they are in the reasonable range that ensures sufficiently good learning\noutcomes. Our baseline choice of β = 5 × 10−7 implies that any action x ∈X is, on average, visited\njust due to random exploration by nv\nnx\n1\n1 −exp(−5 × 10−7) ≈1, 333, 333 times before exploration\ncompletes. In Online Appendix 4.12, we conduct experiments with varying values of α and β. We\nalso study scenarios where informed AI speculators adopt different values of α. In Online Appendix\n4.13, we consider two-tier Meta Q-learning algorithms that enable informed AI speculators to learn\nthe optimal α for the lower-tier agent as part of the upper-tier agent’s optimal decision.\n24In the remainder of this paper, the non-collusive Nash equilibrium and perfect cartel benchmark are computed using\nbσv, to ensure consistency with the discretization scheme of vt used in the simulation experiments.\n25Our choice of np ≈2nx ensures that, all else equal, a one-grid point change in one informed AI speculator’s order flow\nwill result in a change in price pt over the grid defined by P.\n23\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "i = 1, · · · , I, we set its initial Q-matrix bQi,0 at t = 0 as follows:",
          "bbox": [
            64.13999938964844,
            50.88680648803711,
            364.10162353515625,
            70.14530944824219
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "bQi,0(s, x) =\n1\n(1 −ρ)nx ∑\nx−i∈X",
          "bbox": [
            159.4820098876953,
            77.14453887939453,
            290.4392395019531,
            106.8650894165039
          ],
          "font_info": {
            "font": "CMEX10",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "h\nv −(v + λN(x + (I −1)x−i))\ni\nx,",
          "bbox": [
            292.3980407714844,
            79.55713653564453,
            452.76324462890625,
            96.3872299194336
          ],
          "font_info": {
            "font": "CMEX10",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "for s = (p, v, v) ∈P × V × V and x ∈X. The initial states of our simulation, s0 = {p−1, v−1, v0}, are",
          "bbox": [
            64.08000183105469,
            119.13481140136719,
            547.9232788085938,
            133.87738037109375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.85989761352539,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "randomized uniformly over P × V × V.",
          "bbox": [
            64.08000183105469,
            135.56980895996094,
            259.33526611328125,
            149.22361755371094
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Specification of Exploration Rates.\nWe consider the state-dependent ε-greedy scheme:",
          "bbox": [
            64.08000183105469,
            171.13107299804688,
            491.3342590332031,
            183.17420959472656
          ],
          "font_info": {
            "font": "URWPalladioL-BoldItal",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 22
          }
        },
        {
          "text": "εt(v) = e−βt(v),\n(4.3)",
          "bbox": [
            272.43603515625,
            197.82687377929688,
            549.0133056640625,
            213.8934326171875
          ],
          "font_info": {
            "font": "PazoMath-Italic",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "where β > 0 governs the speed that informed AI speculators’ exploration rate diminishes over time",
          "bbox": [
            63.62200164794922,
            229.77410888671875,
            547.9224243164062,
            242.6302032470703
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.920002937316895,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "and t(v) captures the number of times that the system visited v ∈V in the past.",
          "bbox": [
            64.08000183105469,
            244.5248260498047,
            453.1656799316406,
            258.17864990234375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Parameter Values.\nThe parameters used in our numerical experiments are categorized into four\ngroups based on their roles. First, “environment parameters” describe the underlying economic\nenvironment and, importantly, their values are unknown to both the informed AI speculators and\nthe market maker. In the baseline calibration, we set I = 2 and ξ = 500, and consider two different\nvalues for σu, which are σu = 10−1 and σu = 102, representing trading environments with low and",
          "bbox": [
            63.775001525878906,
            280.0057373046875,
            548.1397705078125,
            358.01739501953125
          ],
          "font_info": {
            "font": "URWPalladioL-BoldItal",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 22
          }
        },
        {
          "text": "high noise trading risk, respectively. Later, we examine the implications of varying these parameters.",
          "bbox": [
            64.08000183105469,
            362.5516662597656,
            549.5787353515625,
            373.4006042480469
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.848934173583984,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Second, “preference parameters” include the subjective discount factor for informed AI specula-",
          "bbox": [
            81.01599884033203,
            378.9396057128906,
            549.735595703125,
            389.8541564941406
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.91455364227295,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "tors, ρ, and the market maker’s weight on the pricing error term, θ. We set ρ at a relatively high level,",
          "bbox": [
            64.08000183105469,
            395.4581604003906,
            549.2860717773438,
            407.1751708984375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "ρ = 0.95, to reflect the high-frequency trading environment. We examine the implications of varying",
          "bbox": [
            64.21600341796875,
            410.75408935546875,
            547.9163208007812,
            423.61016845703125
          ],
          "font_info": {
            "font": "PazoMath-Italic",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "ρ values in Section 6. We fix θ ≡0.1 as a universal constant throughout our simulation experiments.",
          "bbox": [
            64.21600341796875,
            427.0417785644531,
            549.8035278320312,
            440.045166015625
          ],
          "font_info": {
            "font": "PazoMath-Italic",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "Third, “discretization parameters” detail the methods used to discretize the system for simulation\nexperiments. We set nv = 10. Under this discretization, the standard deviation of vt is bσv =\nq",
          "bbox": [
            64.08000183105469,
            444.7631530761719,
            547.9204711914062,
            484.0832824707031
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "n−1\nv\n∑nv\nk=1(vk −v)2 = 0.938, which is close to the theoretical value σv = 1.24 We set ι = 0.1, nx = 15,",
          "bbox": [
            75.39800262451172,
            474.757080078125,
            549.283935546875,
            492.8433532714844
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "and np = 31.25 We set Tm = 10, 000 for the market maker. Increasing Tm does not alter any results.",
          "bbox": [
            64.08000183105469,
            491.4455261230469,
            540.8613891601562,
            507.95062255859375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Lastly, “hyperparameters” consist of α and β. Like in any machine learning algorithms, hyperpa-",
          "bbox": [
            81.01599884033203,
            511.8758239746094,
            549.7344970703125,
            523.6361694335938
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.85989761352539,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "rameters (or tuning parameters) are crucial for controlling the learning process of RL algorithms. In",
          "bbox": [
            64.08000183105469,
            528.2911987304688,
            547.91943359375,
            539.178466796875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.887259483337402,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "our baseline calibration, we set α = 0.01 and β = 5 × 10−7. All results are robust to choosing different",
          "bbox": [
            64.08000183105469,
            541.975830078125,
            547.9234008789062,
            556.5061645507812
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "values of α and β so long as they are in the reasonable range that ensures sufficiently good learning",
          "bbox": [
            63.775001525878906,
            561.1533203125,
            547.919189453125,
            572.941162109375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.898184776306152,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "outcomes. Our baseline choice of β = 5 × 10−7 implies that any action x ∈X is, on average, visited\njust due to random exploration by nv\nnx\n1\n1 −exp(−5 × 10−7) ≈1, 333, 333 times before exploration",
          "bbox": [
            64.08000183105469,
            573.5980834960938,
            547.91943359375,
            612.8016357421875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.941778182983398,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "completes. In Online Appendix 4.12, we conduct experiments with varying values of α and β. We",
          "bbox": [
            64.08000183105469,
            613.7797241210938,
            547.9215087890625,
            625.6531982421875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "also study scenarios where informed AI speculators adopt different values of α. In Online Appendix",
          "bbox": [
            64.08000183105469,
            630.339599609375,
            548.2073364257812,
            642.088134765625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.843446731567383,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "4.13, we consider two-tier Meta Q-learning algorithms that enable informed AI speculators to learn",
          "bbox": [
            64.08000183105469,
            646.716796875,
            547.9168701171875,
            657.6422729492188
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.925451278686523,
            "color": 856203,
            "flags": 4
          }
        },
        {
          "text": "the optimal α for the lower-tier agent as part of the upper-tier agent’s optimal decision.",
          "bbox": [
            64.08000183105469,
            663.1635131835938,
            487.7461242675781,
            674.9591674804688
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "24In the remainder of this paper, the non-collusive Nash equilibrium and perfect cartel benchmark are computed using\nbσv, to ensure consistency with the discretization scheme of vt used in the simulation experiments.\n25Our choice of np ≈2nx ensures that, all else equal, a one-grid point change in one informed AI speculator’s order flow\nwill result in a change in price pt over the grid defined by P.",
          "bbox": [
            63.702999114990234,
            683.8677368164062,
            548.2984008789062,
            729.3741455078125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 6.973800182342529,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "23",
          "bbox": [
            300.54498291015625,
            765.1044921875,
            311.4541015625,
            776.0136108398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        }
      ]
    },
    {
      "page_number": 26,
      "text": "Criterion for Numerical Convergence.\nEach experiment contains Nsim = 1, 000 independent simula-\ntion sessions. We adopt a stringent criterion for convergence: all informed AI speculators’ optimal\nstrategies must remain unchanged for 1, 000, 000 consecutive periods within a single session, and all\nNsim sessions must continue running until each meets this convergence condition. The number of\nperiods required for convergence varies substantially across experiments, depending on parameter\nvalues, and can also differ significantly across sessions within the same experiment. Across simulation\nexperiments, convergence occurs within a range of approximately 20 million to 50 billion periods.26\n5\nAI Trading Equilibrium: Outcomes from Simulation Experiments\nIn this section, we present the results of simulation experiments that examine the behavior of AI-\npowered trading algorithms within a theoretical laboratory framework and explore the properties of\nAI trading equilibrium. Building on the theoretical benchmarks in Sections 3.3 and 3.4, Section 5.1\nillustrates the exploration-exploitation tradeoff in RL algorithms that underpins the two algorithmic\nmechanisms driving AI equilibria, and Section 5.2 provides an overview of simulation results across\nvarious cases defined by different levels of σu and ξ. Section 5.3 presents simulation experiments in\ntrading environments with a strong presence of information-insensitive investors (ξ is large relative\nto θ). In contrast, Section 5.4 focuses on simulation experiments in environments with a minimal\npresence of information-insensitive investors (ξ is small relative to θ). Section 5.5 further elaborates\non the intuitions behind how AI collusion arises through two distinct algorithmic mechanisms\ncorresponding to the two economic mechanisms. Finally, Section 5.6 provides a discussion on the\nrole of information-insensitive investors.\n5.1\nTwo Distinct Algorithmic Mechanisms behind AI Collusion\nParallel to the two economic mechanisms underlying collusive equilibrium in trading, as defined in\nDefinitions 3.2 and 3.3, our simulation experiments with Q-learning algorithms reveal two distinct\nalgorithmic mechanisms through which informed AI speculators can autonomously learn to achieve\na collusive trading equilibrium. The first mechanism is AI collusion via price-trigger strategies,\napproximating the collusive Nash equilibrium sustained by such strategies, as defined in Definition\n3.2. The second is AI collusion driven by over-pruning bias in learning, which mirrors the collusive\nexperience-based equilibrium arising from a learning bias caused by over-perceived aversion to noise\ntrading risk, as defined in Definition 3.3.\nWhich algorithmic mechanism prevails, and consequently which type of AI equilibrium emerges,\ndepends on the effectiveness of the exploration-exploitation tradeoff in the RL algorithm. Similar to\nthe bias-variance tradeoff in supervised learning and high-dimensional statistics, this tradeoff aims to\nbalance pruning the action space and reducing outcome variability. In RL, exploration (i.e., trying\nnew actions) is essential to minimize bias in estimating the optimal action, while exploitation (i.e.,\nselecting the optimal actions based on past experience) reduces noise in received rewards, thereby\nlowering variability in the estimation of the optimal action. Similar to shrinkage techniques in\n26Our programs are written in C++, using −O2 to optimize the compiling process. We use a high-powered computing\nserver cluster with 400 CPU cores. Completing all simulation sessions in one experiment can take up to 6 hours.\n24\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "Criterion for Numerical Convergence.\nEach experiment contains Nsim = 1, 000 independent simula-\ntion sessions. We adopt a stringent criterion for convergence: all informed AI speculators’ optimal",
          "bbox": [
            64.08000183105469,
            51.03412628173828,
            549.7352294921875,
            79.46115112304688
          ],
          "font_info": {
            "font": "URWPalladioL-BoldItal",
            "size": 10.881793022155762,
            "color": 0,
            "flags": 22
          }
        },
        {
          "text": "strategies must remain unchanged for 1, 000, 000 consecutive periods within a single session, and all",
          "bbox": [
            64.08000183105469,
            84.98902893066406,
            547.9176635742188,
            95.8653564453125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.876322746276855,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Nsim sessions must continue running until each meets this convergence condition. The number of\nperiods required for convergence varies substantially across experiments, depending on parameter",
          "bbox": [
            63.75299835205078,
            101.21141815185547,
            548.1395263671875,
            128.7584686279297
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "values, and can also differ significantly across sessions within the same experiment. Across simulation",
          "bbox": [
            63.775001525878906,
            134.34915161132812,
            547.923828125,
            145.1486053466797
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "experiments, convergence occurs within a range of approximately 20 million to 50 billion periods.26",
          "bbox": [
            64.08000183105469,
            148.8531951904297,
            547.2830810546875,
            161.61306762695312
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.903643608093262,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "5\nAI Trading Equilibrium: Outcomes from Simulation Experiments",
          "bbox": [
            64.07998657226562,
            187.76072692871094,
            518.28076171875,
            202.10691833496094
          ],
          "font_info": {
            "font": "URWPalladioL-Bold",
            "size": 14.346199989318848,
            "color": 0,
            "flags": 20
          }
        },
        {
          "text": "In this section, we present the results of simulation experiments that examine the behavior of AI-",
          "bbox": [
            64.08000183105469,
            218.49070739746094,
            549.72998046875,
            229.50836181640625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "powered trading algorithms within a theoretical laboratory framework and explore the properties of\nAI trading equilibrium. Building on the theoretical benchmarks in Sections 3.3 and 3.4, Section 5.1",
          "bbox": [
            63.65399932861328,
            235.03883361816406,
            548.4629516601562,
            262.3706970214844
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.85989761352539,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "illustrates the exploration-exploitation tradeoff in RL algorithms that underpins the two algorithmic",
          "bbox": [
            64.08000183105469,
            267.89312744140625,
            547.9215698242188,
            278.7749328613281
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.881793022155762,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "mechanisms driving AI equilibria, and Section 5.2 provides an overview of simulation results across",
          "bbox": [
            64.08000183105469,
            284.3398742675781,
            547.9237060546875,
            295.2052307128906
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.865375518798828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "various cases defined by different levels of σu and ξ. Section 5.3 presents simulation experiments in",
          "bbox": [
            63.775001525878906,
            300.7356872558594,
            547.9171142578125,
            313.2926940917969
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.920002937316895,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "trading environments with a strong presence of information-insensitive investors (ξ is large relative\nto θ). In contrast, Section 5.4 focuses on simulation experiments in environments with a minimal",
          "bbox": [
            64.08000183105469,
            317.17852783203125,
            547.9210815429688,
            345.41015625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "presence of information-insensitive investors (ξ is small relative to θ). Section 5.5 further elaborates\non the intuitions behind how AI collusion arises through two distinct algorithmic mechanisms\ncorresponding to the two economic mechanisms. Finally, Section 5.6 provides a discussion on the",
          "bbox": [
            63.75299835205078,
            350.02996826171875,
            547.9229125976562,
            393.8593444824219
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.936338424682617,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "role of information-insensitive investors.",
          "bbox": [
            64.08000183105469,
            399.3545227050781,
            260.56378173828125,
            410.2636413574219
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "5.1\nTwo Distinct Algorithmic Mechanisms behind AI Collusion",
          "bbox": [
            64.08000183105469,
            432.0347900390625,
            421.5165710449219,
            443.989990234375
          ],
          "font_info": {
            "font": "URWPalladioL-Bold",
            "size": 11.9552001953125,
            "color": 0,
            "flags": 20
          }
        },
        {
          "text": "Parallel to the two economic mechanisms underlying collusive equilibrium in trading, as defined in\nDefinitions 3.2 and 3.3, our simulation experiments with Q-learning algorithms reveal two distinct",
          "bbox": [
            64.08000183105469,
            457.01446533203125,
            547.9225463867188,
            484.3756103515625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.903643608093262,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "algorithmic mechanisms through which informed AI speculators can autonomously learn to achieve\na collusive trading equilibrium. The first mechanism is AI collusion via price-trigger strategies,",
          "bbox": [
            64.08000183105469,
            489.92071533203125,
            549.284912109375,
            517.25634765625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.854416847229004,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "approximating the collusive Nash equilibrium sustained by such strategies, as defined in Definition",
          "bbox": [
            64.08000183105469,
            522.7554321289062,
            547.9161376953125,
            533.6591186523438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.903643608093262,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "3.2. The second is AI collusion driven by over-pruning bias in learning, which mirrors the collusive",
          "bbox": [
            64.08000183105469,
            539.1787109375,
            547.915283203125,
            550.0986938476562
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.920002937316895,
            "color": 856203,
            "flags": 4
          }
        },
        {
          "text": "experience-based equilibrium arising from a learning bias caused by over-perceived aversion to noise",
          "bbox": [
            64.08000183105469,
            555.6922607421875,
            547.920654296875,
            566.5027465820312
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.810471534729004,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "trading risk, as defined in Definition 3.3.",
          "bbox": [
            64.08000183105469,
            572.0565185546875,
            261.13104248046875,
            582.9656372070312
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Which algorithmic mechanism prevails, and consequently which type of AI equilibrium emerges,",
          "bbox": [
            81.01599884033203,
            588.5425415039062,
            549.28515625,
            599.3804931640625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.837958335876465,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "depends on the effectiveness of the exploration-exploitation tradeoff in the RL algorithm. Similar to",
          "bbox": [
            64.08000183105469,
            604.931396484375,
            547.916015625,
            615.8350830078125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.903643608093262,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "the bias-variance tradeoff in supervised learning and high-dimensional statistics, this tradeoff aims to\nbalance pruning the action space and reducing outcome variability. In RL, exploration (i.e., trying\nnew actions) is essential to minimize bias in estimating the optimal action, while exploitation (i.e.,\nselecting the optimal actions based on past experience) reduces noise in received rewards, thereby\nlowering variability in the estimation of the optimal action. Similar to shrinkage techniques in",
          "bbox": [
            64.08000183105469,
            621.441162109375,
            549.2849731445312,
            698.0423583984375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "26Our programs are written in C++, using −O2 to optimize the compiling process. We use a high-powered computing\nserver cluster with 400 CPU cores. Completing all simulation sessions in one experiment can take up to 6 hours.",
          "bbox": [
            64.08000183105469,
            707.8077392578125,
            547.9208374023438,
            729.5591430664062
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 6.973800182342529,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "24",
          "bbox": [
            300.54498291015625,
            765.1044921875,
            311.4541015625,
            776.0136108398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        }
      ]
    },
    {
      "page_number": 27,
      "text": "supervised learning and high-dimensional statistics, exploitation narrows the choice space to improve\nconvergence speed and reduce variance, although it may introduce some bias.\nDrawing on the theoretical results establishing the existence of collusive equilibria sustained\nby two distinct economic mechanisms, as summarized in Propositions 3.1 and 3.2, the type of\nAI equilibrium reached by the system of RL algorithms after convergence depends on two key\nfactors: the risk of noise trading flows, captured by σu, and the presence of information-insensitive\ninvestors, measured by ξ. Together, these parameters determine the informativeness of market prices,\nwhich is shaped by the underlying economic structure and, in turn, affects the effectiveness of the\nexploration-exploitation tradeoff.\nAI collusion through the price-trigger-strategy mechanism becomes the dominant steady state\nwhen the exploration-exploitation tradeoff functions effectively, guiding learning without introducing\nsignificant bias. In this setting, a system of algorithms autonomously learns to sustain a collusive\nAI equilibrium that approximates a Nash equilibrium, even though each algorithm unilaterally\nmaximizes its own trading profit. Crucially, each algorithm not only learns how the state vector\n(i.e., the “environment”) responds to its trading behavior in effect but also integrates this knowledge\ninto its profit optimization process. This dynamic sophistication allows the algorithms to converge\nto a steady-state equilibrium that extends beyond the non-collusive Nash equilibrium. For this\nexploration-exploitation tradeoff to function effectively, price informativeness must be sufficiently\nhigh, which in turn requires a low σu and a high ξ. Intuitively, when price informativeness is high,\nthe information obtained from occasional exploration is more reliable. This allows exploitation to\nbetter focus on optimal trading strategies, while any bias introduced by exploitation can be effectively\ncorrected through exploration. Further intuition is provided in Section 5.5.\nAI collusion through the over-pruning learning bias mechanism emerges as the dominant steady\nstate when the exploration-exploitation tradeoff fails to effectively guide the estimation of optimal\ntrading strategies, resulting in significant bias. In this case, the system of algorithms does not converge\nto a collusive AI equilibrium that approximates a Nash equilibrium. Instead, an imbalance between\nexploration and exploitation causes the systematic over-pruning of aggressive trading strategies,\nresulting in a collusive AI equilibrium driven by over-pruning bias. This outcome closely parallels\nthe theoretical collusive experience-based equilibrium, which arises from a learning bias induced by\nover-perceived aversion to noise trading risk. The exploration-exploitation tradeoff fails to effectively\nguide estimation when price informativeness is not sufficiently high, which can result from a high\nσu or a low ξ. Importantly, as long as ξ is low, price informativeness remains endogenously low,\nregardless of the level of σu. Intuitively, when price informativeness is low, information obtained\nfrom occasional exploration can be misleading, causing exploitation to become trapped in unilaterally\nsuboptimal strategies that are collectively supra-competitive. In such cases, the significant bias\nintroduced by exploitation cannot be effectively corrected through exploration. Further intuition is\nprovided in Section 5.5.\nTo illustrate how over-pruning bias arises from an imbalance between exploration and exploitation,\nconsider environments with low ξ or high σu, where market prices and trading profits are predomi-\nnantly driven by noise trading shocks ut. In these settings, the behavior of RL algorithms depends\ncritically on how they process feedback from such shocks. Exploitation introduces asymmetries into\nthe learning process, depending on whether a shock is adverse or beneficial. An adverse noise trading\n25\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "supervised learning and high-dimensional statistics, exploitation narrows the choice space to improve",
          "bbox": [
            64.08000183105469,
            52.17318344116211,
            547.9187622070312,
            62.97264099121094
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "convergence speed and reduce variance, although it may introduce some bias.\nDrawing on the theoretical results establishing the existence of collusive equilibria sustained\nby two distinct economic mechanisms, as summarized in Propositions 3.1 and 3.2, the type of\nAI equilibrium reached by the system of RL algorithms after convergence depends on two key\nfactors: the risk of noise trading flows, captured by σu, and the presence of information-insensitive",
          "bbox": [
            63.65399932861328,
            68.53052520751953,
            548.3471069335938,
            146.06617736816406
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "investors, measured by ξ. Together, these parameters determine the informativeness of market prices,\nwhich is shaped by the underlying economic structure and, in turn, affects the effectiveness of the",
          "bbox": [
            63.62200164794922,
            150.7801971435547,
            549.2832641601562,
            178.0787811279297
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.80496597290039,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "exploration-exploitation tradeoff.\nAI collusion through the price-trigger-strategy mechanism becomes the dominant steady state",
          "bbox": [
            64.08000183105469,
            183.5755157470703,
            547.9165649414062,
            210.95135498046875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "when the exploration-exploitation tradeoff functions effectively, guiding learning without introducing\nsignificant bias. In this setting, a system of algorithms autonomously learns to sustain a collusive\nAI equilibrium that approximates a Nash equilibrium, even though each algorithm unilaterally\nmaximizes its own trading profit. Crucially, each algorithm not only learns how the state vector",
          "bbox": [
            63.62200164794922,
            216.52517700195312,
            548.3472290039062,
            276.69134521484375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "(i.e., the “environment”) responds to its trading behavior in effect but also integrates this knowledge\ninto its profit optimization process. This dynamic sophistication allows the algorithms to converge\nto a steady-state equilibrium that extends beyond the non-collusive Nash equilibrium. For this\nexploration-exploitation tradeoff to function effectively, price informativeness must be sufficiently\nhigh, which in turn requires a low σu and a high ξ. Intuitively, when price informativeness is high,\nthe information obtained from occasional exploration is more reliable. This allows exploitation to",
          "bbox": [
            63.720001220703125,
            282.22967529296875,
            549.2808837890625,
            375.3023376464844
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.848934173583984,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "better focus on optimal trading strategies, while any bias introduced by exploitation can be effectively",
          "bbox": [
            64.08000183105469,
            380.87615966796875,
            548.3464965820312,
            391.67559814453125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "corrected through exploration. Further intuition is provided in Section 5.5.",
          "bbox": [
            64.08000183105469,
            397.2325134277344,
            426.8076477050781,
            408.1416320800781
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "AI collusion through the over-pruning learning bias mechanism emerges as the dominant steady\nstate when the exploration-exploitation tradeoff fails to effectively guide the estimation of optimal",
          "bbox": [
            64.08000183105469,
            413.6988830566406,
            548.345703125,
            441.03466796875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.865375518798828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "trading strategies, resulting in significant bias. In this case, the system of algorithms does not converge",
          "bbox": [
            64.08000183105469,
            446.6171569824219,
            547.9189453125,
            457.4166259765625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "to a collusive AI equilibrium that approximates a Nash equilibrium. Instead, an imbalance between\nexploration and exploitation causes the systematic over-pruning of aggressive trading strategies,\nresulting in a collusive AI equilibrium driven by over-pruning bias. This outcome closely parallels",
          "bbox": [
            64.08000183105469,
            462.9774475097656,
            549.2849731445312,
            506.7756652832031
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.903643608093262,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "the theoretical collusive experience-based equilibrium, which arises from a learning bias induced by",
          "bbox": [
            64.08000183105469,
            512.298095703125,
            548.3448486328125,
            523.1798706054688
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.881793022155762,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "over-perceived aversion to noise trading risk. The exploration-exploitation tradeoff fails to effectively\nguide estimation when price informativeness is not sufficiently high, which can result from a high",
          "bbox": [
            64.08000183105469,
            528.7684936523438,
            548.3428344726562,
            556.0791625976562
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.832467079162598,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "σu or a low ξ. Importantly, as long as ξ is low, price informativeness remains endogenously low,\nregardless of the level of σu. Intuitively, when price informativeness is low, information obtained",
          "bbox": [
            64.08000183105469,
            561.5067138671875,
            549.2880249023438,
            589.815185546875
          ],
          "font_info": {
            "font": "PazoMath-Italic",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "from occasional exploration can be misleading, causing exploitation to become trapped in unilaterally\nsuboptimal strategies that are collectively supra-competitive. In such cases, the significant bias\nintroduced by exploitation cannot be effectively corrected through exploration. Further intuition is",
          "bbox": [
            64.08000183105469,
            594.5331420898438,
            548.346435546875,
            638.2490234375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "provided in Section 5.5.",
          "bbox": [
            63.75299835205078,
            643.759521484375,
            178.5930633544922,
            654.6686401367188
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "To illustrate how over-pruning bias arises from an imbalance between exploration and exploitation,",
          "bbox": [
            81.01599884033203,
            660.2731323242188,
            549.288818359375,
            671.0726318359375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "consider environments with low ξ or high σu, where market prices and trading profits are predomi-\nnantly driven by noise trading shocks ut. In these settings, the behavior of RL algorithms depends",
          "bbox": [
            64.08000183105469,
            676.6295166015625,
            549.7289428710938,
            704.6411743164062
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "critically on how they process feedback from such shocks. Exploitation introduces asymmetries into",
          "bbox": [
            64.08000183105469,
            709.5200805664062,
            547.9215698242188,
            720.40185546875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.881793022155762,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "the learning process, depending on whether a shock is adverse or beneficial. An adverse noise trading",
          "bbox": [
            64.08000183105469,
            726.0140991210938,
            547.9188842773438,
            736.8135986328125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "25",
          "bbox": [
            300.5450134277344,
            765.1044921875,
            311.4541320800781,
            776.0136108398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        }
      ]
    },
    {
      "page_number": 28,
      "text": "shock moves in the same direction as the informed AI speculator’s trade, causing substantial trading\nlosses and sharply reducing the estimated Q-value of the chosen action. In contrast, a beneficial\nshock moves in the opposite direction, generating significant trading profits and potentially inflating\nthe estimated Q-value, though this overestimation is more likely to be corrected over time through\ncontinued and repeated exploitation.\nMore precisely, following an adverse noise trading shock, the algorithm often classifies the\nchosen strategy as a “disastrous action,” assigning it a significantly low Q-value. Exploitation\nthen discourages the algorithm from revisiting this strategy in subsequent iterations, reinforcing the\ndownward bias and preventing correction for such off-equilibrium-path actions. In contrast, following\na beneficial shock, the algorithm tends to label the strategy as a “fantastic action” and assigns it\nan inflated Q-value. Because exploitation promotes repeated use of high-Q-value strategies, the\nalgorithm continues to select and update this strategy, eventually correcting any initial overestimation.\nAggressive strategies, by their nature, are more exposed to noise trading shocks, making them\nespecially vulnerable to this asymmetric learning dynamic. As a result, they tend to be persistently\nundervalued and prematurely pruned from the set of candidate optimal strategies, reinforcing the\nover-pruning bias. Consequently, informed AI speculators gravitate toward more conservative trading\nstrategies, consistent with the collusive behavior described in Definitions 3.1 and 3.3.\nOne way to interpret the asymmetric effect of exploitation is that it effectively makes RL algo-\nrithms risk-averse to randomness in their rewards. In decision theory, risk aversion arises from\nthe asymmetric impact of adverse and beneficial shocks. Similarly, in RL, exploitation discourages\nrevisiting poorly rated strategies while reinforcing successful ones, leading to an asymmetric impact\nof adverse and beneficial shocks on the learning process. This asymmetry, in turn, causes aggressive\ntrading strategies — more exposed to noise trading shocks — to be prematurely pruned from the set\nof potential optimal strategies, reinforcing over-pruning bias in learning. As a result, the algorithm\nbehaves as if it were risk-averse, opting against aggressive strategies that expose profits to high risk.\n5.2\nKey Findings on AI Collusion\nWe begin with an overview of the key simulation findings, summarized in Figure 1, before digging\ninto the details of our simulation experiments in Sections 5.3 and 5.4, followed by a discussion of\nthe intuitions behind the AI collusive equilibrium in Section 5.5 and heuristic justifications in Online\nAppendix 3. To comprehensively characterize the AI collusive equilibrium, we classify all possible\ntrading environments into three cases: (i) high ξ and low σu, (ii) high ξ and high σu, and (iii) low ξ.\nThe corresponding theoretical benchmarks and key simulation findings are summarized as follows:\n(i) High ξ & low σu: Both a collusive Nash equilibrium via price-trigger strategies and a collusive\nexperience-based equilibrium via learning bias can theoretically be achieved by informed\nspeculators in such environments, as established in Propositions 3.1 and 3.2. However, in our\nsimulations, informed AI speculators using Q-learning consistently converge to an AI collusive\nequilibrium sustained by price-trigger strategies, rather than one driven by over-pruning bias.\n(ii) High ξ & high σu: No collusive Nash equilibrium sustained by price-trigger strategies exists in\ntheory, whereas a collusive experience-based equilibrium driven by learning bias can theoreti-\ncally be achieved by informed speculators in such environments, as established in Propositions\n26\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "shock moves in the same direction as the informed AI speculator’s trade, causing substantial trading\nlosses and sharply reducing the estimated Q-value of the chosen action. In contrast, a beneficial",
          "bbox": [
            64.08000183105469,
            52.15345001220703,
            547.9163208007812,
            79.47032928466797
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.826972007751465,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "shock moves in the opposite direction, generating significant trading profits and potentially inflating\nthe estimated Q-value, though this overestimation is more likely to be corrected over time through",
          "bbox": [
            64.08000183105469,
            85.01654052734375,
            547.9185180664062,
            112.32654571533203
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.837958335876465,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "continued and repeated exploitation.\nMore precisely, following an adverse noise trading shock, the algorithm often classifies the\nchosen strategy as a “disastrous action,” assigning it a significantly low Q-value. Exploitation",
          "bbox": [
            64.08000183105469,
            117.83551788330078,
            547.9165649414062,
            161.64532470703125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "then discourages the algorithm from revisiting this strategy in subsequent iterations, reinforcing the",
          "bbox": [
            64.08000183105469,
            167.1640167236328,
            547.9232177734375,
            178.04034423828125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.876322746276855,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "downward bias and preventing correction for such off-equilibrium-path actions. In contrast, following\na beneficial shock, the algorithm tends to label the strategy as a “fantastic action” and assigns it\nan inflated Q-value. Because exploitation promotes repeated use of high-Q-value strategies, the",
          "bbox": [
            64.08000183105469,
            183.65414428710938,
            547.9189453125,
            227.3863525390625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "algorithm continues to select and update this strategy, eventually correcting any initial overestimation.\nAggressive strategies, by their nature, are more exposed to noise trading shocks, making them",
          "bbox": [
            63.65399932861328,
            232.96017456054688,
            549.8323364257812,
            260.25634765625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "especially vulnerable to this asymmetric learning dynamic. As a result, they tend to be persistently\nundervalued and prematurely pruned from the set of candidate optimal strategies, reinforcing the",
          "bbox": [
            64.08000183105469,
            265.73199462890625,
            548.3441162109375,
            293.1171569824219
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.936338424682617,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "over-pruning bias. Consequently, informed AI speculators gravitate toward more conservative trading",
          "bbox": [
            64.08000183105469,
            298.7001647949219,
            547.9188232421875,
            309.4996337890625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "strategies, consistent with the collusive behavior described in Definitions 3.1 and 3.3.\nOne way to interpret the asymmetric effect of exploitation is that it effectively makes RL algo-\nrithms risk-averse to randomness in their rewards. In decision theory, risk aversion arises from\nthe asymmetric impact of adverse and beneficial shocks. Similarly, in RL, exploitation discourages",
          "bbox": [
            64.08000183105469,
            315.0575256347656,
            549.7305297851562,
            375.294677734375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "revisiting poorly rated strategies while reinforcing successful ones, leading to an asymmetric impact",
          "bbox": [
            64.08000183105469,
            380.83282470703125,
            547.9226684570312,
            391.6927185058594
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.85989761352539,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "of adverse and beneficial shocks on the learning process. This asymmetry, in turn, causes aggressive",
          "bbox": [
            64.08000183105469,
            397.267822265625,
            547.922607421875,
            408.1277160644531
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.85989761352539,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "trading strategies — more exposed to noise trading shocks — to be prematurely pruned from the set",
          "bbox": [
            64.08000183105469,
            413.7264099121094,
            547.916015625,
            424.55340576171875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.826972007751465,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "of potential optimal strategies, reinforcing over-pruning bias in learning. As a result, the algorithm",
          "bbox": [
            64.08000183105469,
            430.0751953125,
            547.9240112304688,
            441.02239990234375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.94721508026123,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "behaves as if it were risk-averse, opting against aggressive strategies that expose profits to high risk.",
          "bbox": [
            64.08000183105469,
            446.5424499511719,
            549.703369140625,
            457.4460754394531
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.903643608093262,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "5.2\nKey Findings on AI Collusion",
          "bbox": [
            64.08000183105469,
            479.1457824707031,
            256.8934631347656,
            491.1009826660156
          ],
          "font_info": {
            "font": "URWPalladioL-Bold",
            "size": 11.9552001953125,
            "color": 0,
            "flags": 20
          }
        },
        {
          "text": "We begin with an overview of the key simulation findings, summarized in Figure 1, before digging\ninto the details of our simulation experiments in Sections 5.3 and 5.4, followed by a discussion of",
          "bbox": [
            63.534000396728516,
            504.10198974609375,
            547.918701171875,
            531.497314453125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.936338424682617,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "the intuitions behind the AI collusive equilibrium in Section 5.5 and heuristic justifications in Online\nAppendix 3. To comprehensively characterize the AI collusive equilibrium, we classify all possible\ntrading environments into three cases: (i) high ξ and low σu, (ii) high ξ and high σu, and (iii) low ξ.",
          "bbox": [
            63.65399932861328,
            537.03564453125,
            549.828857421875,
            581.658203125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.848934173583984,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "The corresponding theoretical benchmarks and key simulation findings are summarized as follows:",
          "bbox": [
            63.742000579833984,
            586.2974853515625,
            547.8989868164062,
            597.2066040039062
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "(i) High ξ & low σu: Both a collusive Nash equilibrium via price-trigger strategies and a collusive\nexperience-based equilibrium via learning bias can theoretically be achieved by informed",
          "bbox": [
            75.45800018310547,
            611.2869262695312,
            547.9186401367188,
            638.7213134765625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "speculators in such environments, as established in Propositions 3.1 and 3.2. However, in our",
          "bbox": [
            91.35299682617188,
            644.1852416992188,
            548.142578125,
            655.137939453125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.952649116516113,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "simulations, informed AI speculators using Q-learning consistently converge to an AI collusive",
          "bbox": [
            91.35299682617188,
            660.7064819335938,
            547.918212890625,
            671.5389404296875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.832467079162598,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "equilibrium sustained by price-trigger strategies, rather than one driven by over-pruning bias.",
          "bbox": [
            91.35299682617188,
            677.0865478515625,
            547.8115234375,
            687.9956665039062
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "(ii) High ξ & high σu: No collusive Nash equilibrium sustained by price-trigger strategies exists in",
          "bbox": [
            72.28399658203125,
            702.2998657226562,
            547.9165649414062,
            714.1421508789062
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "theory, whereas a collusive experience-based equilibrium driven by learning bias can theoreti-",
          "bbox": [
            91.35299682617188,
            718.769775390625,
            549.7281494140625,
            729.6952514648438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.925451278686523,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "cally be achieved by informed speculators in such environments, as established in Propositions",
          "bbox": [
            91.35299682617188,
            735.2685546875,
            547.918212890625,
            746.1065063476562
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.837958335876465,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "26",
          "bbox": [
            300.5450134277344,
            765.1044921875,
            311.4541320800781,
            776.0136108398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        }
      ]
    },
    {
      "page_number": 29,
      "text": "Theory: Non-Collusive Nash Equilibrium\nCollusion (price-trigger strategies)  \nCollusion (learning bias)\nAI: Non-Collusive Nash Equilibrium\nCollusion (price-trigger strategies)              \n“artificial intelligence” \nCollusion (over-pruning bias in learning)    \n“artificial stupidity”\nTheory: Non-Collusive Nash Equilibrium\nCollusion (price-trigger strategies) \nCollusion (learning bias)     \nAI: Non-Collusive Nash Equilibrium\nCollusion (price-trigger strategies)  \n“artificial intelligence” \nCollusion (over-pruning bias in learning)    \n“artificial stupidity”\nLow\nHigh\nLow\nHigh\nPresence of information-insensitive \ninvestors (𝝃)\nNoise trading risk (𝝈𝒖)\nNote: The symbol “✓” indicates that the equilibrium exists, while “×” indicates that it does not. The presence of\ninformation-insensitive investors, ξ, is the slope coefficient of the asset demand curve, as specified in (3.2), while the noise\ntrading risk, σu, denotes the standard deviation of the noise trading flow, ut.\nFigure 1: Summary of our main findings.\n3.1 and 3.2. Consistent with these theoretical benchmarks, simulations show that multiple\ninformed AI speculators using Q-learning converge solely to an AI collusive equilibrium driven\nby over-pruning bias in learning, rather than one sustained by price-trigger strategies.\n(iii) Low ξ: No collusive Nash equilibrium sustained by price-trigger strategies exists in theory,\nwhereas a collusive experience-based equilibrium driven by learning bias can still theoretically\nbe achieved by informed speculators in such environments, regardless of the level of σu > 0,\nas established in Propositions 3.1 and 3.2. Consistent with these theoretical benchmarks,\nsimulations demonstrate that multiple informed AI speculators using Q-learning converge\nsolely to an AI collusive equilibrium driven by over-pruning bias in learning, rather than one\nsustained by price-trigger strategies. Notably, the results in this case are the same as those in\ncase (ii), characterized by high ξ and high σu.\n5.3\nSimulation Experiments in Trading Environments with High ξ\nThis section presents simulation results for cases (i) and (ii) described in Section 5.2. In trading\nenvironments where ξ is large relative to θ, indicating a significant presence of information-insensitive\ninvestors, the market maker primarily sets the market price to minimize inventory costs, rather than\nto reduce pricing errors, as described in (3.4).\nU-Shaped Profitability in AI Collusion: Two Distinct Mechanisms.\nPanel A of Figure 2 plots the\naverage ∆C as log σu varies from −5 to 5 along the x-axis. The horizontal dotted line represents the\ntheoretical benchmark for a perfect cartel (∆M ≡1), while the horizontal dash-dotted line indicates\n27\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "Theory: Non-Collusive Nash Equilibrium",
          "bbox": [
            155.97894287109375,
            73.93031311035156,
            298.7527160644531,
            82.76256561279297
          ],
          "font_info": {
            "font": "Calibri-Bold",
            "size": 8.832249641418457,
            "color": 12582912,
            "flags": 16
          }
        },
        {
          "text": "Collusion (price-trigger strategies)  \nCollusion (learning bias)",
          "bbox": [
            186.3197479248047,
            84.59761047363281,
            311.493896484375,
            103.73455047607422
          ],
          "font_info": {
            "font": "Calibri",
            "size": 8.832249641418457,
            "color": 0,
            "flags": 0
          }
        },
        {
          "text": "AI: Non-Collusive Nash Equilibrium",
          "bbox": [
            155.97894287109375,
            113.31159973144531,
            280.608642578125,
            122.14385223388672
          ],
          "font_info": {
            "font": "Calibri-Bold",
            "size": 8.832249641418457,
            "color": 12582912,
            "flags": 16
          }
        },
        {
          "text": "Collusion (price-trigger strategies)              \n“artificial intelligence” \nCollusion (over-pruning bias in learning)    \n“artificial stupidity”",
          "bbox": [
            168.11624145507812,
            123.98381042480469,
            319.435546875,
            164.4553680419922
          ],
          "font_info": {
            "font": "Calibri",
            "size": 8.832249641418457,
            "color": 0,
            "flags": 0
          }
        },
        {
          "text": "Theory: Non-Collusive Nash Equilibrium",
          "bbox": [
            327.92974853515625,
            169.6861114501953,
            470.4347229003906,
            178.51837158203125
          ],
          "font_info": {
            "font": "Calibri-Bold",
            "size": 8.832249641418457,
            "color": 12582912,
            "flags": 16
          }
        },
        {
          "text": "Collusion (price-trigger strategies) \nCollusion (learning bias)",
          "bbox": [
            358.27545166015625,
            180.35830688476562,
            481.60272216796875,
            199.86276245117188
          ],
          "font_info": {
            "font": "Calibri",
            "size": 8.832249641418457,
            "color": 0,
            "flags": 0
          }
        },
        {
          "text": "AI: Non-Collusive Nash Equilibrium",
          "bbox": [
            327.92974853515625,
            209.42510986328125,
            452.8233337402344,
            218.2573699951172
          ],
          "font_info": {
            "font": "Calibri-Bold",
            "size": 8.832249641418457,
            "color": 12582912,
            "flags": 16
          }
        },
        {
          "text": "Collusion (price-trigger strategies)  \n“artificial intelligence” \nCollusion (over-pruning bias in learning)    \n“artificial stupidity”",
          "bbox": [
            340.0572509765625,
            219.74452209472656,
            491.2098388671875,
            260.58355712890625
          ],
          "font_info": {
            "font": "Calibri",
            "size": 8.832249641418457,
            "color": 0,
            "flags": 0
          }
        },
        {
          "text": "Low\nHigh",
          "bbox": [
            222.12403869628906,
            272.5701904296875,
            411.60980224609375,
            283.2399597167969
          ],
          "font_info": {
            "font": "Calibri",
            "size": 10.669750213623047,
            "color": 0,
            "flags": 0
          }
        },
        {
          "text": "Low\nHigh",
          "bbox": [
            133.9081268310547,
            103.16761779785156,
            144.56561279296875,
            217.8623046875
          ],
          "font_info": {
            "font": "Calibri",
            "size": 10.657500267028809,
            "color": 0,
            "flags": 0
          }
        },
        {
          "text": "Presence of information-insensitive",
          "bbox": [
            108.89361572265625,
            79.58684539794922,
            119.55111694335938,
            241.10299682617188
          ],
          "font_info": {
            "font": "Calibri-Bold",
            "size": 10.657500267028809,
            "color": 0,
            "flags": 16
          }
        },
        {
          "text": "investors (𝝃)",
          "bbox": [
            121.80500793457031,
            134.11453247070312,
            132.7841796875,
            189.21200561523438
          ],
          "font_info": {
            "font": "Calibri-Bold",
            "size": 10.669750213623047,
            "color": 0,
            "flags": 16
          }
        },
        {
          "text": "Noise trading risk (𝝈𝒖)",
          "bbox": [
            267.30694580078125,
            285.2090148925781,
            366.8915100097656,
            297.4417724609375
          ],
          "font_info": {
            "font": "Calibri-Bold",
            "size": 10.669750213623047,
            "color": 0,
            "flags": 16
          }
        },
        {
          "text": "Note: The symbol “✓” indicates that the equilibrium exists, while “×” indicates that it does not. The presence of\ninformation-insensitive investors, ξ, is the slope coefficient of the asset demand curve, as specified in (3.2), while the noise\ntrading risk, σu, denotes the standard deviation of the noise trading flow, ut.",
          "bbox": [
            64.08000183105469,
            308.322998046875,
            547.9213256835938,
            342.8556823730469
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 9.055620193481445,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Figure 1: Summary of our main findings.",
          "bbox": [
            205.739990234375,
            353.7445373535156,
            406.2601318359375,
            364.6536560058594
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "3.1 and 3.2. Consistent with these theoretical benchmarks, simulations show that multiple",
          "bbox": [
            91.35299682617188,
            388.61566162109375,
            547.9163208007812,
            399.6333312988281
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 11.017650604248047,
            "color": 856203,
            "flags": 4
          }
        },
        {
          "text": "informed AI speculators using Q-learning converge solely to an AI collusive equilibrium driven",
          "bbox": [
            91.35299682617188,
            405.2071533203125,
            547.9192504882812,
            416.006591796875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "by over-pruning bias in learning, rather than one sustained by price-trigger strategies.",
          "bbox": [
            91.35299682617188,
            421.56451416015625,
            509.0296936035156,
            432.4736328125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "(iii) Low ξ: No collusive Nash equilibrium sustained by price-trigger strategies exists in theory,",
          "bbox": [
            69.10899353027344,
            446.7802734375,
            549.2808227539062,
            458.76116943359375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "whereas a collusive experience-based equilibrium driven by learning bias can still theoretically\nbe achieved by informed speculators in such environments, regardless of the level of σu > 0,\nas established in Propositions 3.1 and 3.2. Consistent with these theoretical benchmarks,\nsimulations demonstrate that multiple informed AI speculators using Q-learning converge\nsolely to an AI collusive equilibrium driven by over-pruning bias in learning, rather than one\nsustained by price-trigger strategies. Notably, the results in this case are the same as those in",
          "bbox": [
            90.8949966430664,
            463.431884765625,
            549.2849731445312,
            556.5072021484375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.865375518798828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "case (ii), characterized by high ξ and high σu.",
          "bbox": [
            91.35299682617188,
            562.0115356445312,
            311.32525634765625,
            573.8071899414062
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "5.3\nSimulation Experiments in Trading Environments with High ξ",
          "bbox": [
            64.07998657226562,
            594.6917724609375,
            434.4810791015625,
            607.735107421875
          ],
          "font_info": {
            "font": "URWPalladioL-Bold",
            "size": 11.9552001953125,
            "color": 0,
            "flags": 20
          }
        },
        {
          "text": "This section presents simulation results for cases (i) and (ii) described in Section 5.2. In trading",
          "bbox": [
            63.742000579833984,
            619.5896606445312,
            547.9232177734375,
            630.6072998046875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "environments where ξ is large relative to θ, indicating a significant presence of information-insensitive",
          "bbox": [
            64.08000183105469,
            636.18115234375,
            547.918212890625,
            647.898193359375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "investors, the market maker primarily sets the market price to minimize inventory costs, rather than",
          "bbox": [
            64.08000183105469,
            652.5698852539062,
            547.9238891601562,
            663.4352416992188
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.865375518798828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "to reduce pricing errors, as described in (3.4).",
          "bbox": [
            64.08000183105469,
            668.9735107421875,
            284.4438171386719,
            679.8826293945312
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "U-Shaped Profitability in AI Collusion: Two Distinct Mechanisms.\nPanel A of Figure 2 plots the\naverage ∆C as log σu varies from −5 to 5 along the x-axis. The horizontal dotted line represents the",
          "bbox": [
            64.08000183105469,
            701.748779296875,
            547.9241333007812,
            731.030517578125
          ],
          "font_info": {
            "font": "URWPalladioL-BoldItal",
            "size": 10.963509559631348,
            "color": 0,
            "flags": 22
          }
        },
        {
          "text": "theoretical benchmark for a perfect cartel (∆M ≡1), while the horizontal dash-dotted line indicates",
          "bbox": [
            64.08000183105469,
            729.73876953125,
            547.923583984375,
            745.8279418945312
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.952649116516113,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "27",
          "bbox": [
            300.5450134277344,
            765.1044921875,
            311.4541320800781,
            776.0136108398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        }
      ]
    },
    {
      "page_number": 30,
      "text": "-5\n-3\n-1\n1\n3\n5\n0\n0.2\n0.4\n0.6\n0.8\n1\n1.2\n-5\n-3\n-1\n1\n3\n5\n0\n0.2\n0.4\n0.6\n0.8\n1\n1.2\n ''Artificial intelligence'':\n Collusion via price-trigger\n strategies \n ''Artificial stupidity'':\nCollusion via over-pruning\nbias in learning\nFigure 2: Two distinct mechanisms behind AI collusion.\nthe benchmark for a non-collusive Nash equilibrium (∆N ≡0). The solid U-shaped line between 0\nand 1 represents the average normalized trading profitability of informed AI speculators, that is, the\naverage value of ∆C across all Nsim = 1, 000 simulation sessions. The average value of ∆C reflects the\ncollusion capacity of the informed AI speculators. The grey area around the solid line represents the\nrange of ∆C from the 1st to the 99th percentile across all Nsim simulation sessions.27\nThe normalized profitability of AI trading, ∆C, lies between 0 and 1, suggesting that a collusive\nequilibrium with significant supra-competitive profits, as defined in Definition 3.1, emerges robustly,\nirrespective of the noise trading risk level, σu. Importantly, the normalized trading profitability, ∆C,\nand the noise trading risk, σu, exhibit a strong U-shaped relationship, indicating that AI-driven\ncollusive trading is particularly pronounced when σu is either high or low. However, the algorithmic\nmechanisms underlying these AI collusion patterns differ significantly between the high and low σu\nscenarios, as discussed in Section 5.1 and further detailed in Section 5.5. This distinction is evident\nfrom the opposing relationships between σu and ∆C in these two scenarios. When noise trading risk\nσu is low, collusion capacity, as reflected in ∆C, decreases as σu increases. In contrast, when noise\ntrading risk σu is high, collusion capacity, as reflected by ∆C, increases with σu.\nPanel B of Figure 2 shows the proportion of the Nsim parallel simulation sessions that converge to a\nspecific type of AI collusive equilibrium. Collusive equilibria sustained by price-trigger strategies are\nrepresented by the solid line, while those sustained by over-pruning bias in learning are represented\nby the dashed line. In each simulation session, the type of AI collusion is identified based on the\ndefining features of price-trigger AI collusion and over-pruning AI collusion, as determined by the\nimpulse response patterns described in Figure 3.28 The results show that when σu is low, nearly all\nsimulation sessions converge to an AI collusive equilibrium sustained by price-trigger strategies,\n27The U-shaped pattern in the normalized trading profitability of informed AI speculators remains highly robust across\ndifferent levels of ξ, as demonstrated in Figure IA.4 in Online Appendix 4.6.\n28Additional details on the classification are provided in Online Appendix 4.5.\n28\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "-5\n-3\n-1\n1\n3\n5",
          "bbox": [
            94.18095397949219,
            266.637451171875,
            291.6185302734375,
            277.6613464355469
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 11.02391529083252,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0",
          "bbox": [
            88.880615234375,
            242.3233184814453,
            95.0099105834961,
            253.34722900390625
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 11.02391529083252,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.2",
          "bbox": [
            79.72221374511719,
            215.2340545654297,
            95.04545593261719,
            226.25796508789062
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 11.02391529083252,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.4",
          "bbox": [
            79.72221374511719,
            188.144775390625,
            95.04545593261719,
            199.16868591308594
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 11.02391529083252,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.6",
          "bbox": [
            79.72221374511719,
            161.0554962158203,
            95.04545593261719,
            172.07940673828125
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 11.02391529083252,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.8",
          "bbox": [
            79.72221374511719,
            133.96656799316406,
            95.04545593261719,
            144.990478515625
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 11.02391529083252,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1",
          "bbox": [
            88.880615234375,
            106.87728881835938,
            95.0099105834961,
            117.90120697021484
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 11.02391529083252,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1.2",
          "bbox": [
            79.72221374511719,
            79.78800964355469,
            95.04545593261719,
            90.81192779541016
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 11.02391529083252,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "-5\n-3\n-1\n1\n3\n5",
          "bbox": [
            343.49261474609375,
            266.637451171875,
            540.9302368164062,
            277.6613464355469
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 11.02391529083252,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0",
          "bbox": [
            338.192626953125,
            242.3233184814453,
            344.3219299316406,
            253.34722900390625
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 11.02391529083252,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.2",
          "bbox": [
            329.0342102050781,
            215.2340545654297,
            344.35748291015625,
            226.25796508789062
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 11.02391529083252,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.4",
          "bbox": [
            329.0342102050781,
            188.144775390625,
            344.35748291015625,
            199.16868591308594
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 11.02391529083252,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.6",
          "bbox": [
            329.0342102050781,
            161.0554962158203,
            344.35748291015625,
            172.07940673828125
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 11.02391529083252,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.8",
          "bbox": [
            329.0342102050781,
            133.96656799316406,
            344.35748291015625,
            144.990478515625
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 11.02391529083252,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1",
          "bbox": [
            338.192626953125,
            106.87728881835938,
            344.3219299316406,
            117.90120697021484
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 11.02391529083252,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1.2",
          "bbox": [
            329.0342102050781,
            79.78800964355469,
            344.35748291015625,
            90.81192779541016
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 11.02391529083252,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "''Artificial intelligence'':\n Collusion via price-trigger\n strategies",
          "bbox": [
            104.0111312866211,
            214.21046447753906,
            182.4215850830078,
            238.2937469482422
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.784084796905518,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "''Artificial stupidity'':\nCollusion via over-pruning\nbias in learning",
          "bbox": [
            188.91746520996094,
            124.17195129394531,
            267.3346862792969,
            148.25523376464844
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.784084796905518,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Figure 2: Two distinct mechanisms behind AI collusion.",
          "bbox": [
            170.38400268554688,
            304.7565002441406,
            441.6169738769531,
            315.6656188964844
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "the benchmark for a non-collusive Nash equilibrium (∆N ≡0). The solid U-shaped line between 0",
          "bbox": [
            64.08000183105469,
            334.53778076171875,
            547.9241333007812,
            350.643798828125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 11.012248992919922,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "and 1 represents the average normalized trading profitability of informed AI speculators, that is, the",
          "bbox": [
            64.08000183105469,
            356.1797180175781,
            547.92041015625,
            367.0341491699219
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.854416847229004,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "average value of ∆C across all Nsim = 1, 000 simulation sessions. The average value of ∆C reflects the",
          "bbox": [
            64.08000183105469,
            368.65081787109375,
            547.9234619140625,
            384.8003845214844
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.85989761352539,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "collusion capacity of the informed AI speculators. The grey area around the solid line represents the",
          "bbox": [
            64.08000183105469,
            389.0536804199219,
            547.9169921875,
            399.9026184082031
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.848934173583984,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "range of ∆C from the 1st to the 99th percentile across all Nsim simulation sessions.27",
          "bbox": [
            64.08000183105469,
            401.48553466796875,
            468.72308349609375,
            418.27264404296875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "The normalized profitability of AI trading, ∆C, lies between 0 and 1, suggesting that a collusive",
          "bbox": [
            81.01599884033203,
            419.89105224609375,
            547.9244384765625,
            432.8044738769531
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.958080291748047,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "equilibrium with significant supra-competitive profits, as defined in Definition 3.1, emerges robustly,",
          "bbox": [
            64.08000183105469,
            438.3557434082031,
            549.2813110351562,
            449.2101745605469
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.854416847229004,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "irrespective of the noise trading risk level, σu. Importantly, the normalized trading profitability, ∆C,\nand the noise trading risk, σu, exhibit a strong U-shaped relationship, indicating that AI-driven",
          "bbox": [
            64.08000183105469,
            452.7610778808594,
            549.2840576171875,
            482.982177734375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.952649116516113,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "collusive trading is particularly pronounced when σu is either high or low. However, the algorithmic",
          "bbox": [
            64.08000183105469,
            487.6607360839844,
            547.9177856445312,
            500.1511535644531
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.854416847229004,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "mechanisms underlying these AI collusion patterns differ significantly between the high and low σu\nscenarios, as discussed in Section 5.1 and further detailed in Section 5.5. This distinction is evident",
          "bbox": [
            64.08000183105469,
            504.0800476074219,
            547.9161987304688,
            531.4144897460938
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.876322746276855,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "from the opposing relationships between σu and ∆C in these two scenarios. When noise trading risk",
          "bbox": [
            64.08000183105469,
            532.982177734375,
            548.2242431640625,
            549.4664306640625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.887259483337402,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "σu is low, collusion capacity, as reflected in ∆C, decreases as σu increases. In contrast, when noise",
          "bbox": [
            64.21600341796875,
            551.3720703125,
            547.9163818359375,
            565.9383544921875
          ],
          "font_info": {
            "font": "PazoMath-Italic",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "trading risk σu is high, collusion capacity, as reflected by ∆C, increases with σu.",
          "bbox": [
            64.08000183105469,
            567.8070678710938,
            446.9002685546875,
            582.3426513671875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Panel B of Figure 2 shows the proportion of the Nsim parallel simulation sessions that converge to a",
          "bbox": [
            81.01599884033203,
            586.04345703125,
            547.9244995117188,
            599.0286254882812
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "specific type of AI collusive equilibrium. Collusive equilibria sustained by price-trigger strategies are",
          "bbox": [
            64.08000183105469,
            602.7303466796875,
            547.9182739257812,
            613.5518188476562
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.8214750289917,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "represented by the solid line, while those sustained by over-pruning bias in learning are represented\nby the dashed line. In each simulation session, the type of AI collusion is identified based on the",
          "bbox": [
            64.08000183105469,
            619.1417846679688,
            547.92041015625,
            646.477294921875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.854416847229004,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "defining features of price-trigger AI collusion and over-pruning AI collusion, as determined by the\nimpulse response patterns described in Figure 3.28 The results show that when σu is low, nearly all\nsimulation sessions converge to an AI collusive equilibrium sustained by price-trigger strategies,",
          "bbox": [
            64.08000183105469,
            651.9412841796875,
            549.284912109375,
            695.7833251953125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.952649116516113,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "27The U-shaped pattern in the normalized trading profitability of informed AI speculators remains highly robust across\ndifferent levels of ξ, as demonstrated in Figure IA.4 in Online Appendix 4.6.\n28Additional details on the classification are provided in Online Appendix 4.5.",
          "bbox": [
            64.08000183105469,
            705.5477294921875,
            547.9161376953125,
            738.6751098632812
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 6.973800182342529,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "28",
          "bbox": [
            300.54498291015625,
            765.1044921875,
            311.4541015625,
            776.0136108398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        }
      ]
    },
    {
      "page_number": 31,
      "text": "with almost none converging to an equilibrium sustained by over-pruning bias in learning. As σu\nincreases, the proportion of sessions converging to price-trigger AI collusion decreases, while the\nproportion converging to over-pruning learning bias AI collusion rises. At high levels of σu, nearly\nall sessions converge to an AI collusive equilibrium sustained by over-pruning bias in learning, with\nalmost none converging to an AI collusive equilibrium sustained by price-trigger strategies.\nThe simulation results illustrated in Panel B are consistent with the theoretical benchmarks\nestablished in Propositions 3.1 and 3.2. Theoretically, when ξ is large and σu is small, both a collusive\nNash equilibrium sustained by price-trigger strategies and a collusive experience-based equilibrium\ndriven by over-perceived aversion to noise trading risk can exist. However, Proposition 3.4 reveals that\nin low noise trading risk environments (i.e., low σu), the collusion capacity of informed speculators,\nas measured by their normalized trading profitability ∆C, is typically high in a price-trigger Nash\nequilibrium but low in an experience-based equilibrium sustained by the over-perceived aversion\nto noise trading risk. Consequently, informed AI speculators in such environments autonomously\nlearn to achieve an AI collusive equilibrium sustained by price-trigger strategies rather than one\ndriven by over-pruning bias in learning, as explained in Section 5.1, with further intuition and\nheuristic justification detailed in Section 5.5. In contrast, as shown by Propositions 3.1 and 3.2, when\nξ is large and σu is large, only a collusive experience-based equilibrium driven by over-perceived\naversion to noise trading risk can be sustained, while a collusive Nash equilibrium sustained by\nprice-trigger strategies becomes theoretically infeasible. Consequently, informed AI speculators in\nsuch environments autonomously learn to achieve an AI collusive equilibrium driven by over-pruning\nbias in learning rather than one sustained by price-trigger strategies, as explained in Section 5.1, with\nfurther intuition and heuristic justification detailed in Section 5.5.\nThe U-shaped relationship between ∆C and σu becomes clear when analyzing Panels A and B\nof Figure 2 together. In Panel A, the circles (◦) represent the average ∆C conditioned on simulation\nsessions classified as price-trigger AI collusive equilibria, while the diamonds (⋄) represent the\naverage ∆C conditioned on simulation sessions classified as over-pruning AI collusive equilibria.\nWhen noise trading risk is low (i.e., log σu ≤1), informed AI speculators sustain collusion mainly\nthrough price-trigger strategies, achieving significant supra-competitive profits. As σu increases, the\ncollusion capacity, reflected in normalized trading profitability ∆C, decreases. This decline occurs\nbecause higher noise trading risk reduces the informativeness of market prices, making it increasingly\nchallenging to sustain collusive trading through price-trigger strategies. These findings align with\nthe theoretical benchmark established in Proposition 3.4.\nIn contrast, when noise trading risk is high (i.e., log σu ≥3), informed AI speculators sustain\ncollusion mainly through over-pruning bias in learning, also achieving substantial supra-competitive\nprofits. As σu increases, the collusion capacity, reflected in normalized trading profitability ∆C, also\nincreases. This occurs because higher noise trading risk disrupts the balance between exploration and\nexploitation by amplifying the asymmetric effects of exploitation on the learning of aggressive trading\nstrategies in response to beneficial and adverse noise trading shocks. Specifically, it exacerbates\nthis asymmetry to the point where these effects become increasingly difficult to correct through\nexploration updates. As a result, higher noise trading risk reinforces over-pruning bias, making\naggressive trading strategies even less viable. As highlighted in Section 5.1, the asymmetric effect\nof exploitation can be interpreted as risk aversion embedded in algorithms toward randomness\n29\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "with almost none converging to an equilibrium sustained by over-pruning bias in learning. As σu\nincreases, the proportion of sessions converging to price-trigger AI collusion decreases, while the\nproportion converging to over-pruning learning bias AI collusion rises. At high levels of σu, nearly",
          "bbox": [
            63.62200164794922,
            52.01670455932617,
            548.3493041992188,
            96.76117706298828
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "all sessions converge to an AI collusive equilibrium sustained by over-pruning bias in learning, with",
          "bbox": [
            64.08000183105469,
            101.43580627441406,
            547.9225463867188,
            112.29570770263672
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.85989761352539,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "almost none converging to an AI collusive equilibrium sustained by price-trigger strategies.\nThe simulation results illustrated in Panel B are consistent with the theoretical benchmarks",
          "bbox": [
            64.08000183105469,
            117.83551788330078,
            547.9165649414062,
            145.2103271484375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "established in Propositions 3.1 and 3.2. Theoretically, when ξ is large and σu is small, both a collusive",
          "bbox": [
            64.08000183105469,
            150.78414916992188,
            547.9213256835938,
            163.2206268310547
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Nash equilibrium sustained by price-trigger strategies and a collusive experience-based equilibrium",
          "bbox": [
            64.08000183105469,
            167.1561737060547,
            547.9193115234375,
            178.04344177246094
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.887259483337402,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "driven by over-perceived aversion to noise trading risk can exist. However, Proposition 3.4 reveals that",
          "bbox": [
            64.08000183105469,
            183.65414428710938,
            547.9188232421875,
            194.45359802246094
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "in low noise trading risk environments (i.e., low σu), the collusion capacity of informed speculators,\nas measured by their normalized trading profitability ∆C, is typically high in a price-trigger Nash\nequilibrium but low in an experience-based equilibrium sustained by the over-perceived aversion\nto noise trading risk. Consequently, informed AI speculators in such environments autonomously\nlearn to achieve an AI collusive equilibrium sustained by price-trigger strategies rather than one\ndriven by over-pruning bias in learning, as explained in Section 5.1, with further intuition and",
          "bbox": [
            64.08000183105469,
            200.00372314453125,
            549.2814331054688,
            293.1263427734375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.920002937316895,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "heuristic justification detailed in Section 5.5. In contrast, as shown by Propositions 3.1 and 3.2, when",
          "bbox": [
            64.08000183105469,
            298.6607360839844,
            547.92041015625,
            309.5151672363281
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.854416847229004,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "ξ is large and σu is large, only a collusive experience-based equilibrium driven by over-perceived\naversion to noise trading risk can be sustained, while a collusive Nash equilibrium sustained by\nprice-trigger strategies becomes theoretically infeasible. Consequently, informed AI speculators in",
          "bbox": [
            63.75299835205078,
            314.97967529296875,
            548.350341796875,
            358.8642883300781
          ],
          "font_info": {
            "font": "PazoMath-Italic",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "such environments autonomously learn to achieve an AI collusive equilibrium driven by over-pruning",
          "bbox": [
            64.08000183105469,
            364.441162109375,
            547.9188842773438,
            375.2406005859375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "bias in learning rather than one sustained by price-trigger strategies, as explained in Section 5.1, with",
          "bbox": [
            64.08000183105469,
            380.87615966796875,
            547.9187622070312,
            391.67559814453125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "further intuition and heuristic justification detailed in Section 5.5.\nThe U-shaped relationship between ∆C and σu becomes clear when analyzing Panels A and B",
          "bbox": [
            64.08000183105469,
            397.2325134277344,
            547.9227294921875,
            426.24432373046875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "of Figure 2 together. In Panel A, the circles (◦) represent the average ∆C conditioned on simulation\nsessions classified as price-trigger AI collusive equilibria, while the diamonds (⋄) represent the\naverage ∆C conditioned on simulation sessions classified as over-pruning AI collusive equilibria.\nWhen noise trading risk is low (i.e., log σu ≤1), informed AI speculators sustain collusion mainly",
          "bbox": [
            63.534000396728516,
            426.1112976074219,
            549.83251953125,
            491.20416259765625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.952649116516113,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "through price-trigger strategies, achieving significant supra-competitive profits. As σu increases, the\ncollusion capacity, reflected in normalized trading profitability ∆C, decreases. This decline occurs",
          "bbox": [
            64.08000183105469,
            495.8513488769531,
            547.91845703125,
            523.2183227539062
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.898184776306152,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "because higher noise trading risk reduces the informativeness of market prices, making it increasingly\nchallenging to sustain collusive trading through price-trigger strategies. These findings align with",
          "bbox": [
            64.08000183105469,
            528.7921142578125,
            548.346435546875,
            556.083740234375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "the theoretical benchmark established in Proposition 3.4.\nIn contrast, when noise trading risk is high (i.e., log σu ≥3), informed AI speculators sustain",
          "bbox": [
            64.08000183105469,
            561.5845336914062,
            547.9208984375,
            589.815185546875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "collusion mainly through over-pruning bias in learning, also achieving substantial supra-competitive",
          "bbox": [
            64.08000183105469,
            594.509521484375,
            547.9231567382812,
            605.3419799804688
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.832467079162598,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "profits. As σu increases, the collusion capacity, reflected in normalized trading profitability ∆C, also",
          "bbox": [
            63.75299835205078,
            608.8990478515625,
            547.9221801757812,
            623.4407958984375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.930895805358887,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "increases. This occurs because higher noise trading risk disrupts the balance between exploration and",
          "bbox": [
            64.08000183105469,
            627.4031372070312,
            547.9186401367188,
            638.20263671875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "exploitation by amplifying the asymmetric effects of exploitation on the learning of aggressive trading\nstrategies in response to beneficial and adverse noise trading shocks. Specifically, it exacerbates\nthis asymmetry to the point where these effects become increasingly difficult to correct through\nexploration updates. As a result, higher noise trading risk reinforces over-pruning bias, making\naggressive trading strategies even less viable. As highlighted in Section 5.1, the asymmetric effect\nof exploitation can be interpreted as risk aversion embedded in algorithms toward randomness",
          "bbox": [
            64.08000183105469,
            643.838134765625,
            547.9188232421875,
            736.8753051757812
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "29",
          "bbox": [
            300.5450134277344,
            765.1044921875,
            311.4541320800781,
            776.0136108398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        }
      ]
    },
    {
      "page_number": 32,
      "text": "in rewards. Intuitively, greater noise trading risk further discourages algorithms from selecting\naggressive trading strategies. These simulation findings are consistent with the theoretical benchmark\nestablished in Proposition 3.4.\nTo further provide direct evidence of the two AI collusion mechanisms across environments with\nlow and high noise trading risk, as demonstrated in Figure 2, we conduct impulse response analyses\nthroughout the remainder of this section using our simulation experiments. We begin by showing that\nin low noise trading risk scenarios, informed AI speculators autonomously learn to sustain collusive,\nsupra-competitive trading profits through price-trigger strategies, without requiring any form of\nagreement, communication, or pre-programmed intent. To be more precise, we emphasize that, while\nthis AI collusive equilibrium resembles the collusive Nash equilibrium sustained by price-trigger\nstrategies, as described in Definition 3.2 and Proposition 3.1, it does not fully satisfy the requirements\nof subgame perfect Nash equilibrium.29 We then show that in high noise trading risk scenarios,\ninformed AI speculators still sustain collusive, supra-competitive trading profits, but through a\ndifferent mechanism: over-pruning bias in learning.30 This AI collusive equilibrium corresponds to\nthe collusive experience-based equilibrium sustained by over-perceived aversion to noise trading risk,\nas described in Definition 3.3 and Proposition 3.2.\nImpulse Responses: AI Collusion via Price-Trigger Strategies When σu Is Low.\nWe first examine\nhow the trained informed AI speculators respond to an exogenous shock in the noise order flow,\nwhich influences the asset’s market price through the market maker’s endogenous and adaptive\npricing rule. At t = 0, all Nsim simulation sessions have converged. The market price of the asset, pt,\nis determined by the market maker’s adaptive pricing rule, which responds to the random variables\nvt and ut along each simulation path, independently across the parallel simulation paths. At t = 3,\nan unexpected exogenous shock, ushock, is introduced to the noise order flow ut, simultaneously\nand uniformly affecting all Nsim simulation sessions. This shock is designed to adversely impact the\ntrading profits of informed AI speculators, with ushock > 0 when vt > v and ushock < 0 when vt < v.\nAs a result, the market price pt rises unexpectedly if vt > v and falls unexpectedly if vt < v, with\nthe magnitude of the price change determined by the size of ushock. Each impulse-response curve\nin a panel represents the average impulse response dynamics across Nsim independent simulation\nsessions.31 The cross-sectional distribution of path-by-path impulse response dynamics across Nsim\nsimulation sessions is provided in Online Appendix 4.4.\nPanel A of Figure 2 shows that, in environments with a significant presence of information-\ninsensitive investors (here, ξ = 500) and low noise trading risk (specifically, σu = 10−1), the average\nvalue of ∆C across Nsim parallel simulation paths is approximately 0.75. Under these conditions,\ninformed AI speculators achieve average trading profits that are about 10% higher than those in the\nnon-collusive equilibrium benchmark.\n29Our numerical tests suggest that this AI collusive equilibrium is approximately Nash, meaning no local deviation is\npreferred. Numerical tests are detailed in Online Appendix 4.10.\n30In both scenarios, the equilibrium is classified as an experience-based equilibrium, based on the formal tests proposed\nby Fershtman and Pakes (2012). Details of these tests are provided in Online Appendix 4.2. This is unsurprising, as the\nexperience-based equilibrium framework is broader and encompasses subgame perfect Nash equilibrium as a special case.\n31Each of the Nsim simulation sessions averages 10,000 simulation paths to smooth out the randomness of vt and ut,\nensuring a reasonable comparison with the impulse response analysis based on the deterministic model of Calvano et al.\n(2020), which has no information asymmetry or stochastic economic environment.\n30\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "in rewards. Intuitively, greater noise trading risk further discourages algorithms from selecting",
          "bbox": [
            64.08000183105469,
            52.01670455932617,
            547.9161376953125,
            63.03435516357422
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "aggressive trading strategies. These simulation findings are consistent with the theoretical benchmark",
          "bbox": [
            64.08000183105469,
            68.60916137695312,
            548.228759765625,
            79.40861511230469
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "established in Proposition 3.4.",
          "bbox": [
            64.08000183105469,
            84.96552276611328,
            209.70556640625,
            95.87462615966797
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "To further provide direct evidence of the two AI collusion mechanisms across environments with",
          "bbox": [
            81.01599884033203,
            101.4515380859375,
            547.9178466796875,
            112.28949737548828
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.837958335876465,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "low and high noise trading risk, as demonstrated in Figure 2, we conduct impulse response analyses",
          "bbox": [
            64.08000183105469,
            117.88653564453125,
            547.9187622070312,
            128.72450256347656
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.837958335876465,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "throughout the remainder of this section using our simulation experiments. We begin by showing that",
          "bbox": [
            64.08000183105469,
            134.34915161132812,
            547.9188232421875,
            145.1486053466797
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "in low noise trading risk scenarios, informed AI speculators autonomously learn to sustain collusive,\nsupra-competitive trading profits through price-trigger strategies, without requiring any form of",
          "bbox": [
            64.08000183105469,
            150.75653076171875,
            549.2861328125,
            178.080322265625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.837958335876465,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "agreement, communication, or pre-programmed intent. To be more precise, we emphasize that, while\nthis AI collusive equilibrium resembles the collusive Nash equilibrium sustained by price-trigger",
          "bbox": [
            64.08000183105469,
            183.65414428710938,
            548.1387329101562,
            210.95135498046875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "strategies, as described in Definition 3.2 and Proposition 3.1, it does not fully satisfy the requirements\nof subgame perfect Nash equilibrium.29 We then show that in high noise trading risk scenarios,\ninformed AI speculators still sustain collusive, supra-competitive trading profits, but through a",
          "bbox": [
            64.08000183105469,
            216.52517700195312,
            549.2813720703125,
            260.25634765625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "different mechanism: over-pruning bias in learning.30 This AI collusive equilibrium corresponds to",
          "bbox": [
            64.08000183105469,
            261.77197265625,
            547.9207153320312,
            276.6683349609375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.936338424682617,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "the collusive experience-based equilibrium sustained by over-perceived aversion to noise trading risk,",
          "bbox": [
            64.08000183105469,
            282.2611999511719,
            549.2796630859375,
            293.0661926269531
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.80496597290039,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "as described in Definition 3.3 and Proposition 3.2.",
          "bbox": [
            64.08000183105469,
            298.62152099609375,
            306.0765686035156,
            309.5306396484375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Impulse Responses: AI Collusion via Price-Trigger Strategies When σu Is Low.\nWe first examine\nhow the trained informed AI speculators respond to an exogenous shock in the noise order flow,\nwhich influences the asset’s market price through the market maker’s endogenous and adaptive",
          "bbox": [
            63.62200164794922,
            331.35772705078125,
            549.2849731445312,
            375.4953308105469
          ],
          "font_info": {
            "font": "URWPalladioL-BoldItal",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 22
          }
        },
        {
          "text": "pricing rule. At t = 0, all Nsim simulation sessions have converged. The market price of the asset, pt,",
          "bbox": [
            63.75299835205078,
            379.9300842285156,
            549.2833862304688,
            393.8114318847656
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.887259483337402,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "is determined by the market maker’s adaptive pricing rule, which responds to the random variables",
          "bbox": [
            64.08000183105469,
            397.4568786621094,
            547.923828125,
            408.3222351074219
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.865375518798828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "vt and ut along each simulation path, independently across the parallel simulation paths. At t = 3,\nan unexpected exogenous shock, ushock, is introduced to the noise order flow ut, simultaneously",
          "bbox": [
            64.08000183105469,
            412.8000793457031,
            549.283447265625,
            442.3873291015625
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "and uniformly affecting all Nsim simulation sessions. This shock is designed to adversely impact the",
          "bbox": [
            64.08000183105469,
            446.54241943359375,
            547.9208374023438,
            459.5509033203125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.881793022155762,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "trading profits of informed AI speculators, with ushock > 0 when vt > v and ushock < 0 when vt < v.\nAs a result, the market price pt rises unexpectedly if vt > v and falls unexpectedly if vt < v, with\nthe magnitude of the price change determined by the size of ushock. Each impulse-response curve\nin a panel represents the average impulse response dynamics across Nsim independent simulation",
          "bbox": [
            63.65399932861328,
            462.1060791015625,
            549.8292846679688,
            525.329345703125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "sessions.31 The cross-sectional distribution of path-by-path impulse response dynamics across Nsim\nsimulation sessions is provided in Online Appendix 4.4.\nPanel A of Figure 2 shows that, in environments with a significant presence of information-",
          "bbox": [
            64.07998657226562,
            524.915283203125,
            549.7304077148438,
            572.7173461914062
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.952649116516113,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "insensitive investors (here, ξ = 500) and low noise trading risk (specifically, σu = 10−1), the average\nvalue of ∆C across Nsim parallel simulation paths is approximately 0.75. Under these conditions,",
          "bbox": [
            63.775001525878906,
            575.4778442382812,
            549.2864990234375,
            607.5053100585938
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.936338424682617,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "informed AI speculators achieve average trading profits that are about 10% higher than those in the",
          "bbox": [
            64.08000183105469,
            611.09033203125,
            547.9170532226562,
            621.988525390625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.898184776306152,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "non-collusive equilibrium benchmark.",
          "bbox": [
            64.08000183105469,
            627.5175170898438,
            249.32740783691406,
            638.4266357421875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "29Our numerical tests suggest that this AI collusive equilibrium is approximately Nash, meaning no local deviation is\npreferred. Numerical tests are detailed in Online Appendix 4.10.\n30In both scenarios, the equilibrium is classified as an experience-based equilibrium, based on the formal tests proposed\nby Fershtman and Pakes (2012). Details of these tests are provided in Online Appendix 4.2. This is unsurprising, as the\nexperience-based equilibrium framework is broader and encompasses subgame perfect Nash equilibrium as a special case.\n31Each of the Nsim simulation sessions averages 10,000 simulation paths to smooth out the randomness of vt and ut,\nensuring a reasonable comparison with the impulse response analysis based on the deterministic model of Calvano et al.\n(2020), which has no information asymmetry or stochastic economic environment.",
          "bbox": [
            63.784000396728516,
            648.2007446289062,
            549.4910888671875,
            736.5381469726562
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 6.973800182342529,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "30",
          "bbox": [
            300.5450134277344,
            765.1044921875,
            311.4541320800781,
            776.0136108398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        }
      ]
    },
    {
      "page_number": 33,
      "text": "1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n0.02\n0.04\n0.06\n0.08\n1\n2\n3\n4\n5\n6\n7\n8\n9\n-0.105\n-0.085\n-0.065\n-0.045\n-0.025\n-0.005\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n0.01\n0.02\n0.03\n0.04\n0.05\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n0.02\n0.04\n0.06\n0.08\n1\n2\n3\n4\n5\n6\n7\n8\n9\n-0.105\n-0.085\n-0.065\n-0.045\n-0.025\n-0.005\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n0.01\n0.02\n0.03\n0.04\n0.05\nNote: All plots correspond to a trading environment with ξ = 500, indicating a significant presence of information-\ninsensitive investors, and σu = 10−1, representing a low noise trading risk level. Panels A and D depict the percentage\ndeviation of the asset’s price from its long-run mean, expressed as (ept −E[ept])/E[ept], where ept = (pt −v) × sgn(vt −v),\nand sgn(·) is the sign function ensuring ept > 0. Panels B and E depict the percentage deviation of average profits from their\nlong-run mean for each informed AI speculator, expressed as (πi,t −E[πi,t])/E[πi,t]. Panels C and F depict the percentage\ndeviation of order flows from the long-run mean for each informed AI speculator, defined as (exi,t −E[exi,t])/E[exi,t], where\nexi,t = xi,t × sgn(vt −v). The sign function ensures that exi,t > 0.\nFigure 3: Impulse response function (IRF) following an exogenous noise trading shock ushock for\nσu = 10−1 under Q-learning (left column) and the theoretical benchmark (right column).\nTo examine how informed AI speculators behave in steady-state equilibrium, we analyze their\nimpulse responses to exogenous shocks of varying magnitudes. In the “small deviation” experiment,\n|ushock| is approximately 0.25% of the average magnitude of informed AI speculators’ order flow |xi,t|,\nresulting in a minor impact on the asset price pt at t = 3. In contrast, in the “medium deviation,”\n“large deviation,” and “ultra large deviation” experiments, |ushock| corresponds to roughly 2.5%,\n11.5%, and 15.0% of the average |xi,t|, respectively, leading to progressively larger changes in pt.\nTo provide direct evidence that the behavior of informed AI speculators in equilibrium aligns\nclosely with a theoretical collusive Nash equilibrium sustained by price-trigger strategies, we present\nthe impulse responses to the exogenous shocks mentioned above for AI-powered trading in the left\n31\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "1\n2\n3\n4\n5\n6\n7\n8\n9\n0",
          "bbox": [
            336.418212890625,
            152.30776977539062,
            527.0066528320312,
            171.1378631591797
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.02",
          "bbox": [
            324.71820068359375,
            129.74496459960938,
            341.06451416015625,
            138.1470489501953
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.04",
          "bbox": [
            324.71820068359375,
            107.18216705322266,
            341.06451416015625,
            115.58424377441406
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.06",
          "bbox": [
            324.71820068359375,
            84.61908721923828,
            341.06451416015625,
            93.02116394042969
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.08",
          "bbox": [
            324.71820068359375,
            62.05628204345703,
            341.06451416015625,
            70.45835876464844
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1\n2\n3\n4\n5\n6\n7\n8\n9\n-0.105",
          "bbox": [
            317.293212890625,
            290.9815673828125,
            527.0066528320312,
            307.5550537109375
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "-0.085",
          "bbox": [
            317.293212890625,
            272.6360778808594,
            341.1070861816406,
            281.03814697265625
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "-0.065",
          "bbox": [
            317.293212890625,
            254.29037475585938,
            341.1070861816406,
            262.69244384765625
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "-0.045",
          "bbox": [
            317.293212890625,
            235.9448699951172,
            341.1070861816406,
            244.34695434570312
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "-0.025",
          "bbox": [
            317.293212890625,
            217.59939575195312,
            341.1070861816406,
            226.00148010253906
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "-0.005",
          "bbox": [
            317.293212890625,
            199.25390625,
            341.1070861816406,
            207.65599060058594
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1\n2\n3\n4\n5\n6\n7\n8\n9\n0",
          "bbox": [
            336.418212890625,
            423.95501708984375,
            527.0066528320312,
            443.97247314453125
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.01",
          "bbox": [
            324.71820068359375,
            406.7359619140625,
            341.06451416015625,
            415.1380310058594
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.02",
          "bbox": [
            324.71820068359375,
            389.5169372558594,
            341.06451416015625,
            397.91900634765625
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.03",
          "bbox": [
            324.71820068359375,
            372.2978820800781,
            341.06451416015625,
            380.699951171875
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.04",
          "bbox": [
            324.71820068359375,
            355.078857421875,
            341.06451416015625,
            363.4809265136719
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.05",
          "bbox": [
            324.71820068359375,
            337.8600769042969,
            341.06451416015625,
            346.26214599609375
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1\n2\n3\n4\n5\n6\n7\n8\n9\n0",
          "bbox": [
            98.59320068359375,
            152.30776977539062,
            289.1819152832031,
            171.1378631591797
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.02",
          "bbox": [
            86.89318084716797,
            129.74496459960938,
            103.2394790649414,
            138.1470489501953
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.04",
          "bbox": [
            86.89318084716797,
            107.18216705322266,
            103.2394790649414,
            115.58424377441406
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.06",
          "bbox": [
            86.89318084716797,
            84.61908721923828,
            103.2394790649414,
            93.02116394042969
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.08",
          "bbox": [
            86.89318084716797,
            62.05628204345703,
            103.2394790649414,
            70.45835876464844
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1\n2\n3\n4\n5\n6\n7\n8\n9\n-0.105",
          "bbox": [
            79.46820068359375,
            290.9815673828125,
            289.1819152832031,
            307.5550537109375
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "-0.085",
          "bbox": [
            79.46820068359375,
            272.6360778808594,
            103.28205108642578,
            281.03814697265625
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "-0.065",
          "bbox": [
            79.46820068359375,
            254.29037475585938,
            103.28205108642578,
            262.69244384765625
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "-0.045",
          "bbox": [
            79.46820068359375,
            235.9448699951172,
            103.28205108642578,
            244.34695434570312
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "-0.025",
          "bbox": [
            79.46820068359375,
            217.59939575195312,
            103.28205108642578,
            226.00148010253906
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "-0.005",
          "bbox": [
            79.46820068359375,
            199.25390625,
            103.28205108642578,
            207.65599060058594
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1\n2\n3\n4\n5\n6\n7\n8\n9\n0",
          "bbox": [
            98.59320068359375,
            423.95501708984375,
            289.1819152832031,
            443.97247314453125
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.01",
          "bbox": [
            86.89318084716797,
            406.7359619140625,
            103.2394790649414,
            415.1380310058594
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.02",
          "bbox": [
            86.89318084716797,
            389.5169372558594,
            103.2394790649414,
            397.91900634765625
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.03",
          "bbox": [
            86.89318084716797,
            372.2978820800781,
            103.2394790649414,
            380.699951171875
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.04",
          "bbox": [
            86.89318084716797,
            355.078857421875,
            103.2394790649414,
            363.4809265136719
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.05",
          "bbox": [
            86.89318084716797,
            337.8600769042969,
            103.2394790649414,
            346.26214599609375
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "Note: All plots correspond to a trading environment with ξ = 500, indicating a significant presence of information-\ninsensitive investors, and σu = 10−1, representing a low noise trading risk level. Panels A and D depict the percentage\ndeviation of the asset’s price from its long-run mean, expressed as (ept −E[ept])/E[ept], where ept = (pt −v) × sgn(vt −v),\nand sgn(·) is the sign function ensuring ept > 0. Panels B and E depict the percentage deviation of average profits from their\nlong-run mean for each informed AI speculator, expressed as (πi,t −E[πi,t])/E[πi,t]. Panels C and F depict the percentage\ndeviation of order flows from the long-run mean for each informed AI speculator, defined as (exi,t −E[exi,t])/E[exi,t], where\nexi,t = xi,t × sgn(vt −v). The sign function ensures that exi,t > 0.",
          "bbox": [
            64.08000183105469,
            461.2871398925781,
            549.4052124023438,
            542.748046875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 9.055620193481445,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Figure 3: Impulse response function (IRF) following an exogenous noise trading shock ushock for\nσu = 10−1 under Q-learning (left column) and the theoretical benchmark (right column).",
          "bbox": [
            64.08000183105469,
            548.7283935546875,
            548.1381225585938,
            574.409423828125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "To examine how informed AI speculators behave in steady-state equilibrium, we analyze their",
          "bbox": [
            81.01599884033203,
            597.3377075195312,
            548.1390380859375,
            608.3553466796875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "impulse responses to exogenous shocks of varying magnitudes. In the “small deviation” experiment,\n|ushock| is approximately 0.25% of the average magnitude of informed AI speculators’ order flow |xi,t|,\nresulting in a minor impact on the asset price pt at t = 3. In contrast, in the “medium deviation,”\n“large deviation,” and “ultra large deviation” experiments, |ushock| corresponds to roughly 2.5%,",
          "bbox": [
            62.444000244140625,
            613.9015502929688,
            550.1072998046875,
            675.247314453125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.837958335876465,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "11.5%, and 15.0% of the average |xi,t|, respectively, leading to progressively larger changes in pt.\nTo provide direct evidence that the behavior of informed AI speculators in equilibrium aligns",
          "bbox": [
            63.534000396728516,
            678.3837280273438,
            547.9166259765625,
            706.96630859375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "closely with a theoretical collusive Nash equilibrium sustained by price-trigger strategies, we present",
          "bbox": [
            64.08000183105469,
            712.5283203125,
            547.9199829101562,
            723.3442993164062
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.815974235534668,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "the impulse responses to the exogenous shocks mentioned above for AI-powered trading in the left",
          "bbox": [
            64.08000183105469,
            728.884765625,
            547.9168090820312,
            739.8102416992188
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.925451278686523,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "31",
          "bbox": [
            300.5450134277344,
            765.1044921875,
            311.4541320800781,
            776.0136108398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        }
      ]
    },
    {
      "page_number": 34,
      "text": "column of Figure 3, alongside the corresponding theoretical benchmarks in the right column. For a\nmeaningful comparison, Panels D through F use the same magnitudes of unexpected price deviations\nat t = 3 as those in the simulation experiments shown in Panels A to C. Additionally, all shared\nparameters between the theoretical benchmarks and the simulation experiments are set to identical\nvalues. The parameters (T, ω, η), which specify the price-trigger punishment scheme in theory, are\nnot relevant to the structure of the Q-learning simulations. Here, we set T = 2 to align with the\ntwo-period punishment observed in the Q-learning experiments, ω = 2.826 to achieve an average\nprofitability ∆C of approximately 0.75, and η = 0.327 to match the average order flow deviation in\nthe “ultra large deviation” case at t = 4 in the Q-learning simulations. This side-by-side comparison\nhighlights the strong resemblance between the AI collusive equilibrium and the corresponding\ntheoretical benchmarks of collusive Nash equilibrium sustained by price-trigger strategies.\nThe price-trigger punishment scheme is evident throughout Panels A to C. Specifically, immedi-\nately after the shock at t = 3 (starting at t = 4), the responses display two defining characteristics of\nprice-trigger strategies, as outlined in Definition 3.2 and Proposition 3.1. These features of trigger-type\nstrategies, also reflected in the theoretical benchmark shown in Panels D to F, are as follows: (i) there\nis, on average, no response when the price deviation at t = 3 is small (i.e., the “small deviation”\nscenario, represented by the solid curve), and (ii) when the price deviation at t = 3 is sufficiently large,\nAI speculators respond by adopting similarly aggressive trading strategies starting at t = 4, despite\nsignificant differences in the deviation’s magnitude at t = 3 (i.e., the “medium deviation,” “large\ndeviation,” and “ultra large deviation” cases, represented by the dotted, dashed, and dash-dotted\ncurves, respectively).\nTo further validate the price-trigger punishment scheme among informed AI speculators, Panel A\nshows that for large and ultra-large price deviations, the percentage deviation of the asset’s price\nat t = 4 decreases relative to t = 3 but remains above the long-run mean. In the medium deviation\ncase, the percentage deviation at t = 4 surpasses that at t = 3. Notably, in the medium, large, and\nultra-large cases, price deviations at t = 4 converge to similar magnitudes, driven by comparable\norder flow deviations at t = 4, as shown in Panel C. In contrast, for the small deviation case, both the\nasset price and informed AI speculators’ profits revert to the long-run mean at t = 4. These nuanced\npatterns of the AI collusive equilibrium closely align with those of the collusive Nash equilibrium\nsustained by price trigger strategies, as depicted in Panels D through F.\nWe emphasize that, although the Q-learning algorithms rely only on the one-period lagged market\nprice pt−1 and fundamental value vt−1 for their decisions at period t, the punishment can extend\nbeyond a single period. Panels A through C of Figure 3 illustrate that informed AI speculators\ncontinue to enforce punishment at t = 5, albeit significantly weaker on average than at t = 4. This\npattern demonstrates that informed AI speculators learn to sustain the collusive equilibrium using\nprice-trigger strategies, where the punishment scheme generally lasts for more than one period.\nTo confirm that the price-trigger strategy employed by informed AI speculators in Panels A\nthrough C of Figure 3 is indeed the driving force behind the collusive, supra-competitive trading\nprofitability observed in Figure 2 under low noise trading risk, we disable the AI speculators’ ability\nto use lagged market prices as a monitoring tool. This is accomplished by removing the lagged\nmarket price pt−1 from the state variable st used for decision-making at period t. Our findings reveal\nthat even in environments with both a significant presence of information-insensitive investors (i.e., a\n32\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "column of Figure 3, alongside the corresponding theoretical benchmarks in the right column. For a",
          "bbox": [
            64.08000183105469,
            52.07501983642578,
            547.9166259765625,
            63.011356353759766
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.936338424682617,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "meaningful comparison, Panels D through F use the same magnitudes of unexpected price deviations\nat t = 3 as those in the simulation experiments shown in Panels A to C. Additionally, all shared",
          "bbox": [
            64.08000183105469,
            68.60916137695312,
            547.9188232421875,
            95.90532684326172
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "parameters between the theoretical benchmarks and the simulation experiments are set to identical\nvalues. The parameters (T, ω, η), which specify the price-trigger punishment scheme in theory, are\nnot relevant to the structure of the Q-learning simulations. Here, we set T = 2 to align with the\ntwo-period punishment observed in the Q-learning experiments, ω = 2.826 to achieve an average\nprofitability ∆C of approximately 0.75, and η = 0.327 to match the average order flow deviation in",
          "bbox": [
            63.75299835205078,
            101.38098907470703,
            547.9240112304688,
            178.93617248535156
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.936338424682617,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "the “ultra large deviation” case at t = 4 in the Q-learning simulations. This side-by-side comparison\nhighlights the strong resemblance between the AI collusive equilibrium and the corresponding",
          "bbox": [
            64.08000183105469,
            182.51507568359375,
            547.9249877929688,
            210.95135498046875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.870850563049316,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "theoretical benchmarks of collusive Nash equilibrium sustained by price-trigger strategies.",
          "bbox": [
            64.08000183105469,
            216.44654846191406,
            504.02227783203125,
            227.3556365966797
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "The price-trigger punishment scheme is evident throughout Panels A to C. Specifically, immedi-",
          "bbox": [
            81.01599884033203,
            232.87371826171875,
            549.7338256835938,
            243.79373168945312
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.920002937316895,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "ately after the shock at t = 3 (starting at t = 4), the responses display two defining characteristics of",
          "bbox": [
            64.08000183105469,
            248.256103515625,
            547.924072265625,
            260.2225646972656
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.898184776306152,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "price-trigger strategies, as outlined in Definition 3.2 and Proposition 3.1. These features of trigger-type",
          "bbox": [
            63.75299835205078,
            265.8301696777344,
            547.9231567382812,
            276.629638671875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "strategies, also reflected in the theoretical benchmark shown in Panels D to F, are as follows: (i) there\nis, on average, no response when the price deviation at t = 3 is small (i.e., the “small deviation”",
          "bbox": [
            64.08000183105469,
            282.2493591308594,
            550.0986328125,
            309.56134033203125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.8214750289917,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "scenario, represented by the solid curve), and (ii) when the price deviation at t = 3 is sufficiently large,",
          "bbox": [
            64.08000183105469,
            313.9971008300781,
            549.2841186523438,
            325.93560791015625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "AI speculators respond by adopting similarly aggressive trading strategies starting at t = 4, despite\nsignificant differences in the deviation’s magnitude at t = 3 (i.e., the “medium deviation,” “large\ndeviation,” and “ultra large deviation” cases, represented by the dotted, dashed, and dash-dotted",
          "bbox": [
            63.65399932861328,
            330.4320983886719,
            547.9187622070312,
            375.3023376464844
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.920002937316895,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "curves, respectively).",
          "bbox": [
            64.08000183105469,
            380.7975158691406,
            165.45826721191406,
            391.7066345214844
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "To further validate the price-trigger punishment scheme among informed AI speculators, Panel A\nshows that for large and ultra-large price deviations, the percentage deviation of the asset’s price\nat t = 4 decreases relative to t = 3 but remains above the long-run mean. In the medium deviation\ncase, the percentage deviation at t = 4 surpasses that at t = 3. Notably, in the medium, large, and\nultra-large cases, price deviations at t = 4 converge to similar magnitudes, driven by comparable",
          "bbox": [
            64.08000183105469,
            397.30718994140625,
            548.343505859375,
            473.913330078125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.80496597290039,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "order flow deviations at t = 4, as shown in Panel C. In contrast, for the small deviation case, both the",
          "bbox": [
            64.08000183105469,
            478.34808349609375,
            547.921630859375,
            490.28662109375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "asset price and informed AI speculators’ profits revert to the long-run mean at t = 4. These nuanced\npatterns of the AI collusive equilibrium closely align with those of the collusive Nash equilibrium",
          "bbox": [
            63.75299835205078,
            494.7830810546875,
            547.9194946289062,
            523.216796875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.843446731567383,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "sustained by price trigger strategies, as depicted in Panels D through F.",
          "bbox": [
            64.08000183105469,
            528.7135009765625,
            410.6076354980469,
            539.6226196289062
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "We emphasize that, although the Q-learning algorithms rely only on the one-period lagged market\nprice pt−1 and fundamental value vt−1 for their decisions at period t, the punishment can extend\nbeyond a single period. Panels A through C of Figure 3 illustrate that informed AI speculators\ncontinue to enforce punishment at t = 5, albeit significantly weaker on average than at t = 4. This\npattern demonstrates that informed AI speculators learn to sustain the collusive equilibrium using",
          "bbox": [
            63.75299835205078,
            545.2271118164062,
            547.9254760742188,
            621.8140258789062
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "price-trigger strategies, where the punishment scheme generally lasts for more than one period.\nTo confirm that the price-trigger strategy employed by informed AI speculators in Panels A\nthrough C of Figure 3 is indeed the driving force behind the collusive, supra-competitive trading",
          "bbox": [
            63.75299835205078,
            627.3245239257812,
            548.3504638671875,
            671.1343383789062
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "profitability observed in Figure 2 under low noise trading risk, we disable the AI speculators’ ability\nto use lagged market prices as a monitoring tool. This is accomplished by removing the lagged",
          "bbox": [
            63.75299835205078,
            676.664794921875,
            548.341552734375,
            704.0053100585938
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.85989761352539,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "market price pt−1 from the state variable st used for decision-making at period t. Our findings reveal",
          "bbox": [
            64.08000183105469,
            709.3114013671875,
            547.9247436523438,
            722.1932373046875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.815974235534668,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "that even in environments with both a significant presence of information-insensitive investors (i.e., a",
          "bbox": [
            64.08000183105469,
            726.0101928710938,
            547.9205322265625,
            736.8151245117188
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.80496597290039,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "32",
          "bbox": [
            300.5450134277344,
            765.1044921875,
            311.4541320800781,
            776.0136108398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        }
      ]
    },
    {
      "page_number": 35,
      "text": "1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n0.02\n0.04\n0.06\n0.08\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n0.01\n0.02\n0.03\n0.04\n0.05\nNote: Both plots are based on Q-learning simulation experiments in a trading environment with ξ = 500, indicating a\nsignificant presence of information-insensitive investors, and σu = 102, indicating high noise trading risk.\nFigure 4: Impulse response function (IRF) of informed AI speculators using Q-learning algorithms\nfollowing an exogenous noise trading shock ushock for σu = 102.\nhigh ξ) and low noise trading risk (i.e., a low σu), the price-trigger punishment scheme cannot be\nlearned, and the collusion capacity, measured by ∆C, drops to zero.\nImpulse Responses: No AI Collusion via Price-Trigger Strategies When σu Is High.\nNext, we\ndemonstrate that the collusive, supra-competitive trading profitability observed under high noise\ntrading risk (i.e., high σu) in Figure 2 is not driven by price trigger strategies, in contrast to the low\nnoise trading risk (i.e., low σu) scenario. The setup of simulation experiments in Figure 4 is the same\nas that in Figure 3 for a straightforward comparison. In Figure 4, we investigate the average IRF\nover the Nsim simulation paths in the environment with high noise trading risk (i.e., σu = 102). A\ncomparison between Panel B of Figure 4 and Panel C of Figure 3 shows that informed AI speculators\ndo not respond at all to the exogenous shock to noise trading flow (ushock) when σu is high, let alone\nrespond according to price-trigger strategies. This finding is consistent with the theoretical result\nof Proposition 3.1, which states that a collusive Nash equilibrium sustained through price-trigger\nstrategies does not exist in an environment with high noise trading risk.\nImpulse Responses: AI Collusion via Over-Pruning Bias When σu Is High.\nLastly, we investigate\nhow informed AI speculators achieve and sustain supra-competitive profits despite being unable to\nlearn and employ price-trigger strategies under high noise trading risk (i.e., high σu). Our analysis\ndemonstrates that informed AI speculators can reach an AI collusive equilibrium through over-\npruning bias in learning. This behavior corresponds to the theoretical collusive experience-based\nequilibrium, sustained by an over-perceived aversion to noise trading risk, as described in Definition\n3.3 and Proposition 3.2. To illustrate this, we compare the IRFs following a unilateral trading deviation\nby one informed AI speculator in two environments: one with low noise trading risk (σu = 10−1) and\nthe other with high noise trading risk (σu = 102), as shown in Figure 5. Specifically, we exogenously\nforce a single informed AI speculator, labeled as i, to deviate from its learned optimal strategy for\none period at t = 3, uniformly across all Nsim simulation paths. This one-period deviation at t = 3 is\ndesigned to increase the contemporaneous trading profit of the deviating speculator. Concretely, we\nexogenously increase the order flow of the deviating speculator by xi,shock if vt > v and reduce its\n33\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "1\n2\n3\n4\n5\n6\n7\n8\n9\n0",
          "bbox": [
            96.07608032226562,
            160.96527099609375,
            297.4645690917969,
            180.86538696289062
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.875936508178711,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.02",
          "bbox": [
            83.71307373046875,
            137.0263214111328,
            100.98564910888672,
            145.90225219726562
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.875936508178711,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.04",
          "bbox": [
            83.71307373046875,
            113.08736419677734,
            100.98564910888672,
            121.96329498291016
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.875936508178711,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.06",
          "bbox": [
            83.71307373046875,
            89.1484146118164,
            100.98564910888672,
            98.02434539794922
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.875936508178711,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.08",
          "bbox": [
            83.71307373046875,
            65.20947265625,
            100.98564910888672,
            74.08540344238281
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.875936508178711,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1\n2\n3\n4\n5\n6\n7\n8\n9\n0",
          "bbox": [
            347.3778381347656,
            159.70518493652344,
            548.7662353515625,
            180.86538696289062
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.875936508178711,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.01",
          "bbox": [
            335.01483154296875,
            141.43609619140625,
            352.2873840332031,
            150.31202697753906
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.875936508178711,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.02",
          "bbox": [
            335.01483154296875,
            123.16676330566406,
            352.2873840332031,
            132.04269409179688
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.875936508178711,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.03",
          "bbox": [
            335.01483154296875,
            104.89765930175781,
            352.2873840332031,
            113.77359008789062
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.875936508178711,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.04",
          "bbox": [
            335.01483154296875,
            86.62857055664062,
            352.2873840332031,
            95.50450134277344
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.875936508178711,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.05",
          "bbox": [
            335.01483154296875,
            68.3592300415039,
            352.2873840332031,
            77.23516082763672
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.875936508178711,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "Note: Both plots are based on Q-learning simulation experiments in a trading environment with ξ = 500, indicating a\nsignificant presence of information-insensitive investors, and σu = 102, indicating high noise trading risk.",
          "bbox": [
            64.08000183105469,
            201.38912963867188,
            547.9243774414062,
            223.03614807128906
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 9.055620193481445,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Figure 4: Impulse response function (IRF) of informed AI speculators using Q-learning algorithms\nfollowing an exogenous noise trading shock ushock for σu = 102.",
          "bbox": [
            64.08000183105469,
            233.76861572265625,
            547.9155883789062,
            260.28265380859375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.9689359664917,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "high ξ) and low noise trading risk (i.e., a low σu), the price-trigger punishment scheme cannot be",
          "bbox": [
            64.08000183105469,
            282.2316589355469,
            547.9164428710938,
            294.10516357421875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "learned, and the collusion capacity, measured by ∆C, drops to zero.",
          "bbox": [
            64.08000183105469,
            296.7540588378906,
            390.9988098144531,
            309.65362548828125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Impulse Responses: No AI Collusion via Price-Trigger Strategies When σu Is High.\nNext, we\ndemonstrate that the collusive, supra-competitive trading profitability observed under high noise\ntrading risk (i.e., high σu) in Figure 2 is not driven by price trigger strategies, in contrast to the low",
          "bbox": [
            64.08000183105469,
            331.479736328125,
            548.3792114257812,
            376.4731750488281
          ],
          "font_info": {
            "font": "URWPalladioL-BoldItal",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 22
          }
        },
        {
          "text": "noise trading risk (i.e., low σu) scenario. The setup of simulation experiments in Figure 4 is the same\nas that in Figure 3 for a straightforward comparison. In Figure 4, we investigate the average IRF\nover the Nsim simulation paths in the environment with high noise trading risk (i.e., σu = 102). A",
          "bbox": [
            64.08000183105469,
            381.1606140136719,
            548.3433227539062,
            426.8413391113281
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.843446731567383,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "comparison between Panel B of Figure 4 and Panel C of Figure 3 shows that informed AI speculators",
          "bbox": [
            64.08000183105469,
            430.4892578125,
            547.9205322265625,
            441.29974365234375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.810471534729004,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "do not respond at all to the exogenous shock to noise trading flow (ushock) when σu is high, let alone\nrespond according to price-trigger strategies. This finding is consistent with the theoretical result\nof Proposition 3.1, which states that a collusive Nash equilibrium sustained through price-trigger",
          "bbox": [
            64.08000183105469,
            446.6644287109375,
            548.1388549804688,
            490.663330078125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.854416847229004,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "strategies does not exist in an environment with high noise trading risk.",
          "bbox": [
            64.08000183105469,
            496.1595153808594,
            414.80755615234375,
            507.0686340332031
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Impulse Responses: AI Collusion via Over-Pruning Bias When σu Is High.\nLastly, we investigate",
          "bbox": [
            64.08000183105469,
            528.9107666015625,
            547.9202270507812,
            541.5427856445312
          ],
          "font_info": {
            "font": "URWPalladioL-BoldItal",
            "size": 10.996026039123535,
            "color": 0,
            "flags": 22
          }
        },
        {
          "text": "how informed AI speculators achieve and sustain supra-competitive profits despite being unable to\nlearn and employ price-trigger strategies under high noise trading risk (i.e., high σu). Our analysis\ndemonstrates that informed AI speculators can reach an AI collusive equilibrium through over-\npruning bias in learning. This behavior corresponds to the theoretical collusive experience-based",
          "bbox": [
            63.75299835205078,
            545.6536254882812,
            549.72998046875,
            605.90234375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.91455364227295,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "equilibrium, sustained by an over-perceived aversion to noise trading risk, as described in Definition",
          "bbox": [
            64.08000183105469,
            611.4446411132812,
            547.9237060546875,
            622.2880859375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.843446731567383,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "3.3 and Proposition 3.2. To illustrate this, we compare the IRFs following a unilateral trading deviation",
          "bbox": [
            64.08000183105469,
            627.912109375,
            547.9187622070312,
            638.7116088867188
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 856203,
            "flags": 4
          }
        },
        {
          "text": "by one informed AI speculator in two environments: one with low noise trading risk (σu = 10−1) and",
          "bbox": [
            64.08000183105469,
            641.5338745117188,
            547.9168701171875,
            656.21142578125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "the other with high noise trading risk (σu = 102), as shown in Figure 5. Specifically, we exogenously\nforce a single informed AI speculator, labeled as i, to deviate from its learned optimal strategy for",
          "bbox": [
            64.08000183105469,
            658.8512573242188,
            548.3489990234375,
            688.0783081054688
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.887259483337402,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "one period at t = 3, uniformly across all Nsim simulation paths. This one-period deviation at t = 3 is",
          "bbox": [
            64.08000183105469,
            692.5130615234375,
            547.9200439453125,
            706.3851318359375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.854416847229004,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "designed to increase the contemporaneous trading profit of the deviating speculator. Concretely, we\nexogenously increase the order flow of the deviating speculator by xi,shock if vt > v and reduce its",
          "bbox": [
            64.08000183105469,
            710.0281372070312,
            547.9220581054688,
            739.3973388671875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.881793022155762,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "33",
          "bbox": [
            300.5450134277344,
            765.1044921875,
            311.4541320800781,
            776.0136108398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        }
      ]
    },
    {
      "page_number": 36,
      "text": "1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n0.01\n0.02\n0.03\n0.04\n1\n2\n3\n4\n5\n6\n7\n8\n9\n-0.02\n-0.01\n0\n0.01\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n0.01\n0.02\n0.03\n0.04\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n0.01\n0.02\n0.03\n0.04\n1\n2\n3\n4\n5\n6\n7\n8\n9\n-0.02\n-0.01\n0\n0.01\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n0.01\n0.02\n0.03\n0.04\nNote: All the plots are based on simulation experiments using Q-learning algorithms in a trading environment with\nξ = 500, indicating a significant presence of information-insensitive investors.\nFigure 5: Impulse response function (IRF) following a unilateral deviation in trading order flows\nxi,shock, shown for σu = 10−1 (left column) and σu = 102 (right column) under Q-learning.\norder flow by xi,shock if vt < v.\nServing as a benchmark for comparison, Panels A through C of Figure 5 show the IRF following a\nunilateral deviation by AI speculator i (solid line) at t = 3, under the low noise trading risk scenario\n(σu = 10−1). Panel C specifically illustrates the exogenous deviation that forces AI speculator i (solid\nline) to trade more aggressively at t = 3, while the other AI speculator (dashed line) maintains its\noriginal trading behavior at t = 3. As shown in Panel A, the aggressive trading by AI speculator i\ncauses the market price pt to rise at t = 3. Panel B illustrates that the deviating AI speculator (solid\nline) achieves higher profits, while the non-deviating AI speculator (dashed line) incurs losses at\nt = 3. According to Definition 3.1, which formally defines a collusive equilibrium, the IRF results\nsupport the findings in Figure 2. Together, they show that informed AI speculators can interact and\nlearn to sustain such an equilibrium in low noise trading risk environments. More importantly, the\nresponses of informed AI speculators to this unilateral deviation in subsequent periods, starting\n34\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "1\n2\n3\n4\n5\n6\n7\n8\n9",
          "bbox": [
            103.83600616455078,
            162.73577880859375,
            289.1819152832031,
            171.1378631591797
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0",
          "bbox": [
            98.59320068359375,
            149.890380859375,
            103.2635726928711,
            158.29246520996094
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.01",
          "bbox": [
            86.89318084716797,
            126.5215835571289,
            103.2394790649414,
            134.9236602783203
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.02",
          "bbox": [
            86.89318084716797,
            103.15296173095703,
            103.2394790649414,
            111.55503845214844
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.03",
          "bbox": [
            86.89318084716797,
            79.78433990478516,
            103.2394790649414,
            88.18641662597656
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.04",
          "bbox": [
            86.89318084716797,
            56.41553497314453,
            103.2394790649414,
            64.81761169433594
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1\n2\n3\n4\n5\n6\n7\n8\n9",
          "bbox": [
            103.83600616455078,
            299.1529846191406,
            289.1819152832031,
            307.5550537109375
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "-0.02",
          "bbox": [
            83.96820068359375,
            278.7127380371094,
            103.11168670654297,
            287.11480712890625
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "-0.01",
          "bbox": [
            83.96820068359375,
            254.17556762695312,
            103.11168670654297,
            262.57763671875
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0",
          "bbox": [
            98.59323120117188,
            229.63864135742188,
            103.26360321044922,
            238.0407257080078
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.01",
          "bbox": [
            86.89321899414062,
            205.10147094726562,
            103.23951721191406,
            213.50355529785156
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1\n2\n3\n4\n5\n6\n7\n8\n9",
          "bbox": [
            103.83600616455078,
            435.5704040527344,
            289.1819152832031,
            443.97247314453125
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0",
          "bbox": [
            98.59320068359375,
            422.7250061035156,
            103.2635726928711,
            431.1270751953125
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.01",
          "bbox": [
            86.89318084716797,
            399.35638427734375,
            103.2394790649414,
            407.7584533691406
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.02",
          "bbox": [
            86.89318084716797,
            375.9877624511719,
            103.2394790649414,
            384.38983154296875
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.03",
          "bbox": [
            86.89318084716797,
            352.61895751953125,
            103.2394790649414,
            361.0210266113281
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.04",
          "bbox": [
            86.89318084716797,
            329.2503356933594,
            103.2394790649414,
            337.65240478515625
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1\n2\n3\n4\n5\n6\n7\n8\n9",
          "bbox": [
            341.6610107421875,
            162.73577880859375,
            527.0066528320312,
            171.1378631591797
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0",
          "bbox": [
            336.418212890625,
            149.890380859375,
            341.0885925292969,
            158.29246520996094
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.01",
          "bbox": [
            324.71820068359375,
            126.5215835571289,
            341.06451416015625,
            134.9236602783203
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.02",
          "bbox": [
            324.71820068359375,
            103.15296173095703,
            341.06451416015625,
            111.55503845214844
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.03",
          "bbox": [
            324.71820068359375,
            79.78433990478516,
            341.06451416015625,
            88.18641662597656
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.04",
          "bbox": [
            324.71820068359375,
            56.41553497314453,
            341.06451416015625,
            64.81761169433594
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1\n2\n3\n4\n5\n6\n7\n8\n9",
          "bbox": [
            341.6610107421875,
            299.1529846191406,
            527.0066528320312,
            307.5550537109375
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "-0.02",
          "bbox": [
            321.793212890625,
            278.7127380371094,
            340.93670654296875,
            287.11480712890625
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "-0.01",
          "bbox": [
            321.793212890625,
            254.17556762695312,
            340.93670654296875,
            262.57763671875
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0",
          "bbox": [
            336.4182434082031,
            229.63864135742188,
            341.088623046875,
            238.0407257080078
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.01",
          "bbox": [
            324.7182312011719,
            205.10147094726562,
            341.0645446777344,
            213.50355529785156
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1\n2\n3\n4\n5\n6\n7\n8\n9",
          "bbox": [
            341.6610107421875,
            435.5704040527344,
            527.0066528320312,
            443.97247314453125
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0",
          "bbox": [
            336.418212890625,
            422.7250061035156,
            341.0885925292969,
            431.1270751953125
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.01",
          "bbox": [
            324.71820068359375,
            399.35638427734375,
            341.06451416015625,
            407.7584533691406
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.02",
          "bbox": [
            324.71820068359375,
            375.9877624511719,
            341.06451416015625,
            384.38983154296875
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.03",
          "bbox": [
            324.71820068359375,
            352.61895751953125,
            341.06451416015625,
            361.0210266113281
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.04",
          "bbox": [
            324.71820068359375,
            329.2503356933594,
            341.06451416015625,
            337.65240478515625
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.402073860168457,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "Note: All the plots are based on simulation experiments using Q-learning algorithms in a trading environment with\nξ = 500, indicating a significant presence of information-insensitive investors.",
          "bbox": [
            64.08000183105469,
            462.0947265625,
            547.9163208007812,
            482.81280517578125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 9.055620193481445,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Figure 5: Impulse response function (IRF) following a unilateral deviation in trading order flows\nxi,shock, shown for σu = 10−1 (left column) and σu = 102 (right column) under Q-learning.",
          "bbox": [
            64.08000183105469,
            493.63067626953125,
            547.9163818359375,
            519.3493041992188
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "order flow by xi,shock if vt < v.",
          "bbox": [
            64.07998657226562,
            541.1461181640625,
            210.0852813720703,
            555.129638671875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Serving as a benchmark for comparison, Panels A through C of Figure 5 show the IRF following a",
          "bbox": [
            81.01599884033203,
            558.7211303710938,
            547.9203491210938,
            569.5206298828125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "unilateral deviation by AI speculator i (solid line) at t = 3, under the low noise trading risk scenario",
          "bbox": [
            64.08000183105469,
            574.01708984375,
            547.9228515625,
            585.975830078125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.870850563049316,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "(σu = 10−1). Panel C specifically illustrates the exogenous deviation that forces AI speculator i (solid\nline) to trade more aggressively at t = 3, while the other AI speculator (dashed line) maintains its\noriginal trading behavior at t = 3. As shown in Panel A, the aggressive trading by AI speculator i",
          "bbox": [
            63.720001220703125,
            588.77783203125,
            547.9227294921875,
            635.3223266601562
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.854416847229004,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "causes the market price pt to rise at t = 3. Panel B illustrates that the deviating AI speculator (solid\nline) achieves higher profits, while the non-deviating AI speculator (dashed line) incurs losses at",
          "bbox": [
            64.08000183105469,
            639.757080078125,
            547.9240112304688,
            668.1923217773438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.925451278686523,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "t = 3. According to Definition 3.1, which formally defines a collusive equilibrium, the IRF results",
          "bbox": [
            64.21600341796875,
            672.6270751953125,
            547.9227905273438,
            684.6273193359375
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "support the findings in Figure 2. Together, they show that informed AI speculators can interact and",
          "bbox": [
            64.08000183105469,
            690.12744140625,
            547.9161376953125,
            701.0311279296875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.903643608093262,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "learn to sustain such an equilibrium in low noise trading risk environments. More importantly, the\nresponses of informed AI speculators to this unilateral deviation in subsequent periods, starting",
          "bbox": [
            64.08000183105469,
            706.5350952148438,
            547.9163818359375,
            733.933349609375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.941778182983398,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "34",
          "bbox": [
            300.5450134277344,
            765.1044921875,
            311.4541320800781,
            776.0136108398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        }
      ]
    },
    {
      "page_number": 37,
      "text": "from t = 4, further reinforce the findings of Figure 3, confirming that the AI collusive equilibrium is\nsustained by price-trigger strategies, closely resembling the behavior of a collusive Nash equilibrium\nthrough price-trigger strategies. Specifically, at t = 4, Panel C shows that both AI speculators, on\naverage, engage in equally aggressive trading as a form of punishment for the deviation that occurs\nat t = 3. As shown in Panel B, this behavior results in losses for both AI speculators at t = 4 due to\nthe sharp increase in the market price.\nIn a parallel comparison to the simulation experiments under the low noise trading risk scenario\n(σu = 10−1), Panels D through F of Figure 5 show the IRF for the same experiment, conducted under\nthe high noise trading risk scenario (σu = 102). Specifically, Panel F illustrates AI speculator i being\nforced to trade more aggressively at t = 3, while the other AI speculator (dashed line) maintains its\noriginal trading behavior at t = 3. Panel D shows that this aggressive trading by AI speculator i drives\nthe market price pt higher at t = 3. Consistent with the pattern in Panel B, Panel E demonstrates that\nthe deviating AI speculator (solid line) achieves higher profits at t = 3, while the non-deviating AI\nspeculator (dashed line) incurs losses at t = 3. According to Definition 3.1, these IRF results support\nthe findings of Figure 2, demonstrating that informed AI speculators can still reach an AI collusive\nequilibrium in environments with high noise trading risk. However, while the immediate reactions\nat t = 3 are similar to those in the low noise trading risk scenario, the subsequent responses from\nt = 4 onward differ significantly. The deviating AI speculator reverts to its original trading order\nflow, while the non-deviating AI speculator’s behavior remains unchanged, as shown in Panel F.\nImportantly, we emphasize that the pattern observed in Panel F, where the non-deviating AI\nspeculator remains unresponsive to the deviation behavior, is highly robust. This holds even though,\nas shown in Panel E, the deviating AI speculator exploits the non-deviating one at t = 3 by imposing\ncosts on it. This provides clear evidence that the AI collusive equilibrium in the high noise trading\nrisk scenario is not driven by price-trigger strategies, which theoretically sustain a collusive Nash\nequilibrium. Instead, this AI collusive equilibrium closely mirrors a theoretical collusive experience-\nbased equilibrium, sustained by over-perceived aversion to noise trading risk. Consistent with\nthe experience-based equilibrium, the persistent over-pruning bias in learning prevents the AI\nequilibrium from being altered through new trial-and-error observations within a single period. In\nOnline Appendix 4.2, we formally verify that the AI collusive equilibrium meets the criteria of an\nexperience-based equilibrium, following the methodology of Fershtman and Pakes (2012).\n5.4\nSimulation Experiments in Trading Environments with Low ξ\nThe previous section covers cases (i) and (ii) described in Section 5.1. This section provides evi-\ndence that over-pruning bias, rather than price-trigger strategies, drives AI collusion in the trading\nenvironment of case (iii), where a low ξ leads to strong price discovery by market makers.\nIn a parallel comparison to the simulation experiments with a high ξ value (ξ = 500) in Figure 5,\nFigure 6 presents the IRFs for the same experiment, where an informed AI speculator deviates at\nt = 3 by trading more aggressively (solid line in Panels C and F), conducted in a trading environment\nwith a low ξ value (ξ = 5). Specifically, the left column corresponds to a trading environment with\nσu = 10−1, while the right column corresponds to one with σu = 102. The patterns observed in both\ncolumns of Figure 6 are the same as those in the right column of Figure 5. The immediate reversion\nat t = 4 is highly robust regardless of the level of σu, even though the deviating AI speculator exploits\n35\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "from t = 4, further reinforce the findings of Figure 3, confirming that the AI collusive equilibrium is",
          "bbox": [
            64.08000183105469,
            51.03412628173828,
            547.9193115234375,
            62.994380950927734
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.876322746276855,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "sustained by price-trigger strategies, closely resembling the behavior of a collusive Nash equilibrium\nthrough price-trigger strategies. Specifically, at t = 4, Panel C shows that both AI speculators, on",
          "bbox": [
            64.08000183105469,
            68.58154296875,
            547.9207153320312,
            95.90532684326172
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.837958335876465,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "average, engage in equally aggressive trading as a form of punishment for the deviation that occurs",
          "bbox": [
            64.08000183105469,
            101.41226959228516,
            547.915283203125,
            112.30499267578125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.89272403717041,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "at t = 3. As shown in Panel B, this behavior results in losses for both AI speculators at t = 4 due to",
          "bbox": [
            64.08000183105469,
            116.77509307861328,
            547.9171142578125,
            128.7507781982422
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.930895805358887,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "the sharp increase in the market price.",
          "bbox": [
            64.08000183105469,
            134.27052307128906,
            250.60377502441406,
            145.1796112060547
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "In a parallel comparison to the simulation experiments under the low noise trading risk scenario",
          "bbox": [
            81.01599884033203,
            150.73687744140625,
            547.9237060546875,
            161.6022491455078
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.865375518798828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "(σu = 10−1), Panels D through F of Figure 5 show the IRF for the same experiment, conducted under",
          "bbox": [
            63.720001220703125,
            164.40585327148438,
            548.1339721679688,
            179.08441162109375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.843446731567383,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "the high noise trading risk scenario (σu = 102). Specifically, Panel F illustrates AI speculator i being",
          "bbox": [
            64.08000183105469,
            181.72325134277344,
            547.9205322265625,
            195.5194091796875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.936338424682617,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "forced to trade more aggressively at t = 3, while the other AI speculator (dashed line) maintains its",
          "bbox": [
            64.08000183105469,
            198.95111083984375,
            547.9150390625,
            210.92373657226562
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.920002937316895,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "original trading behavior at t = 3. Panel D shows that this aggressive trading by AI speculator i drives",
          "bbox": [
            64.08000183105469,
            215.3861083984375,
            547.918701171875,
            227.3246307373047
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "the market price pt higher at t = 3. Consistent with the pattern in Panel B, Panel E demonstrates that\nthe deviating AI speculator (solid line) achieves higher profits at t = 3, while the non-deviating AI",
          "bbox": [
            64.08000183105469,
            231.82110595703125,
            547.9200439453125,
            260.2456359863281
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "speculator (dashed line) incurs losses at t = 3. According to Definition 3.1, these IRF results support",
          "bbox": [
            64.08000183105469,
            264.69110107421875,
            547.9202880859375,
            276.646728515625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.85989761352539,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "the findings of Figure 2, demonstrating that informed AI speculators can still reach an AI collusive",
          "bbox": [
            64.08000183105469,
            282.1592102050781,
            547.9240112304688,
            293.1064147949219
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.94721508026123,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "equilibrium in environments with high noise trading risk. However, while the immediate reactions\nat t = 3 are similar to those in the low noise trading risk scenario, the subsequent responses from",
          "bbox": [
            64.08000183105469,
            298.59808349609375,
            547.9171752929688,
            325.9973449707031
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.941778182983398,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "t = 4 onward differ significantly. The deviating AI speculator reverts to its original trading order",
          "bbox": [
            64.21600341796875,
            330.4320983886719,
            548.1438598632812,
            342.4323425292969
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "flow, while the non-deviating AI speculator’s behavior remains unchanged, as shown in Panel F.\nImportantly, we emphasize that the pattern observed in Panel F, where the non-deviating AI",
          "bbox": [
            64.08000183105469,
            347.9275207519531,
            547.9166259765625,
            375.3023376464844
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "speculator remains unresponsive to the deviation behavior, is highly robust. This holds even though,",
          "bbox": [
            64.08000183105469,
            380.8406677246094,
            549.2872924804688,
            391.6896057128906
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.848934173583984,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "as shown in Panel E, the deviating AI speculator exploits the non-deviating one at t = 3 by imposing\ncosts on it. This provides clear evidence that the AI collusive equilibrium in the high noise trading\nrisk scenario is not driven by price-trigger strategies, which theoretically sustain a collusive Nash",
          "bbox": [
            64.08000183105469,
            396.1720886230469,
            547.916259765625,
            441.0423278808594
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.810471534729004,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "equilibrium. Instead, this AI collusive equilibrium closely mirrors a theoretical collusive experience-\nbased equilibrium, sustained by over-perceived aversion to noise trading risk. Consistent with\nthe experience-based equilibrium, the persistent over-pruning bias in learning prevents the AI",
          "bbox": [
            64.08000183105469,
            446.5463562011719,
            549.7291870117188,
            490.34832763671875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.898184776306152,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "equilibrium from being altered through new trial-and-error observations within a single period. In\nOnline Appendix 4.2, we formally verify that the AI collusive equilibrium meets the criteria of an",
          "bbox": [
            64.08000183105469,
            495.8161926269531,
            547.9240112304688,
            523.2183227539062
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.94721508026123,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "experience-based equilibrium, following the methodology of Fershtman and Pakes (2012).",
          "bbox": [
            64.08000183105469,
            528.7135009765625,
            501.3604431152344,
            539.6226196289062
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "5.4\nSimulation Experiments in Trading Environments with Low ξ",
          "bbox": [
            64.08000183105469,
            561.3937377929688,
            430.27313232421875,
            574.4370727539062
          ],
          "font_info": {
            "font": "URWPalladioL-Bold",
            "size": 11.9552001953125,
            "color": 0,
            "flags": 20
          }
        },
        {
          "text": "The previous section covers cases (i) and (ii) described in Section 5.1. This section provides evi-\ndence that over-pruning bias, rather than price-trigger strategies, drives AI collusion in the trading",
          "bbox": [
            63.742000579833984,
            586.2926635742188,
            549.7259521484375,
            613.728515625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "environment of case (iii), where a low ξ leads to strong price discovery by market makers.",
          "bbox": [
            64.08000183105469,
            619.240478515625,
            502.36358642578125,
            631.0361328125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "In a parallel comparison to the simulation experiments with a high ξ value (ξ = 500) in Figure 5,\nFigure 6 presents the IRFs for the same experiment, where an informed AI speculator deviates at",
          "bbox": [
            64.08000183105469,
            634.6151123046875,
            549.2820434570312,
            663.0503540039062
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.876322746276855,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "t = 3 by trading more aggressively (solid line in Panels C and F), conducted in a trading environment\nwith a low ξ value (ξ = 5). Specifically, the left column corresponds to a trading environment with",
          "bbox": [
            63.62200164794922,
            667.485107421875,
            547.9255981445312,
            696.7761840820312
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "σu = 10−1, while the right column corresponds to one with σu = 102. The patterns observed in both",
          "bbox": [
            64.21600341796875,
            698.681884765625,
            547.92236328125,
            713.359375
          ],
          "font_info": {
            "font": "PazoMath-Italic",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "columns of Figure 6 are the same as those in the right column of Figure 5. The immediate reversion",
          "bbox": [
            64.08000183105469,
            717.8593139648438,
            547.9216918945312,
            728.7575073242188
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.898184776306152,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "at t = 4 is highly robust regardless of the level of σu, even though the deviating AI speculator exploits",
          "bbox": [
            64.08000183105469,
            733.22607421875,
            547.9151611328125,
            746.0821533203125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "35",
          "bbox": [
            300.5450134277344,
            765.1044921875,
            311.4541320800781,
            776.0136108398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        }
      ]
    },
    {
      "page_number": 38,
      "text": "1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n5\n10\n15\n20\n10-3\n1\n2\n3\n4\n5\n6\n7\n8\n9\n-0.02\n-0.01\n0\n0.01\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n0.01\n0.02\n0.03\n0.04\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n5\n10\n15\n20\n10-3\n1\n2\n3\n4\n5\n6\n7\n8\n9\n-0.02\n-0.01\n0\n0.01\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n0.01\n0.02\n0.03\n0.04\nNote: All the plots are based on simulation experiments using Q-learning algorithms in a trading environment with ξ = 5,\nreflecting a minimal presence of information-insensitive investors.\nFigure 6: Impulse response function (IRF) following a unilateral deviation in trading order flows\nxi,shock in the trading environment with ξ = 5, shown for σu = 10−1 (left column) and σu = 102 (right\ncolumn) under Q-learning.\nthe non-deviating AI speculator at t = 3 by imposing costs on it, as shown in Panels B and E.\nThese patterns clearly show that the AI collusive equilibrium in a low-ξ environment is not driven\nby price-trigger strategies. Instead, it is sustained by over-pruning bias against aggressive strategies,\nclosely resembling a theoretical experience-based equilibrium driven by over-perceived aversion to\nnoise trading risk. In Online Appendix 4.2, following Fershtman and Pakes (2012), we formally verify\nthat the AI collusive outcome meets the criteria for an experience-based equilibrium.\n5.5\nIntuition Behind AI Collusion and Its Underlying Algorithmic Mechanisms\nThis section explains why AI collusion through price-trigger strategies or over-pruning bias in\nlearning either occurs or does not occur across three trading environments: (i) high ξ and low σu, (ii)\nhigh ξ and high σu, and (iii) low ξ. Detailed explanations are provided in Online Appendix 3.\n36\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "1\n2\n3\n4\n5\n6\n7\n8\n9",
          "bbox": [
            100.46905517578125,
            164.62802124023438,
            288.9040222167969,
            173.17013549804688
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.542108535766602,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0",
          "bbox": [
            95.13886260986328,
            147.24850463867188,
            99.88706970214844,
            155.79061889648438
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.542108535766602,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "5",
          "bbox": [
            95.13886260986328,
            124.57034301757812,
            99.88706970214844,
            133.11245727539062
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.542108535766602,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "10",
          "bbox": [
            90.33511352539062,
            101.89218139648438,
            99.83154296875,
            110.43428802490234
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.542108535766602,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "15",
          "bbox": [
            90.33511352539062,
            79.21380615234375,
            99.83154296875,
            87.75591278076172
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.542108535766602,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "20\n10-3",
          "bbox": [
            90.33511352539062,
            48.69335174560547,
            125.18558502197266,
            65.07775115966797
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.542108535766602,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1\n2\n3\n4\n5\n6\n7\n8\n9",
          "bbox": [
            100.46905517578125,
            303.31884765625,
            288.9040222167969,
            311.8609619140625
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.542108535766602,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "-0.02",
          "bbox": [
            80.27011108398438,
            282.5379638671875,
            99.73265075683594,
            291.080078125
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.542108535766602,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "-0.01",
          "bbox": [
            80.27011108398438,
            257.59185791015625,
            99.73265075683594,
            266.13397216796875
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.542108535766602,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0",
          "bbox": [
            95.13890075683594,
            232.6459503173828,
            99.88711547851562,
            241.1880645751953
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.542108535766602,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.01",
          "bbox": [
            83.24388122558594,
            207.6998291015625,
            99.86262512207031,
            216.241943359375
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.542108535766602,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1\n2\n3\n4\n5\n6\n7\n8\n9",
          "bbox": [
            100.46905517578125,
            442.0099182128906,
            288.9040222167969,
            450.5520324707031
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.542108535766602,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0",
          "bbox": [
            95.13886260986328,
            428.950439453125,
            99.88706970214844,
            437.4925537109375
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.542108535766602,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.01",
          "bbox": [
            83.24384307861328,
            405.19232177734375,
            99.86257934570312,
            413.73443603515625
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.542108535766602,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.02",
          "bbox": [
            83.24384307861328,
            381.4342346191406,
            99.86257934570312,
            389.9763488769531
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.542108535766602,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.03",
          "bbox": [
            83.24384307861328,
            357.6759338378906,
            99.86257934570312,
            366.2180480957031
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.542108535766602,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.04",
          "bbox": [
            83.24384307861328,
            333.9178466796875,
            99.86257934570312,
            342.4599609375
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.542108535766602,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1\n2\n3\n4\n5\n6\n7\n8\n9",
          "bbox": [
            342.2577819824219,
            164.62802124023438,
            530.6925659179688,
            173.17013549804688
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.542108535766602,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0",
          "bbox": [
            336.9276123046875,
            147.24850463867188,
            341.6758117675781,
            155.79061889648438
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.542108535766602,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "5",
          "bbox": [
            336.9276123046875,
            124.57034301757812,
            341.6758117675781,
            133.11245727539062
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.542108535766602,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "10",
          "bbox": [
            332.1238708496094,
            101.89218139648438,
            341.62030029296875,
            110.43428802490234
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.542108535766602,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "15",
          "bbox": [
            332.1238708496094,
            79.21380615234375,
            341.62030029296875,
            87.75591278076172
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.542108535766602,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "20\n10-3",
          "bbox": [
            332.1238708496094,
            48.69335174560547,
            366.9743347167969,
            65.07775115966797
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.542108535766602,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1\n2\n3\n4\n5\n6\n7\n8\n9",
          "bbox": [
            342.2577819824219,
            303.31884765625,
            530.6925659179688,
            311.8609619140625
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.542108535766602,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "-0.02",
          "bbox": [
            322.0588684082031,
            282.5379638671875,
            341.5213928222656,
            291.080078125
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.542108535766602,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "-0.01",
          "bbox": [
            322.0588684082031,
            257.59185791015625,
            341.5213928222656,
            266.13397216796875
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.542108535766602,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0",
          "bbox": [
            336.92767333984375,
            232.6459503173828,
            341.6758728027344,
            241.1880645751953
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.542108535766602,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.01",
          "bbox": [
            325.03265380859375,
            207.6998291015625,
            341.6513671875,
            216.241943359375
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.542108535766602,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1\n2\n3\n4\n5\n6\n7\n8\n9",
          "bbox": [
            342.2577819824219,
            442.0099182128906,
            530.6925659179688,
            450.5520324707031
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.542108535766602,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0",
          "bbox": [
            336.9276123046875,
            428.950439453125,
            341.6758117675781,
            437.4925537109375
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.542108535766602,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.01",
          "bbox": [
            325.0325927734375,
            405.19232177734375,
            341.6513366699219,
            413.73443603515625
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.542108535766602,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.02",
          "bbox": [
            325.0325927734375,
            381.4342346191406,
            341.6513366699219,
            389.9763488769531
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.542108535766602,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.03",
          "bbox": [
            325.0325927734375,
            357.6759338378906,
            341.6513366699219,
            366.2180480957031
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.542108535766602,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.04",
          "bbox": [
            325.0325927734375,
            333.9178466796875,
            341.6513366699219,
            342.4599609375
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 8.542108535766602,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "Note: All the plots are based on simulation experiments using Q-learning algorithms in a trading environment with ξ = 5,\nreflecting a minimal presence of information-insensitive investors.",
          "bbox": [
            64.08000183105469,
            468.0511474609375,
            549.0404663085938,
            488.84814453125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 8.907927513122559,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Figure 6: Impulse response function (IRF) following a unilateral deviation in trading order flows\nxi,shock in the trading environment with ξ = 5, shown for σu = 10−1 (left column) and σu = 102 (right\ncolumn) under Q-learning.",
          "bbox": [
            64.08000183105469,
            500.3946533203125,
            547.9198608398438,
            538.4806518554688
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "the non-deviating AI speculator at t = 3 by imposing costs on it, as shown in Panels B and E.",
          "bbox": [
            64.08000183105469,
            561.455078125,
            517.4456176757812,
            573.4246215820312
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "These patterns clearly show that the AI collusive equilibrium in a low-ξ environment is not driven",
          "bbox": [
            81.01599884033203,
            579.0301513671875,
            547.9207153320312,
            590.7471923828125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "by price-trigger strategies. Instead, it is sustained by over-pruning bias against aggressive strategies,\nclosely resembling a theoretical experience-based equilibrium driven by over-perceived aversion to",
          "bbox": [
            64.08000183105469,
            595.4022216796875,
            549.2882080078125,
            622.7445068359375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.887259483337402,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "noise trading risk. In Online Appendix 4.2, following Fershtman and Pakes (2012), we formally verify",
          "bbox": [
            64.08000183105469,
            628.3351440429688,
            548.346435546875,
            639.1346435546875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "that the AI collusive outcome meets the criteria for an experience-based equilibrium.",
          "bbox": [
            64.08000183105469,
            644.6915283203125,
            475.85498046875,
            655.6006469726562
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "5.5\nIntuition Behind AI Collusion and Its Underlying Algorithmic Mechanisms",
          "bbox": [
            64.08000183105469,
            677.3707885742188,
            508.87322998046875,
            689.3259887695312
          ],
          "font_info": {
            "font": "URWPalladioL-Bold",
            "size": 11.9552001953125,
            "color": 0,
            "flags": 20
          }
        },
        {
          "text": "This section explains why AI collusion through price-trigger strategies or over-pruning bias in",
          "bbox": [
            63.742000579833984,
            702.2686767578125,
            547.9232177734375,
            713.2863159179688
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "learning either occurs or does not occur across three trading environments: (i) high ξ and low σu, (ii)",
          "bbox": [
            64.08000183105469,
            718.82861328125,
            549.012451171875,
            730.5771484375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.843446731567383,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "high ξ and high σu, and (iii) low ξ. Detailed explanations are provided in Online Appendix 3.",
          "bbox": [
            64.08000183105469,
            735.217529296875,
            519.5577392578125,
            747.01318359375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "36",
          "bbox": [
            300.5450134277344,
            765.1044921875,
            311.4541320800781,
            776.0136108398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        }
      ]
    },
    {
      "page_number": 39,
      "text": "Case (i): Low σu and High ξ.\nWhy cannot an AI collusive equilibrium sustained by over-pruning\nbias emerge in such environments? When σu is low and ξ is high, noise trading flows have minimal\nimpact on an informed AI speculator’s profit. This allows the exploration-exploitation tradeoff\nto operate effectively, mitigating over-pruning bias against aggressive strategies. Since algorithms\nrarely incur large losses from noise trading shocks, even when exploring aggressive strategies, these\nstrategies are not prematurely pruned and remain in the learning process. As a result, they are\nproperly evaluated and retained, preventing the emergence of AI collusion through over-pruning\nbias. Further details are provided in Result 1 of Online Appendix 3.1.1.\nWe now explain why an AI collusive equilibrium sustained by price-trigger strategies emerges in\nsuch environments, focusing on how informed AI speculators achieve it using Q-learning algorithms.\nHigh price informativeness is essential, as it ensures that market prices reflect the trading order flow of\ninformed speculators. This allows algorithms to condition their strategies on the unobserved actions\nof others, indirectly, through observed prices. In these environments, aggressive trading strategies\nmake the market price pt moves strongly with the fundamental value vt, and this strong alignment\nis reflected in the next period’s state vector, defined as st+1 = {pt, vt, vt+1}. Conversely, when all\nalgorithms trade conservatively, the price pt responds only moderately to vt, and this moderate\nalignment is similarly captured in the state vector st+1 = {pt, vt, vt+1}. Thus, from the perspective\nof the next period, the lagged price pt, as an endogenous state variable, becomes informative about\nwhether all algorithms traded conservatively in period t. This informativeness is a necessary condition\nfor price-trigger strategies to be effective. Model-free Q-learning algorithms do not logically infer the\nrelationship between lagged prices and others’ past order flows. Instead, they focus solely on learning\nthe optimal trading strategy for a given state. Nonetheless, their update rules inherently account for\nhow current trading behavior is mechanically connected with the next period’s price state, and this\nconnection is incorporated into the Q-value update, as shown in (2.4). This is a process of pattern\nrecognition, not logical reasoning. It fundamentally differs from logic-based human coordination,\nwhich requires understanding punishment-for-deviation causality and logically inferring others’\nactions from prices.\nIn addition, for algorithms to adopt price-trigger strategies, they must first learn to assign very\nlow Q-values to aggressive trading strategies across all states. This learning process unfolds in\ntwo distinct phases. In the early phase, when exploration dominates (i.e., exploration rates remain\nhigh for all algorithms), strategies are selected largely at random, and Q-values are updated based\non realized payoffs. During this phase, aggressive strategies tend to receive higher Q-values than\nconservative ones. This is because aggressive strategies yield much higher payoffs when played\nagainst opponents who randomly choose to trade aggressively. This asymmetry causes algorithms\nto assign higher Q-values to aggressive trading strategies than conservative ones early on. As\nthe exploration rate gradually declines to zero, the system transitions into a phase dominated\nby exploitation. Algorithms begin to consistently choose actions with higher learned Q-values.\nThus, early in this exploitation-intensive phase, algorithms continue to favor aggressive strategies\ninherited from the earlier exploration-intensive phase. They then settle on a state-action pair in\nwhich lagged market prices move strongly with lagged fundamentals and trading flows respond\naggressively to current private signals about fundamental values. This dynamic persists because\neven when the system occasionally enters states where lagged prices respond only moderately to\n37\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "Case (i): Low σu and High ξ.\nWhy cannot an AI collusive equilibrium sustained by over-pruning",
          "bbox": [
            64.08000183105469,
            51.77875518798828,
            547.9221801757812,
            64.4172134399414
          ],
          "font_info": {
            "font": "URWPalladioL-BoldItal",
            "size": 11.001436233520508,
            "color": 0,
            "flags": 22
          }
        },
        {
          "text": "bias emerge in such environments? When σu is low and ξ is high, noise trading flows have minimal\nimpact on an informed AI speculator’s profit. This allows the exploration-exploitation tradeoff\nto operate effectively, mitigating over-pruning bias against aggressive strategies. Since algorithms",
          "bbox": [
            64.08000183105469,
            68.54227447509766,
            547.927490234375,
            112.34032440185547
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.89272403717041,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "rarely incur large losses from noise trading shocks, even when exploring aggressive strategies, these\nstrategies are not prematurely pruned and remain in the learning process. As a result, they are\nproperly evaluated and retained, preventing the emergence of AI collusion through over-pruning",
          "bbox": [
            63.75299835205078,
            117.85902404785156,
            547.9232177734375,
            161.64532470703125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.876322746276855,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "bias. Further details are provided in Result 1 of Online Appendix 3.1.1.",
          "bbox": [
            64.08000183105469,
            167.14051818847656,
            410.35675048828125,
            178.0496063232422
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "We now explain why an AI collusive equilibrium sustained by price-trigger strategies emerges in",
          "bbox": [
            81.01599884033203,
            183.62258911132812,
            547.9164428710938,
            194.46603393554688
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.843446731567383,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "such environments, focusing on how informed AI speculators achieve it using Q-learning algorithms.",
          "bbox": [
            64.08000183105469,
            200.082275390625,
            549.8274536132812,
            210.8927459716797
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.810471534729004,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "High price informativeness is essential, as it ensures that market prices reflect the trading order flow of",
          "bbox": [
            64.08000183105469,
            216.52517700195312,
            547.918701171875,
            227.3246307373047
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "informed speculators. This allows algorithms to condition their strategies on the unobserved actions\nof others, indirectly, through observed prices. In these environments, aggressive trading strategies",
          "bbox": [
            64.08000183105469,
            232.92076110839844,
            547.9255981445312,
            260.2502136230469
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.854416847229004,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "make the market price pt moves strongly with the fundamental value vt, and this strong alignment\nis reflected in the next period’s state vector, defined as st+1 = {pt, vt, vt+1}. Conversely, when all\nalgorithms trade conservatively, the price pt responds only moderately to vt, and this moderate\nalignment is similarly captured in the state vector st+1 = {pt, vt, vt+1}. Thus, from the perspective",
          "bbox": [
            64.08000183105469,
            265.56243896484375,
            547.9194946289062,
            327.1744079589844
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.941778182983398,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "of the next period, the lagged price pt, as an endogenous state variable, becomes informative about",
          "bbox": [
            64.08000183105469,
            331.3034362792969,
            547.9172973632812,
            343.06817626953125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.930895805358887,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "whether all algorithms traded conservatively in period t. This informativeness is a necessary condition",
          "bbox": [
            63.62200164794922,
            347.7384338378906,
            547.9151000976562,
            358.80560302734375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "for price-trigger strategies to be effective. Model-free Q-learning algorithms do not logically infer the",
          "bbox": [
            64.08000183105469,
            364.42535400390625,
            547.9181518554688,
            375.2468566894531
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.8214750289917,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "relationship between lagged prices and others’ past order flows. Instead, they focus solely on learning",
          "bbox": [
            64.08000183105469,
            380.87615966796875,
            547.9188842773438,
            391.67559814453125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "the optimal trading strategy for a given state. Nonetheless, their update rules inherently account for",
          "bbox": [
            64.08000183105469,
            397.25994873046875,
            548.1406860351562,
            408.13079833984375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.870850563049316,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "how current trading behavior is mechanically connected with the next period’s price state, and this\nconnection is incorporated into the Q-value update, as shown in (2.4). This is a process of pattern\nrecognition, not logical reasoning. It fundamentally differs from logic-based human coordination,\nwhich requires understanding punishment-for-deviation causality and logically inferring others’",
          "bbox": [
            63.62200164794922,
            413.6518859863281,
            550.051025390625,
            473.913330078125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.930895805358887,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "actions from prices.\nIn addition, for algorithms to adopt price-trigger strategies, they must first learn to assign very\nlow Q-values to aggressive trading strategies across all states. This learning process unfolds in\ntwo distinct phases. In the early phase, when exploration dominates (i.e., exploration rates remain\nhigh for all algorithms), strategies are selected largely at random, and Q-values are updated based\non realized payoffs. During this phase, aggressive strategies tend to receive higher Q-values than\nconservative ones. This is because aggressive strategies yield much higher payoffs when played\nagainst opponents who randomly choose to trade aggressively. This asymmetry causes algorithms\nto assign higher Q-values to aggressive trading strategies than conservative ones early on. As\nthe exploration rate gradually declines to zero, the system transitions into a phase dominated\nby exploitation. Algorithms begin to consistently choose actions with higher learned Q-values.\nThus, early in this exploitation-intensive phase, algorithms continue to favor aggressive strategies\ninherited from the earlier exploration-intensive phase. They then settle on a state-action pair in\nwhich lagged market prices move strongly with lagged fundamentals and trading flows respond\naggressively to current private signals about fundamental values. This dynamic persists because\neven when the system occasionally enters states where lagged prices respond only moderately to",
          "bbox": [
            63.62200164794922,
            479.40850830078125,
            549.8302001953125,
            736.8753051757812
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "37",
          "bbox": [
            300.5450134277344,
            765.1044921875,
            311.4541320800781,
            776.0136108398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        }
      ]
    },
    {
      "page_number": 40,
      "text": "lagged fundamentals, algorithms continue to select aggressive actions, which push the market, in\nthe next period, back to states where lagged prices respond strongly to lagged fundamentals. These\nactions result in both low immediate profits and weak continuation values. Consequently, over many\niterations, the Q-values of aggressive trading strategies gradually decline across all states, whether\ncharacterized by lagged prices strongly tracking lagged fundamentals or only moderately responding\nto them, due to persistently poor outcomes in both immediate profits and continuation values.\nLastly, for algorithms to adopt price-trigger strategies, they must eventually learn to assign\nvery high Q-values to conservative trading in states where lagged prices respond only moderately\nto lagged fundamentals. How does this occur? As discussed earlier, over many iterations, the\nQ-values of aggressive strategies in states where lagged prices respond only moderately to lagged\nfundamentals gradually decline to very low levels and eventually fall below those of conservative\nstrategies in the same states. Once this shift occurs, the algorithms begin to reinforce the state-action\npair characterized by lagged prices responding only moderately to fundamentals and conservative\ntrading in response to current fundamental signals. They consistently choose conservative actions in\nthese states, which keeps the market anchored in this region of the state space and yields both high\nimmediate rewards and increasingly strong continuation values. Over iterations, this reinforcement\ndrives the Q-values for this state-action pair to converge to very high levels. See Result 2 in Online\nAppendix 3.1.1 for details.\nCase (ii): High σu and High ξ.\nWe first explain why no AI collusive equilibrium sustained by\nprice-trigger strategies exists when σu is high, even if ξ is large. When σu is high, the state variable\npt becomes very noisy, providing little useful information for the Q-learning algorithms to track.\nConsequently, the algorithms learn to make optimal decisions with minimal reliance on the state\nvariables, effectively behaving as if no state variable is being used. In this scenario, the optimization\nproblem becomes effectively static, and the Q-learning algorithms operate more like bandit algorithms,\nlacking dynamic sophistication. When price is not an informative state variable, the mechanism\nbehind price-trigger strategies becomes ineffective, as the state variable pt is now primarily driven by\nnoise trading flows ut rather than by the trading behavior of informed AI speculators. As a result, no\nAI collusive equilibrium sustained by price-trigger strategies can be achieved by multiple informed\nAI speculators using Q-learning algorithms when σu is high, even if ξ is large. More details can be\nfound in Result 3 of Online Appendix 3.1.2.\nHowever, AI collusion still arises in this environment, but through a different algorithmic mech-\nanism. Specifically, it is sustained by a learning bias that systematically over-prunes aggressive\nstrategies. This bias results from an inherent asymmetry in the way Q-values are updated following\nnoise trading shocks, a generic feature of RL due to its reliance on exploitation.\nWhen noise trading flows move in the same direction as the algorithm’s trade, they tend to cause\nlarge losses for the algorithm. In response, the algorithm sharply lowers the Q-value of the associated\nstrategy, treats it as a “disastrous action,” and avoids selecting it in future iterations, which locks in\nthe downward bias. By contrast, when noise trading flows move in the opposite direction as the\nalgorithm’s trade, the algorithm may record large profits and significantly overestimate the Q-value,\ntreating the strategy as a “fantastic action.” Because exploitation leads to frequent reuse of high\nQ-value strategies, the algorithm continually revisits this action, allowing its Q-value to be gradually\n38\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "lagged fundamentals, algorithms continue to select aggressive actions, which push the market, in",
          "bbox": [
            64.08000183105469,
            52.01670455932617,
            547.9161987304688,
            63.03435516357422
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "the next period, back to states where lagged prices respond strongly to lagged fundamentals. These",
          "bbox": [
            64.08000183105469,
            68.54618835449219,
            547.9193115234375,
            79.4334487915039
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.887259483337402,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "actions result in both low immediate profits and weak continuation values. Consequently, over many\niterations, the Q-values of aggressive trading strategies gradually decline across all states, whether",
          "bbox": [
            64.08000183105469,
            85.02836608886719,
            548.34765625,
            112.32807922363281
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.8214750289917,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "characterized by lagged prices strongly tracking lagged fundamentals or only moderately responding",
          "bbox": [
            64.08000183105469,
            117.91415405273438,
            547.9188232421875,
            128.71360778808594
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "to them, due to persistently poor outcomes in both immediate profits and continuation values.\nLastly, for algorithms to adopt price-trigger strategies, they must eventually learn to assign\nvery high Q-values to conservative trading in states where lagged prices respond only moderately\nto lagged fundamentals. How does this occur? As discussed earlier, over many iterations, the\nQ-values of aggressive strategies in states where lagged prices respond only moderately to lagged\nfundamentals gradually decline to very low levels and eventually fall below those of conservative",
          "bbox": [
            63.775001525878906,
            134.27052307128906,
            548.3510131835938,
            227.3863525390625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "strategies in the same states. Once this shift occurs, the algorithms begin to reinforce the state-action\npair characterized by lagged prices responding only moderately to fundamentals and conservative",
          "bbox": [
            63.75299835205078,
            232.9246826171875,
            547.9254760742188,
            260.24102783203125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.848934173583984,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "trading in response to current fundamental signals. They consistently choose conservative actions in",
          "bbox": [
            64.08000183105469,
            265.7907409667969,
            547.9202880859375,
            276.6451721191406
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.854416847229004,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "these states, which keeps the market anchored in this region of the state space and yields both high",
          "bbox": [
            64.08000183105469,
            282.1865234375,
            547.9204711914062,
            293.09564208984375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "immediate rewards and increasingly strong continuation values. Over iterations, this reinforcement\ndrives the Q-values for this state-action pair to converge to very high levels. See Result 2 in Online",
          "bbox": [
            64.08000183105469,
            298.61761474609375,
            547.9240112304688,
            325.9820251464844
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.91455364227295,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Appendix 3.1.1 for details.",
          "bbox": [
            63.65399932861328,
            331.4925231933594,
            192.14137268066406,
            342.4016418457031
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Case (ii): High σu and High ξ.\nWe first explain why no AI collusive equilibrium sustained by\nprice-trigger strategies exists when σu is high, even if ξ is large. When σu is high, the state variable",
          "bbox": [
            63.75299835205078,
            364.22772216796875,
            548.3440551757812,
            393.55560302734375
          ],
          "font_info": {
            "font": "URWPalladioL-BoldItal",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 22
          }
        },
        {
          "text": "pt becomes very noisy, providing little useful information for the Q-learning algorithms to track.\nConsequently, the algorithms learn to make optimal decisions with minimal reliance on the state",
          "bbox": [
            64.08000183105469,
            397.2364196777344,
            549.833251953125,
            424.8003234863281
          ],
          "font_info": {
            "font": "URWPalladioL-Ital",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "variables, effectively behaving as if no state variable is being used. In this scenario, the optimization",
          "bbox": [
            63.775001525878906,
            430.3150939941406,
            547.920654296875,
            441.1968994140625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.881793022155762,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "problem becomes effectively static, and the Q-learning algorithms operate more like bandit algorithms,\nlacking dynamic sophistication. When price is not an informative state variable, the mechanism",
          "bbox": [
            63.75299835205078,
            446.8101501464844,
            549.2809448242188,
            474.1063232421875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "behind price-trigger strategies becomes ineffective, as the state variable pt is now primarily driven by",
          "bbox": [
            64.08000183105469,
            479.41241455078125,
            548.3502197265625,
            492.11871337890625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.810471534729004,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "noise trading flows ut rather than by the trading behavior of informed AI speculators. As a result, no",
          "bbox": [
            64.08000183105469,
            495.847412109375,
            547.9198608398438,
            508.55059814453125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "AI collusive equilibrium sustained by price-trigger strategies can be achieved by multiple informed\nAI speculators using Q-learning algorithms when σu is high, even if ξ is large. More details can be",
          "bbox": [
            63.65399932861328,
            512.4559326171875,
            547.9209594726562,
            541.4741821289062
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.930895805358887,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "found in Result 3 of Online Appendix 3.1.2.",
          "bbox": [
            64.08000183105469,
            545.3414916992188,
            276.53466796875,
            556.2506103515625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "However, AI collusion still arises in this environment, but through a different algorithmic mech-\nanism. Specifically, it is sustained by a learning bias that systematically over-prunes aggressive",
          "bbox": [
            64.08000183105469,
            561.7697143554688,
            549.7337036132812,
            589.15234375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.920002937316895,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "strategies. This bias results from an inherent asymmetry in the way Q-values are updated following",
          "bbox": [
            64.08000183105469,
            594.6671142578125,
            547.9216918945312,
            605.5488891601562
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.881793022155762,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "noise trading shocks, a generic feature of RL due to its reliance on exploitation.",
          "bbox": [
            64.08000183105469,
            611.08251953125,
            449.40045166015625,
            621.9916381835938
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "When noise trading flows move in the same direction as the algorithm’s trade, they tend to cause",
          "bbox": [
            81.01599884033203,
            627.576416015625,
            547.9171142578125,
            638.4033813476562
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.826972007751465,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "large losses for the algorithm. In response, the algorithm sharply lowers the Q-value of the associated",
          "bbox": [
            64.08000183105469,
            644.0311279296875,
            547.9188842773438,
            654.8306274414062
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "strategy, treats it as a “disastrous action,” and avoids selecting it in future iterations, which locks in\nthe downward bias. By contrast, when noise trading flows move in the opposite direction as the",
          "bbox": [
            64.08000183105469,
            660.3757934570312,
            547.9168090820312,
            687.7623291015625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.925451278686523,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "algorithm’s trade, the algorithm may record large profits and significantly overestimate the Q-value,\ntreating the strategy as a “fantastic action.” Because exploitation leads to frequent reuse of high",
          "bbox": [
            64.08000183105469,
            693.2742309570312,
            549.288330078125,
            720.63330078125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.887259483337402,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Q-value strategies, the algorithm continually revisits this action, allowing its Q-value to be gradually",
          "bbox": [
            64.08000183105469,
            726.1756591796875,
            548.3441162109375,
            737.0191040039062
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.843446731567383,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "38",
          "bbox": [
            300.5450134277344,
            765.1044921875,
            311.4541320800781,
            776.0136108398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        }
      ]
    },
    {
      "page_number": 41,
      "text": "corrected through subsequent updates.\nIn environments where trading outcomes are driven primarily by random noise rather than\ninformed behavior, exploration cannot effectively correct the asymmetry in the learning process\ncaused by the exploitation scheme of RL algorithms. This imbalance between exploration and\nexploitation leads to the premature pruning of aggressive strategies because their higher exposure to\nnoise trading shocks makes them more susceptible to exploitation-driven undervaluation. As a result,\nthe algorithm converges to a biased Q-value system that systematically favors conservative trading.\nSee Result 4 in Online Appendix 3.1.2 for further discussion.\nCase (iii): Low ξ.\nWe now explain why no AI collusive equilibrium sustained by price-trigger\nstrategies can arise when ξ is low, regardless of the level of σu. In this setting, the minimal presence\nof information-insensitive investors forces market makers to prioritize price discovery. As a result,\nAI speculators must trade conservatively to preserve information rents, leading to endogenously\nlow price informativeness. The equilibrium price becomes dominated by noise trading shocks and\nfails to serve as a useful state variable for Q-learning algorithms. This lack of price informativeness\nundermines the sustainability of price-trigger strategies, following the algorithmic mechanism\ndescribed in case (ii). See Result 5 in Online Appendix 3.2 for further details.\nWhy, then, can an AI collusive equilibrium sustained by over-pruning bias still arise under the\nsame low-ξ condition? As discussed above, when ξ is low, the equilibrium price is endogenously\ndominated by noise trading shocks, as in case (ii). Although the underlying reason for low price\ninformativeness differs, the consequence for the RL process is the same: the exploitation-driven\nlearning asymmetry disproportionately penalizes aggressive strategies due to their higher exposure\nto noise trading shocks. See Result 6 in Online Appendix 3.2 for further details.\n5.6\nWinners and Losers: The Role of Information-Insensitive Investors\nWe now examine who gains and who loses from AI collusion, and how this depends on the role\nof information-insensitive investors, captured by ξ, across three distinct trading environments. In\ncase (i), with high ξ and low σu, the AI collusive equilibrium is driven by price-trigger strategies.\nHere, informed AI speculators primarily trade against information-insensitive investors, who absorb\nmost of their order flow. In the simulation with ξ = 500 and σu = 10−1, each informed AI speculator\nearns an average profit of approximately 54, totaling a loss of about 108 for information-insensitive\ninvestors. Noise traders and market makers earn near-zero profits.\nIn case (ii), with high ξ and high σu, the AI collusion is sustained by the over-pruning bias\nmechanism. Here, informed AI speculators earn supra-competitive profits from trading against both\ninformation-insensitive investors and noise traders. In the simulation with ξ = 500 and σu = 102,\neach informed AI speculator earns about 54 on average, derived from average losses of 88 from\ninformation-insensitive investors and 20 from noise traders. Market makers again break even.\nThe contrast between σu = 10−1 and σu = 102, holding ξ = 500 fixed, illustrates the shift in the\nmechanism sustaining AI collusion, from price-trigger strategies to over-pruning bias. To further\nexplore this shift, we conduct additional simulations under an extreme case with σu = 2.5 × 102.\nWhen noise traders submit large orders that generate substantial losses for themselves, information-\ninsensitive investors begin trading more in line with informed AI speculators. In this case, each\n39\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "corrected through subsequent updates.\nIn environments where trading outcomes are driven primarily by random noise rather than\ninformed behavior, exploration cannot effectively correct the asymmetry in the learning process\ncaused by the exploitation scheme of RL algorithms. This imbalance between exploration and",
          "bbox": [
            64.08000183105469,
            52.09455490112305,
            547.9166259765625,
            112.34032440185547
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "exploitation leads to the premature pruning of aggressive strategies because their higher exposure to",
          "bbox": [
            64.08000183105469,
            117.89441680908203,
            547.9158935546875,
            128.7213897705078
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.826972007751465,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "noise trading shocks makes them more susceptible to exploitation-driven undervaluation. As a result,",
          "bbox": [
            64.08000183105469,
            134.34915161132812,
            549.2871704101562,
            145.1486053466797
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "the algorithm converges to a biased Q-value system that systematically favors conservative trading.",
          "bbox": [
            64.08000183105469,
            150.6820831298828,
            549.82470703125,
            161.6238555908203
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.941778182983398,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "See Result 4 in Online Appendix 3.1.2 for further discussion.",
          "bbox": [
            64.08000183105469,
            167.14051818847656,
            359.0401611328125,
            178.0496063232422
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Case (iii): Low ξ.\nWe now explain why no AI collusive equilibrium sustained by price-trigger",
          "bbox": [
            64.08000183105469,
            199.87673950195312,
            548.1408081054688,
            212.0001983642578
          ],
          "font_info": {
            "font": "URWPalladioL-BoldItal",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 22
          }
        },
        {
          "text": "strategies can arise when ξ is low, regardless of the level of σu. In this setting, the minimal presence\nof information-insensitive investors forces market makers to prioritize price discovery. As a result,\nAI speculators must trade conservatively to preserve information rents, leading to endogenously\nlow price informativeness. The equilibrium price becomes dominated by noise trading shocks and",
          "bbox": [
            63.65399932861328,
            216.63954162597656,
            549.2891845703125,
            276.8736267089844
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "fails to serve as a useful state variable for Q-learning algorithms. This lack of price informativeness\nundermines the sustainability of price-trigger strategies, following the algorithmic mechanism",
          "bbox": [
            64.08000183105469,
            282.3638916015625,
            547.9170532226562,
            309.75433349609375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.930895805358887,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "described in case (ii). See Result 5 in Online Appendix 3.2 for further details.\nWhy, then, can an AI collusive equilibrium sustained by over-pruning bias still arise under the\nsame low-ξ condition? As discussed above, when ξ is low, the equilibrium price is endogenously\ndominated by noise trading shocks, as in case (ii). Although the underlying reason for low price\ninformativeness differs, the consequence for the RL process is the same: the exploitation-driven",
          "bbox": [
            64.08000183105469,
            315.2505187988281,
            548.3453979492188,
            391.9303283691406
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "learning asymmetry disproportionately penalizes aggressive strategies due to their higher exposure",
          "bbox": [
            64.08000183105469,
            397.433349609375,
            547.921630859375,
            408.33154296875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.898184776306152,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "to noise trading shocks. See Result 6 in Online Appendix 3.2 for further details.",
          "bbox": [
            64.08000183105469,
            413.8605041503906,
            451.189453125,
            424.7696228027344
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "5.6\nWinners and Losers: The Role of Information-Insensitive Investors",
          "bbox": [
            64.08000183105469,
            446.540771484375,
            459.7373352050781,
            458.4959716796875
          ],
          "font_info": {
            "font": "URWPalladioL-Bold",
            "size": 11.9552001953125,
            "color": 0,
            "flags": 20
          }
        },
        {
          "text": "We now examine who gains and who loses from AI collusion, and how this depends on the role\nof information-insensitive investors, captured by ξ, across three distinct trading environments. In\ncase (i), with high ξ and low σu, the AI collusive equilibrium is driven by price-trigger strategies.",
          "bbox": [
            63.534000396728516,
            471.4396667480469,
            549.830078125,
            516.1831665039062
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Here, informed AI speculators primarily trade against information-insensitive investors, who absorb",
          "bbox": [
            64.08000183105469,
            520.8656616210938,
            547.9171752929688,
            531.714599609375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.848934173583984,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "most of their order flow. In the simulation with ξ = 500 and σu = 10−1, each informed AI speculator",
          "bbox": [
            64.08000183105469,
            534.5228271484375,
            548.1409301757812,
            549.201416015625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.843446731567383,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "earns an average profit of approximately 54, totaling a loss of about 108 for information-insensitive",
          "bbox": [
            64.08000183105469,
            553.6690673828125,
            547.9152221679688,
            564.61083984375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.941778182983398,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "investors. Noise traders and market makers earn near-zero profits.\nIn case (ii), with high ξ and high σu, the AI collusion is sustained by the over-pruning bias",
          "bbox": [
            64.08000183105469,
            570.1275024414062,
            547.9182739257812,
            598.359130859375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "mechanism. Here, informed AI speculators earn supra-competitive profits from trading against both\ninformation-insensitive investors and noise traders. In the simulation with ξ = 500 and σu = 102,\neach informed AI speculator earns about 54 on average, derived from average losses of 88 from",
          "bbox": [
            64.08000183105469,
            603.0416870117188,
            549.2838134765625,
            646.808349609375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.848934173583984,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "information-insensitive investors and 20 from noise traders. Market makers again break even.\nThe contrast between σu = 10−1 and σu = 102, holding ξ = 500 fixed, illustrates the shift in the\nmechanism sustaining AI collusion, from price-trigger strategies to over-pruning bias. To further\nexplore this shift, we conduct additional simulations under an extreme case with σu = 2.5 × 102.",
          "bbox": [
            64.08000183105469,
            652.3035278320312,
            549.8287963867188,
            713.5523681640625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "When noise traders submit large orders that generate substantial losses for themselves, information-\ninsensitive investors begin trading more in line with informed AI speculators. In this case, each",
          "bbox": [
            63.534000396728516,
            718.0562744140625,
            549.7294921875,
            745.4193115234375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.89272403717041,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "39",
          "bbox": [
            300.5450134277344,
            765.1044921875,
            311.4541320800781,
            776.0136108398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        }
      ]
    },
    {
      "page_number": 42,
      "text": "2\n3\n4\n5\n6\n7\n8\n9\n0\n0.2\n0.4\n0.6\n0.8\n1\n2\n3\n4\n5\n6\n7\n8\n9\n1\n1.5\n2\n2.5\n3\n3.5\n2\n3\n4\n5\n6\n7\n8\n9\n0\n2\n4\n6\n8\n10\n2\n3\n4\n5\n6\n7\n8\n9\n0\n0.2\n0.4\n0.6\n0.8\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n0.2\n0.4\n0.6\n0.8\n1\n2\n3\n4\n5\n6\n7\n8\n9\n1\n1.5\n2\n2.5\n3\n3.5\n2\n3\n4\n5\n6\n7\n8\n9\n0\n5\n10\n15\n2\n3\n4\n5\n6\n7\n8\n9\n0\n0.2\n0.4\n0.6\n0.8\n1\nNote: Parameters are set according to the baseline economic environment specified in Section 4.2.\nFigure 7: Implications of the number of informed AI speculators.\ninformed AI speculator earns about 54.5, while information-insensitive investors gain roughly 16,\ntogether extracting approximately 125 in total losses from noise traders. Market makers continue to\nearn near-zero profits.\nNotably, in our model, information-insensitive investors can be interpreted as retail investors\nwho follow technical analysis (see Section 3.1). Our results align with empirical evidence from Chen,\nPeng and Zhou (2024), which shows that AI-driven strategies earn profits primarily by exploiting\nsentiment among retail investors using technical analysis. Their finding that such investors may earn\npositive trading profits in high-noise environments is also consistent with our simulation outcomes.\nIn case (iii), with low ξ, AI collusion sustained by price-trigger strategies does not arise. Instead,\nan AI collusive equilibrium driven by over-pruning bias emerges robustly, similar to case (ii). In\nthis case, informed AI speculators earn supra-competitive profits primarily from trading against\nnoise traders, rather than from exploiting information-insensitive investors. In the simulation with\nξ = 5 and σu = 2, each informed AI speculator earns about 0.54 on average, derived from average\nlosses of 1.08 from noise traders. Market makers again earn near-zero profits. By design, the role of\ninformation-insensitive investors in this environment is negligible.\n6\nComparative Statics of AI Equilibrium\nEffect of the Number of Informed AI Speculators (I).\nFigure 7 shows how the AI equilibrium changes\nas I increases from 2 to 9 in the baseline environment under both low and high noise trading risk\nconditions. Panels A to D focus on the scenario with low noise trading risk (i.e., σu = 10−1), revealing\nthe following patterns as I increases: ∆decreases (for I ≥4), IC/I M and LC/LM both increase,\n40\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "2\n3\n4\n5\n6\n7\n8\n9",
          "bbox": [
            83.03173065185547,
            162.71434020996094,
            178.90467834472656,
            169.5742950439453
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0",
          "bbox": [
            78.75010681152344,
            145.85784912109375,
            82.56423950195312,
            152.71780395507812
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.2",
          "bbox": [
            73.0538558959961,
            131.3059844970703,
            82.58918762207031,
            138.1659393310547
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.4",
          "bbox": [
            73.0538558959961,
            116.75411987304688,
            82.58918762207031,
            123.61407470703125
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.6",
          "bbox": [
            73.0538558959961,
            102.20223999023438,
            82.58918762207031,
            109.06219482421875
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.8",
          "bbox": [
            73.0538558959961,
            87.65057373046875,
            82.58918762207031,
            94.51052856445312
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1",
          "bbox": [
            78.75010681152344,
            73.09869384765625,
            82.56423950195312,
            79.95864868164062
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "2\n3\n4\n5\n6\n7\n8\n9",
          "bbox": [
            204.30673217773438,
            162.71434020996094,
            300.17962646484375,
            169.5742950439453
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1",
          "bbox": [
            200.02511596679688,
            146.37774658203125,
            203.83924865722656,
            153.23770141601562
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1.5",
          "bbox": [
            194.32887268066406,
            130.2668914794922,
            203.86419677734375,
            137.12684631347656
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "2",
          "bbox": [
            200.02511596679688,
            114.15583801269531,
            203.83924865722656,
            121.01579284667969
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "2.5",
          "bbox": [
            194.32887268066406,
            98.04498291015625,
            203.86419677734375,
            104.90493774414062
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "3",
          "bbox": [
            200.02511596679688,
            81.93392944335938,
            203.83924865722656,
            88.79388427734375
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "3.5",
          "bbox": [
            194.32887268066406,
            65.82305908203125,
            203.86419677734375,
            72.68301391601562
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "2\n3\n4\n5\n6\n7\n8\n9\n0",
          "bbox": [
            321.11639404296875,
            156.0439910888672,
            421.27093505859375,
            169.5742950439453
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "2",
          "bbox": [
            321.11639404296875,
            137.99972534179688,
            324.9305419921875,
            144.85968017578125
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "4",
          "bbox": [
            321.11639404296875,
            119.95547485351562,
            324.9305419921875,
            126.8154296875
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "6",
          "bbox": [
            321.11639404296875,
            101.91122436523438,
            324.9305419921875,
            108.77117919921875
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "8",
          "bbox": [
            321.11639404296875,
            83.86695861816406,
            324.9305419921875,
            90.72691345214844
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "10",
          "bbox": [
            317.25762939453125,
            65.82270812988281,
            324.88592529296875,
            72.68266296386719
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "2\n3\n4\n5\n6\n7\n8\n9\n0",
          "bbox": [
            442.391357421875,
            156.0439910888672,
            542.546142578125,
            169.5742950439453
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.2",
          "bbox": [
            436.69512939453125,
            139.64010620117188,
            446.23046875,
            146.50006103515625
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.4",
          "bbox": [
            436.69512939453125,
            123.23623657226562,
            446.23046875,
            130.09619140625
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.6",
          "bbox": [
            436.69512939453125,
            106.83236694335938,
            446.23046875,
            113.69232177734375
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.8",
          "bbox": [
            436.69512939453125,
            90.42863464355469,
            446.23046875,
            97.28858947753906
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1",
          "bbox": [
            442.391357421875,
            74.02476501464844,
            446.20550537109375,
            80.88471984863281
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "2\n3\n4\n5\n6\n7\n8\n9",
          "bbox": [
            83.03173065185547,
            288.2156066894531,
            178.90467834472656,
            295.0755615234375
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0",
          "bbox": [
            78.75010681152344,
            271.3385314941406,
            82.56423950195312,
            278.198486328125
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.2",
          "bbox": [
            73.0538558959961,
            256.75701904296875,
            82.58918762207031,
            263.6169738769531
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.4",
          "bbox": [
            73.0538558959961,
            242.17550659179688,
            82.58918762207031,
            249.03546142578125
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.6",
          "bbox": [
            73.0538558959961,
            227.59417724609375,
            82.58918762207031,
            234.45413208007812
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.8",
          "bbox": [
            73.0538558959961,
            213.01266479492188,
            82.58918762207031,
            219.87261962890625
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1",
          "bbox": [
            78.75010681152344,
            198.43115234375,
            82.56423950195312,
            205.29110717773438
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "2\n3\n4\n5\n6\n7\n8\n9",
          "bbox": [
            204.30673217773438,
            288.2156066894531,
            300.17962646484375,
            295.0755615234375
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1",
          "bbox": [
            200.02511596679688,
            271.8591613769531,
            203.83924865722656,
            278.7191162109375
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1.5",
          "bbox": [
            194.32887268066406,
            255.71539306640625,
            203.86419677734375,
            262.5753479003906
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "2",
          "bbox": [
            200.02511596679688,
            239.57179260253906,
            203.83924865722656,
            246.43174743652344
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "2.5",
          "bbox": [
            194.32887268066406,
            223.42800903320312,
            203.86419677734375,
            230.2879638671875
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "3",
          "bbox": [
            200.02511596679688,
            207.28421020507812,
            203.83924865722656,
            214.1441650390625
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "3.5",
          "bbox": [
            194.32887268066406,
            191.14044189453125,
            203.86419677734375,
            198.00039672851562
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "2\n3\n4\n5\n6\n7\n8\n9\n0",
          "bbox": [
            321.11639404296875,
            281.54547119140625,
            421.27093505859375,
            295.0755615234375
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "5",
          "bbox": [
            321.11639404296875,
            251.41049194335938,
            324.9305419921875,
            258.27044677734375
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "10",
          "bbox": [
            317.25762939453125,
            221.27548217773438,
            324.88592529296875,
            228.13543701171875
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "15",
          "bbox": [
            317.25762939453125,
            191.14047241210938,
            324.88592529296875,
            198.00042724609375
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "2\n3\n4\n5\n6\n7\n8\n9\n0",
          "bbox": [
            442.391357421875,
            281.54547119140625,
            542.546142578125,
            295.0755615234375
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.2",
          "bbox": [
            436.69512939453125,
            265.1082763671875,
            446.23046875,
            271.9682312011719
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.4",
          "bbox": [
            436.69512939453125,
            248.67088317871094,
            446.23046875,
            255.5308380126953
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.6",
          "bbox": [
            436.69512939453125,
            232.2336883544922,
            446.23046875,
            239.09364318847656
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.8",
          "bbox": [
            436.69512939453125,
            215.79647827148438,
            446.23046875,
            222.65643310546875
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1",
          "bbox": [
            442.391357421875,
            199.35910034179688,
            446.20550537109375,
            206.21905517578125
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "Note: Parameters are set according to the baseline economic environment specified in Section 4.2.",
          "bbox": [
            64.08000183105469,
            321.6767272949219,
            454.3155822753906,
            330.64312744140625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 8.966400146484375,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Figure 7: Implications of the number of informed AI speculators.",
          "bbox": [
            147.79100036621094,
            342.26849365234375,
            464.2093811035156,
            353.1776123046875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "informed AI speculator earns about 54.5, while information-insensitive investors gain roughly 16,",
          "bbox": [
            64.08000183105469,
            377.1396484375,
            549.2849731445312,
            388.1573181152344
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "together extracting approximately 125 in total losses from noise traders. Market makers continue to",
          "bbox": [
            64.08000183105469,
            393.6564636230469,
            547.9160766601562,
            404.5600891113281
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.903643608093262,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "earn near-zero profits.\nNotably, in our model, information-insensitive investors can be interpreted as retail investors",
          "bbox": [
            64.08000183105469,
            410.0875244140625,
            547.91650390625,
            437.46234130859375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "who follow technical analysis (see Section 3.1). Our results align with empirical evidence from Chen,\nPeng and Zhou (2024), which shows that AI-driven strategies earn profits primarily by exploiting",
          "bbox": [
            63.62200164794922,
            443.0046081542969,
            549.2872924804688,
            470.33233642578125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.843446731567383,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "sentiment among retail investors using technical analysis. Their finding that such investors may earn",
          "bbox": [
            64.08000183105469,
            475.891357421875,
            547.9182739257812,
            486.7128601074219
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.8214750289917,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "positive trading profits in high-noise environments is also consistent with our simulation outcomes.",
          "bbox": [
            63.75299835205078,
            492.2635192871094,
            549.218994140625,
            503.1726379394531
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "In case (iii), with low ξ, AI collusion sustained by price-trigger strategies does not arise. Instead,\nan AI collusive equilibrium driven by over-pruning bias emerges robustly, similar to case (ii). In\nthis case, informed AI speculators earn supra-competitive profits primarily from trading against\nnoise traders, rather than from exploiting information-insensitive investors. In the simulation with",
          "bbox": [
            64.08000183105469,
            508.7063293457031,
            549.2791137695312,
            568.9295654296875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.898184776306152,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "ξ = 5 and σu = 2, each informed AI speculator earns about 0.54 on average, derived from average",
          "bbox": [
            64.21600341796875,
            573.3780517578125,
            547.924560546875,
            586.3823852539062
          ],
          "font_info": {
            "font": "PazoMath-Italic",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "losses of 1.08 from noise traders. Market makers again earn near-zero profits. By design, the role of",
          "bbox": [
            64.08000183105469,
            590.87353515625,
            547.9204711914062,
            601.7826538085938
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "information-insensitive investors in this environment is negligible.",
          "bbox": [
            64.08000183105469,
            607.3095092773438,
            386.81488037109375,
            618.2186279296875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "6\nComparative Statics of AI Equilibrium",
          "bbox": [
            64.08000183105469,
            644.36376953125,
            341.2773132324219,
            658.7099609375
          ],
          "font_info": {
            "font": "URWPalladioL-Bold",
            "size": 14.346199989318848,
            "color": 0,
            "flags": 20
          }
        },
        {
          "text": "Effect of the Number of Informed AI Speculators (I).\nFigure 7 shows how the AI equilibrium changes\nas I increases from 2 to 9 in the baseline environment under both low and high noise trading risk",
          "bbox": [
            64.08000183105469,
            674.982421875,
            548.2235717773438,
            702.5463256835938
          ],
          "font_info": {
            "font": "URWPalladioL-BoldItal",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 22
          }
        },
        {
          "text": "conditions. Panels A to D focus on the scenario with low noise trading risk (i.e., σu = 10−1), revealing\nthe following patterns as I increases: ∆decreases (for I ≥4), IC/I M and LC/LM both increase,",
          "bbox": [
            64.08000183105469,
            705.306884765625,
            549.2845458984375,
            735.4163208007812
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "40",
          "bbox": [
            300.5450134277344,
            765.1044921875,
            311.4541320800781,
            776.0136108398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        }
      ]
    },
    {
      "page_number": 43,
      "text": "0.05 0.2 0.35 0.5 0.65 0.8 0.95\n0\n0.2\n0.4\n0.6\n0.8\n1\n0.05 0.2 0.35 0.5 0.65 0.8 0.95\n1\n1.2\n1.4\n1.6\n1.8\n0.05 0.2 0.35 0.5 0.65 0.8 0.95\n1\n1.2\n1.4\n1.6\n1.8\n2\n0.05 0.2 0.35 0.5 0.65 0.8 0.95\n0.7\n0.8\n0.9\n1\n0.05 0.2 0.35 0.5 0.65 0.8 0.95\n0\n0.2\n0.4\n0.6\n0.8\n1\n0.05 0.2 0.35 0.5 0.65 0.8 0.95\n1\n1.2\n1.4\n1.6\n1.8\n0.05 0.2 0.35 0.5 0.65 0.8 0.95\n1\n1.2\n1.4\n1.6\n1.8\n2\n0.05 0.2 0.35 0.5 0.65 0.8 0.95\n0.7\n0.8\n0.9\n1\nNote: Parameters are set according to the baseline economic environment specified in Section 4.2.\nFigure 8: Implications of the subjective discount factor.\nwhile E C decreases. These findings are consistent with the theoretical results in Proposition 3.4 for\ncollusive Nash equilibrium sustained by price-trigger strategies.\nFor comparisons, in panels E to H, we focus on the environment with high noise trading risk (i.e.,\nσu = 102). In this environment, informed AI speculators achieve supra-competitive profits due to\nAI collusion through over-pruning bias in learning. These panels reveal the following patterns as I\nincreases: ∆decreases, IC/I M and LC/LM both increase, while E C decreases. These findings are\nconsistent with the theoretical results in Proposition 3.4 for collusive experience-based equilibrium\nsustained by over-perceived aversion against noise trading risk.\nEffect of Subjective Discount Factor (ρ).\nFigure 8 illustrates how the AI equilibrium changes as\nρ increases from 0.05 to 0.95 in the baseline environment under both low and high noise trading\nrisk conditions. Panels A to D focus on the low noise trading risk scenario (i.e., σu = 10−1) and\nreveal the following patterns as ρ increases: ∆rises, IC/I M and LC/LM both decline, while E C\nincreases. These findings are consistent with the theoretical results in Proposition 3.4 for collusive\nNash equilibrium sustained by price-trigger strategies and, more broadly, with the Folk theorem for\nrepeated games.\nIn sharp contrast, Panels E to H show that ρ has little effects on the AI equilibrium when noise\ntrading risk is high (i.e., σu = 102). The insignificant impact of ρ in this environment is due to the\nalgorithmic property that ρ does not meaningfully affect the magnitude of over-pruning learning\nbiases. These findings are consistent with the theoretical results in Proposition 3.4 for collusive\nexperience-based equilibrium sustained by over-perceived aversion against noise trading risk.\n41\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "0.05 0.2 0.35 0.5 0.65 0.8 0.95",
          "bbox": [
            78.25423431396484,
            162.71434020996094,
            181.82510375976562,
            169.5742950439453
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0",
          "bbox": [
            78.75010681152344,
            145.85784912109375,
            82.56423950195312,
            152.71780395507812
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.2",
          "bbox": [
            73.0538558959961,
            131.3059844970703,
            82.58918762207031,
            138.1659393310547
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.4",
          "bbox": [
            73.0538558959961,
            116.75411987304688,
            82.58918762207031,
            123.61407470703125
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.6",
          "bbox": [
            73.0538558959961,
            102.20223999023438,
            82.58918762207031,
            109.06219482421875
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.8",
          "bbox": [
            73.0538558959961,
            87.65057373046875,
            82.58918762207031,
            94.51052856445312
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1",
          "bbox": [
            78.75010681152344,
            73.09869384765625,
            82.56423950195312,
            79.95864868164062
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.05 0.2 0.35 0.5 0.65 0.8 0.95",
          "bbox": [
            199.5292205810547,
            162.71434020996094,
            303.10009765625,
            169.5742950439453
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1",
          "bbox": [
            200.02511596679688,
            144.8827667236328,
            203.83924865722656,
            151.7427215576172
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1.2",
          "bbox": [
            194.32887268066406,
            126.28054809570312,
            203.86419677734375,
            133.1405029296875
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1.4",
          "bbox": [
            194.32887268066406,
            107.67814636230469,
            203.86419677734375,
            114.53810119628906
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1.6",
          "bbox": [
            194.32887268066406,
            89.07572937011719,
            203.86419677734375,
            95.93568420410156
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1.8",
          "bbox": [
            194.32887268066406,
            70.47352600097656,
            203.86419677734375,
            77.33348083496094
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.05 0.2 0.35 0.5 0.65 0.8 0.95",
          "bbox": [
            320.6204833984375,
            162.71434020996094,
            424.19140625,
            169.5742950439453
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1",
          "bbox": [
            321.11639404296875,
            145.21791076660156,
            324.9305419921875,
            152.07786560058594
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1.2",
          "bbox": [
            315.42010498046875,
            130.78240966796875,
            324.9554443359375,
            137.64236450195312
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1.4",
          "bbox": [
            315.42010498046875,
            116.34710693359375,
            324.9554443359375,
            123.20706176757812
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1.6",
          "bbox": [
            315.42010498046875,
            101.91160583496094,
            324.9554443359375,
            108.77156066894531
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1.8",
          "bbox": [
            315.42010498046875,
            87.47610473632812,
            324.9554443359375,
            94.3360595703125
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "2",
          "bbox": [
            321.11639404296875,
            73.04080200195312,
            324.9305419921875,
            79.9007568359375
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.05 0.2 0.35 0.5 0.65 0.8 0.95",
          "bbox": [
            441.8955078125,
            162.71434020996094,
            545.4662475585938,
            169.5742950439453
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.7",
          "bbox": [
            436.69512939453125,
            137.1608428955078,
            446.23046875,
            144.0207977294922
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.8",
          "bbox": [
            436.69512939453125,
            116.17930603027344,
            446.23046875,
            123.03926086425781
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.9",
          "bbox": [
            436.69512939453125,
            95.19755554199219,
            446.23046875,
            102.05751037597656
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1",
          "bbox": [
            442.391357421875,
            74.21580505371094,
            446.20550537109375,
            81.07575988769531
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.05 0.2 0.35 0.5 0.65 0.8 0.95",
          "bbox": [
            78.25423431396484,
            288.2156066894531,
            181.82510375976562,
            295.0755615234375
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0",
          "bbox": [
            78.75010681152344,
            271.3385314941406,
            82.56423950195312,
            278.198486328125
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.2",
          "bbox": [
            73.0538558959961,
            256.75701904296875,
            82.58918762207031,
            263.6169738769531
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.4",
          "bbox": [
            73.0538558959961,
            242.17550659179688,
            82.58918762207031,
            249.03546142578125
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.6",
          "bbox": [
            73.0538558959961,
            227.59417724609375,
            82.58918762207031,
            234.45413208007812
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.8",
          "bbox": [
            73.0538558959961,
            213.01266479492188,
            82.58918762207031,
            219.87261962890625
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1",
          "bbox": [
            78.75010681152344,
            198.43115234375,
            82.56423950195312,
            205.29110717773438
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.05 0.2 0.35 0.5 0.65 0.8 0.95",
          "bbox": [
            199.5292205810547,
            288.2156066894531,
            303.10009765625,
            295.0755615234375
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1",
          "bbox": [
            200.02511596679688,
            270.3614196777344,
            203.83924865722656,
            277.22137451171875
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1.2",
          "bbox": [
            194.32887268066406,
            251.72113037109375,
            203.86419677734375,
            258.5810852050781
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1.4",
          "bbox": [
            194.32887268066406,
            233.0810546875,
            203.86419677734375,
            239.94100952148438
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1.6",
          "bbox": [
            194.32887268066406,
            214.44076538085938,
            203.86419677734375,
            221.30072021484375
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1.8",
          "bbox": [
            194.32887268066406,
            195.80047607421875,
            203.86419677734375,
            202.66043090820312
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.05 0.2 0.35 0.5 0.65 0.8 0.95",
          "bbox": [
            320.6204833984375,
            288.2156066894531,
            424.19140625,
            295.0755615234375
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1",
          "bbox": [
            321.11639404296875,
            269.85516357421875,
            324.9305419921875,
            276.7151184082031
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1.2",
          "bbox": [
            315.42010498046875,
            254.26815795898438,
            324.9554443359375,
            261.12811279296875
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1.4",
          "bbox": [
            315.42010498046875,
            238.68101501464844,
            324.9554443359375,
            245.5409698486328
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1.6",
          "bbox": [
            315.42010498046875,
            223.09402465820312,
            324.9554443359375,
            229.9539794921875
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1.8",
          "bbox": [
            315.42010498046875,
            207.50686645507812,
            324.9554443359375,
            214.3668212890625
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "2",
          "bbox": [
            321.11639404296875,
            191.9198760986328,
            324.9305419921875,
            198.7798309326172
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.05 0.2 0.35 0.5 0.65 0.8 0.95",
          "bbox": [
            441.8955078125,
            288.2156066894531,
            545.4662475585938,
            295.0755615234375
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.7",
          "bbox": [
            436.69512939453125,
            262.6234436035156,
            446.23046875,
            269.4833984375
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.8",
          "bbox": [
            436.69512939453125,
            241.5989990234375,
            446.23046875,
            248.45895385742188
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "0.9",
          "bbox": [
            436.69512939453125,
            220.57476806640625,
            446.23046875,
            227.43472290039062
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "1",
          "bbox": [
            442.391357421875,
            199.55035400390625,
            446.20550537109375,
            206.41030883789062
          ],
          "font_info": {
            "font": "Helvetica",
            "size": 6.859951019287109,
            "color": 2500134,
            "flags": 4
          }
        },
        {
          "text": "Note: Parameters are set according to the baseline economic environment specified in Section 4.2.",
          "bbox": [
            64.08000183105469,
            321.6767272949219,
            454.3155822753906,
            330.64312744140625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 8.966400146484375,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Figure 8: Implications of the subjective discount factor.",
          "bbox": [
            172.81700134277344,
            342.26849365234375,
            439.1844787597656,
            353.1776123046875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "while E C decreases. These findings are consistent with the theoretical results in Proposition 3.4 for",
          "bbox": [
            63.62200164794922,
            373.2068176269531,
            548.1337280273438,
            388.1466064453125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.979779243469238,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "collusive Nash equilibrium sustained by price-trigger strategies.",
          "bbox": [
            64.08000183105469,
            393.65252685546875,
            375.2511291503906,
            404.5616455078125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "For comparisons, in panels E to H, we focus on the environment with high noise trading risk (i.e.,",
          "bbox": [
            81.01599884033203,
            410.15826416015625,
            549.2801513671875,
            420.96875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.810471534729004,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "σu = 102). In this environment, informed AI speculators achieve supra-competitive profits due to\nAI collusion through over-pruning bias in learning. These panels reveal the following patterns as I\nincreases: ∆decreases, IC/I M and LC/LM both increase, while E C decreases. These findings are\nconsistent with the theoretical results in Proposition 3.4 for collusive experience-based equilibrium",
          "bbox": [
            63.65399932861328,
            424.67022705078125,
            547.9219970703125,
            486.7530212402344
          ],
          "font_info": {
            "font": "PazoMath-Italic",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "sustained by over-perceived aversion against noise trading risk.",
          "bbox": [
            64.08000183105469,
            492.2635192871094,
            372.3712463378906,
            503.1726379394531
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Effect of Subjective Discount Factor (ρ).\nFigure 8 illustrates how the AI equilibrium changes as",
          "bbox": [
            64.08000183105469,
            524.998779296875,
            547.921142578125,
            537.1221923828125
          ],
          "font_info": {
            "font": "URWPalladioL-BoldItal",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 22
          }
        },
        {
          "text": "ρ increases from 0.05 to 0.95 in the baseline environment under both low and high noise trading\nrisk conditions. Panels A to D focus on the low noise trading risk scenario (i.e., σu = 10−1) and\nreveal the following patterns as ρ increases: ∆rises, IC/I M and LC/LM both decline, while E C",
          "bbox": [
            64.08000183105469,
            541.6837158203125,
            547.9232788085938,
            586.4271850585938
          ],
          "font_info": {
            "font": "PazoMath-Italic",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 6
          }
        },
        {
          "text": "increases. These findings are consistent with the theoretical results in Proposition 3.4 for collusive",
          "bbox": [
            64.08000183105469,
            590.9925537109375,
            547.920166015625,
            602.0048217773438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 11.012248992919922,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Nash equilibrium sustained by price-trigger strategies and, more broadly, with the Folk theorem for",
          "bbox": [
            64.08000183105469,
            607.5220947265625,
            548.1387939453125,
            618.4038696289062
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.881793022155762,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "repeated games.\nIn sharp contrast, Panels E to H show that ρ has little effects on the AI equilibrium when noise\ntrading risk is high (i.e., σu = 102). The insignificant impact of ρ in this environment is due to the\nalgorithmic property that ρ does not meaningfully affect the magnitude of over-pruning learning\nbiases. These findings are consistent with the theoretical results in Proposition 3.4 for collusive",
          "bbox": [
            64.08000183105469,
            623.9375,
            547.9252319335938,
            700.6173095703125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "experience-based equilibrium sustained by over-perceived aversion against noise trading risk.",
          "bbox": [
            64.08000183105469,
            706.1124877929688,
            519.2840576171875,
            717.0216064453125
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "41",
          "bbox": [
            300.54498291015625,
            765.1044921875,
            311.4541015625,
            776.0136108398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        }
      ]
    },
    {
      "page_number": 44,
      "text": "7\nConclusions\nThis paper shows that AI collusion in securities trading can robustly emerge through two distinct\nalgorithmic mechanisms: one based on price-trigger strategies, and the other driven by over-pruning\nbias in learning. We characterize the conditions under which each mechanism prevails and show that\nboth correspond to established game-theoretic equilibrium concepts. This highlights a fundamental\ninsight about AI: algorithms relying solely on pattern recognition can exhibit behavior that closely\nresembles logical and strategic reasoning.\nFinancial markets differ from product markets in their role as platforms for information aggrega-\ntion and price discovery, with market makers playing a central role. The over-pruning bias identified\nin this paper is not the result of specific, nonstandard algorithmic assumptions or limitations, but a\ngeneric feature of RL that persists even in sophisticated settings.\nThese findings raise new and pressing policy and regulatory challenges.\nWhile restricting\nalgorithmic complexity or memory capacity may help deter price-trigger AI collusion, such measures\ncan inadvertently exacerbate over-pruning bias by amplifying distorted learning dynamics that\nprematurely eliminate aggressive yet efficient strategies from the set of potentially optimal options.\nAs a result, well-intentioned constraints may unintentionally undermine market efficiency. Designing\neffective guardrails for AI in financial markets requires a deep and rigorous understanding of how\nalgorithmic learning dynamics interact with the structure of trading environments to govern machine\nbehavior and shape the resulting AI-driven equilibrium.\nThis study serves as a proof of concept for analyzing AI-driven manipulation risks in financial\nmarkets and opens the door to a broader research agenda. Future work should extend this qualitative\nframework into a full-scale, data-driven quantitative model, incorporating estimated synthetic trading\nenvironments and state-of-the-art RL strengthened by deep learning techniques. Such developments\nwould enable quantitative assessments of AI’s impact on market efficiency. In parallel, extending\nthe framework to incorporate bubbles and crashes would offer valuable insights into the role of\nAI-powered trading in amplifying or dampening market instability.\nReferences\nAbada, Ibrahim, and Xavier Lambin. 2023. “Artificial Intelligence: Can Seemingly Collusive Outcomes Be Avoided?”\nManagement Science, 69(9): 5042–5065.\nAbreu, Dilip, David Pearce, and Ennio Stacchetti. 1986. “Optimal Cartel Equilibria with Imperfect Monitoring.” Journal of\nEconomic Theory, 39(1): 251–269.\nAbreu, Dilip, Paul Milgrom, and David Pearce. 1991. “Information and Timing in Repeated Partnerships.” Econometrica,\n59(6): 1713–1733.\nAsker, John, Chaim Fershtman, and Ariel Pakes. 2022. “Artificial Intelligence, Algorithm Design, and Pricing.” AEA Papers\nand Proceedings, 112: 452–56.\nAsker, John, Chaim Fershtman, and Ariel Pakes. 2024. “The Impact of Artificial Intelligence Design on Pricing.” Journal of\nEconomics & Management Strategy, 33(2): 276–304.\nBanchio, Martino, and Giacomo Mantegazza. 2024. “Artificial Intelligence and Spontaneous Collusion.” Working papers.\nBattigalli, Pierpaolo, Simone Cerreia-Vioglio, Fabio Maccheroni, and Massimo Marinacci. 2015. “Self-Confirming\nEquilibrium and Model Uncertainty.” American Economic Review, 105(2): 646–77.\nBellman, Richard Ernest. 1954. The Theory of Dynamic Programming. Santa Monica, CA:RAND Corporation.\nBryzgalova, Svetlana, Anna Pavlova, and Taisiya Sikorskaya. 2025. “Strategic Arbitrage in Segmented Markets.” Journal of\nFinancial Economics, 166(104008).\nCalvano, Emilio, Giacomo Calzolari, Vincenzo Denicoló, and Sergio Pastorello. 2020. “Artificial Intelligence, Algorithmic\nPricing, and Collusion.” American Economic Review, 110(10): 3267–3297.\nCalvano, Emilio, Giacomo Calzolari, Vincenzo Denicoló, and Sergio Pastorello. 2021. “Algorithmic Collusion with\nImperfect Monitoring.” International Journal of Industrial Organization, 79(C).\n42\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "7\nConclusions",
          "bbox": [
            64.08000183105469,
            49.489784240722656,
            166.87054443359375,
            63.83598709106445
          ],
          "font_info": {
            "font": "URWPalladioL-Bold",
            "size": 14.346199989318848,
            "color": 0,
            "flags": 20
          }
        },
        {
          "text": "This paper shows that AI collusion in securities trading can robustly emerge through two distinct",
          "bbox": [
            63.742000579833984,
            80.21965026855469,
            547.9232177734375,
            91.23729705810547
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 11.017650604248047,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "algorithmic mechanisms: one based on price-trigger strategies, and the other driven by over-pruning",
          "bbox": [
            64.08000183105469,
            96.78751373291016,
            547.92333984375,
            107.61997985839844
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.832467079162598,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "bias in learning. We characterize the conditions under which each mechanism prevails and show that",
          "bbox": [
            64.08000183105469,
            113.24618530273438,
            547.9188232421875,
            124.04563903808594
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "both correspond to established game-theoretic equilibrium concepts. This highlights a fundamental\ninsight about AI: algorithms relying solely on pattern recognition can exhibit behavior that closely",
          "bbox": [
            64.08000183105469,
            129.60353088378906,
            548.3449096679688,
            156.96914672851562
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "resembles logical and strategic reasoning.",
          "bbox": [
            64.08000183105469,
            162.47352600097656,
            266.1055603027344,
            173.3826141357422
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "Financial markets differ from product markets in their role as platforms for information aggrega-",
          "bbox": [
            81.01599884033203,
            178.94773864746094,
            549.736328125,
            189.80215454101562
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.854416847229004,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "tion and price discovery, with market makers playing a central role. The over-pruning bias identified",
          "bbox": [
            64.08000183105469,
            195.4024200439453,
            547.916015625,
            206.22938537597656
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.826972007751465,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "in this paper is not the result of specific, nonstandard algorithmic assumptions or limitations, but a",
          "bbox": [
            64.08000183105469,
            211.76287841796875,
            547.9171752929688,
            222.6937713623047
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.930895805358887,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "generic feature of RL that persists even in sophisticated settings.\nThese findings raise new and pressing policy and regulatory challenges.\nWhile restricting",
          "bbox": [
            64.08000183105469,
            228.21351623535156,
            547.9166259765625,
            255.58831787109375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "algorithmic complexity or memory capacity may help deter price-trigger AI collusion, such measures\ncan inadvertently exacerbate over-pruning bias by amplifying distorted learning dynamics that",
          "bbox": [
            64.08000183105469,
            261.1631774902344,
            547.9187622070312,
            288.4593200683594
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "prematurely eliminate aggressive yet efficient strategies from the set of potentially optimal options.",
          "bbox": [
            63.75299835205078,
            293.9233093261719,
            549.8258666992188,
            304.8759460449219
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.952649116516113,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "As a result, well-intentioned constraints may unintentionally undermine market efficiency. Designing\neffective guardrails for AI in financial markets requires a deep and rigorous understanding of how",
          "bbox": [
            63.65399932861328,
            310.4681701660156,
            548.3736572265625,
            337.7490234375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "algorithmic learning dynamics interact with the structure of trading environments to govern machine",
          "bbox": [
            64.08000183105469,
            343.3381652832031,
            547.9188232421875,
            354.13763427734375
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "behavior and shape the resulting AI-driven equilibrium.\nThis study serves as a proof of concept for analyzing AI-driven manipulation risks in financial",
          "bbox": [
            64.08000183105469,
            359.69451904296875,
            547.9229736328125,
            387.0672912597656
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "markets and opens the door to a broader research agenda. Future work should extend this qualitative",
          "bbox": [
            64.08000183105469,
            392.6441650390625,
            547.9188842773438,
            403.443603515625
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "framework into a full-scale, data-driven quantitative model, incorporating estimated synthetic trading",
          "bbox": [
            64.08000183105469,
            409.07916259765625,
            547.9188232421875,
            419.87860107421875
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.799457550048828,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "environments and state-of-the-art RL strengthened by deep learning techniques. Such developments\nwould enable quantitative assessments of AI’s impact on market efficiency. In parallel, extending\nthe framework to incorporate bubbles and crashes would offer valuable insights into the role of",
          "bbox": [
            63.62200164794922,
            425.4747314453125,
            547.9256591796875,
            469.2453308105469
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.854416847229004,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "AI-powered trading in amplifying or dampening market instability.",
          "bbox": [
            63.65399932861328,
            474.7405090332031,
            392.1161193847656,
            485.6496276855469
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        },
        {
          "text": "References",
          "bbox": [
            64.08000183105469,
            510.7507019042969,
            135.7966766357422,
            525.096923828125
          ],
          "font_info": {
            "font": "URWPalladioL-Bold",
            "size": 14.346199989318848,
            "color": 0,
            "flags": 20
          }
        },
        {
          "text": "Abada, Ibrahim, and Xavier Lambin. 2023. “Artificial Intelligence: Can Seemingly Collusive Outcomes Be Avoided?”\nManagement Science, 69(9): 5042–5065.\nAbreu, Dilip, David Pearce, and Ennio Stacchetti. 1986. “Optimal Cartel Equilibria with Imperfect Monitoring.” Journal of\nEconomic Theory, 39(1): 251–269.\nAbreu, Dilip, Paul Milgrom, and David Pearce. 1991. “Information and Timing in Repeated Partnerships.” Econometrica,\n59(6): 1713–1733.\nAsker, John, Chaim Fershtman, and Ariel Pakes. 2022. “Artificial Intelligence, Algorithm Design, and Pricing.” AEA Papers\nand Proceedings, 112: 452–56.\nAsker, John, Chaim Fershtman, and Ariel Pakes. 2024. “The Impact of Artificial Intelligence Design on Pricing.” Journal of\nEconomics & Management Strategy, 33(2): 276–304.\nBanchio, Martino, and Giacomo Mantegazza. 2024. “Artificial Intelligence and Spontaneous Collusion.” Working papers.\nBattigalli, Pierpaolo, Simone Cerreia-Vioglio, Fabio Maccheroni, and Massimo Marinacci. 2015. “Self-Confirming\nEquilibrium and Model Uncertainty.” American Economic Review, 105(2): 646–77.\nBellman, Richard Ernest. 1954. The Theory of Dynamic Programming. Santa Monica, CA:RAND Corporation.\nBryzgalova, Svetlana, Anna Pavlova, and Taisiya Sikorskaya. 2025. “Strategic Arbitrage in Segmented Markets.” Journal of\nFinancial Economics, 166(104008).\nCalvano, Emilio, Giacomo Calzolari, Vincenzo Denicoló, and Sergio Pastorello. 2020. “Artificial Intelligence, Algorithmic\nPricing, and Collusion.” American Economic Review, 110(10): 3267–3297.\nCalvano, Emilio, Giacomo Calzolari, Vincenzo Denicoló, and Sergio Pastorello. 2021. “Algorithmic Collusion with\nImperfect Monitoring.” International Journal of Industrial Organization, 79(C).",
          "bbox": [
            64.07998657226562,
            531.91748046875,
            549.7152709960938,
            733.358154296875
          ],
          "font_info": {
            "font": "URWPalladioL-Bold",
            "size": 9.055620193481445,
            "color": 0,
            "flags": 20
          }
        },
        {
          "text": "42",
          "bbox": [
            300.54498291015625,
            765.1044921875,
            311.4541015625,
            776.0136108398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        }
      ]
    },
    {
      "page_number": 45,
      "text": "Cao, Sean, Wei Jiang, Junbo Wang, and Baozhong Yang. 2024. “From Man vs. Machine to Man + Machine: The Art and\nAI of Stock Analyses.” Journal of Financial Economics, 160(103910).\nCarlin, Bruce Ian, Miguel Sousa Lobo, and S Viswanathan. 2007. “Episodic Liquidity Crises: Cooperative and Predatory\nTrading.” Journal of Finance, 62(5): 2235–2274.\nCartea, Álvaro, Patrick Chang, José Penalva, and Harrison Waldon. 2022a. “The Algorithmic Learning Equations: Evolving\nStrategies in Dynamic Games.” Working papers.\nCartea, Álvaro, Patrick Chang, Mateusz Mroczka, and Roel Oomen. 2022b. “AI-Driven Liquidity Provision in OTC\nFinancial Markets.” Quantitative Finance, 22(12): 2171–2204.\nCharness, Gary, Francesco Feri, Miguel A. Meléndez-Jiménez, and Matthias Sutter. 2014. “Experimental Games on\nNetworks: Underpinnings of Behavior and Equilibrium Selection.” Econometrica, 82(5): 1615–1670.\nChen, Hsuan-Chi, and Jay R. Ritter. 2000. “The Seven Percent Solution.” Journal of Finance, 55(3): 1105–1131.\nChen, Hui, Winston Wei Dou, Hongye Guo, and Yan Ji. 2023. “Feedback and Contagion through Distressed Competition.”\nJournal of Finance, forthcoming.\nChen, Hui, Winston Wei Dou, Hongye Guo, and Yan Ji. 2024. “Industry Distress Anomaly.” Working papers.\nChen, Hui, Yuhan Cheng, Yanchu Liu, and Ke Tang. 2025. “Teaching Economics to the Machines.” Working papers.\nChen, Shuaiyu, Lin Peng, and Dexin Zhou. 2024. “Wisdom or Whims? Decoding Investor Trading Strategies with Large\nLanguage Models.” Working papers.\nChen, Yifei, Bryan T. Kelly, and Dacheng Xiu. 2024. “Expected Returns and Large Language Models.” Working papers.\nCho, In-Koo, and Thomas J. Sargent. 2008. “Self-Confirming Equilibria.” 407–408. Palgrave Macmillan.\nCho, Inkoo, Noah Williams, and Thomas Sargent. 2002. “Escaping Nash Inflation.” Review of Economic Studies, 69(1): 1–40.\nChristie, William G, and Paul H Schultz. 1994. “Why Do NASDAQ Market Makers Avoid Odd-Eighth Quotes?” Journal of\nFinance, 49(5): 1813–1840.\nChristie, William G., and Paul H. Schultz. 1995. “Policy Watch: Did Nasdaq Market Makers Implicitly Collude?” Journal\nof Economic Perspectives, 9(3): 199–208.\nChristie, William G, Jeffrey H Harris, and Paul H Schultz. 1994. “Why Did NASDAQ Market Makers Stop Avoiding\nOdd-Eighth Quotes?” Journal of Finance, 49(5): 1841–1860.\nColliard, Jean-Edouard, Thierry Foucault, and Stefano Lovo. 2025. “Algorithmic Pricing and Liquidity in Securities\nMarkets.” Working papers.\nCong, Lin, and Zhiguo He. 2019. “Blockchain Disruption and Smart Contracts.” Review of Financial Studies, 32(5): 1754–1797.\nCooper, David J., and Kai-Uwe Kühn. 2014. “Communication, Renegotiation, and the Scope for Collusion.” American\nEconomic Journal: Microeconomics, 6(2): 247–278.\nDolgopolov, Arthur. 2024. “Reinforcement Learning in a Prisoner’s Dilemma.” Games and Economic Behavior, 144(C): 84–103.\nDou, Winston Wei, Wei Wang, and Wenyu Wang. 2023. “The Cost of Intermediary Market Power for Distressed Borrowers.”\nWorking papers.\nDou, Winston Wei, Xiang Fang, Andrew W. Lo, and Harald Uhlig. 2023. “Macro-Finance Models with Nonlinear\nDynamics.” Annual Review of Financial Economics, 15: 407–432.\nDou, Winston Wei, Yan Ji, and Wei Wu. 2021a. “Competition, Profitability, and Discount Rates.” Journal of Financial\nEconomcis, 140(2): 582–620.\nDou, Winston Wei, Yan Ji, and Wei Wu. 2021b. “The Oligopoly Lucas Tree.” Review of Financial Studies, 35(8): 3867–3921.\nDuarte, Victor, Diogo Duarte, and Dejanir H Silva. 2024. “Machine Learning for Continuous-Time Finance.” Review of\nFinancial Studies, 37(11): 3217–3271.\nDugast, Jérôme, and Thierry Foucault. 2018. “Data Abundance and Asset Price Informativeness.” Journal of Financial\nEconomics, 130(2): 367–391.\nDugast, Jérôme, and Thierry Foucault. 2024. “Equilibrium Data Mining and Data Abundance.” Journal of Finance, 80(1): 211–\n258.\nDutta, Prajit K, and Ananth Madhavan. 1997. “Competition and Collusion in Dealer Markets.” Journal of Finance, 52(1): 245–\n276.\nFarboodi, Maryam, and Laura Veldkamp. 2020. “Long-Run Growth of Financial Data Technology.” American Economic\nReview, 110(8): 2485–2523.\nFarboodi, Maryam, and Laura Veldkamp. 2023. “Data and Markets.” Annual Review of Economics, 15: 23–40.\nFershtman, Chaim, and Ariel Pakes. 2012. “Dynamic Games with Asymmetric Information: A Framework for Empirical\nWork.” Quarterly Journal of Economics, 127(4): 1611–1661.\nFonseca, Miguel A., and Hans-Theo Normann. 2012. “Explicit vs. Tacit Collusion: The Impact of Communication in\nOligopoly Experiments.” European Economic Review, 56(8): 1759–1772.\nFudenberg, Drew, and David Levine. 1993. “Self-Confirming Equilibrium.” Econometrica, 61(3): 523–45.\nFudenberg, Drew, and David M. Kreps. 1988. “A Theory of Learning, Experimentation, and Equilibrium in Games.”\nWorking papers.\nFudenberg, Drew, and David M. Kreps. 1995. “Learning in Extensive-Form Games I. Self-Confirming Equilibria.” Games\nand Economic Behavior, 8(1): 20–55.\nFudenberg, Drew, and Eric Maskin. 1986. “The Folk Theorem in Repeated Games with Discounting or with Incomplete\nInformation.” Econometrica, 54(3): 533–54.\nGao, Zhenyu, Wei Xiong, and Jian Yuan. 2024. “Structured Beliefs and Fund Performance: An LLM-Based Approach.”\nWorking papers.\nGenesove, David, and Wallace P. Mullin. 2001. “Rules, Communication, and Collusion: Narrative Evidence from the Sugar\nInstitute Case.” American Economic Review, 91(3): 379–398.\nGoldstein, Itay, Chester S Spatt, and Mao Ye. 2021. “Big Data in Finance.” Review of Financial Studies, 34(7): 3213–3225.\nGoldstein, Itay, Emre Ozdenoren, and Kathy Yuan. 2013. “Trading Frenzies and Their Impact on Real Investment.” Journal\nof Financial Economics, 109(2): 566–582.\n43\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "Cao, Sean, Wei Jiang, Junbo Wang, and Baozhong Yang. 2024. “From Man vs. Machine to Man + Machine: The Art and\nAI of Stock Analyses.” Journal of Financial Economics, 160(103910).\nCarlin, Bruce Ian, Miguel Sousa Lobo, and S Viswanathan. 2007. “Episodic Liquidity Crises: Cooperative and Predatory\nTrading.” Journal of Finance, 62(5): 2235–2274.\nCartea, Álvaro, Patrick Chang, José Penalva, and Harrison Waldon. 2022a. “The Algorithmic Learning Equations: Evolving\nStrategies in Dynamic Games.” Working papers.\nCartea, Álvaro, Patrick Chang, Mateusz Mroczka, and Roel Oomen. 2022b. “AI-Driven Liquidity Provision in OTC\nFinancial Markets.” Quantitative Finance, 22(12): 2171–2204.\nCharness, Gary, Francesco Feri, Miguel A. Meléndez-Jiménez, and Matthias Sutter. 2014. “Experimental Games on\nNetworks: Underpinnings of Behavior and Equilibrium Selection.” Econometrica, 82(5): 1615–1670.\nChen, Hsuan-Chi, and Jay R. Ritter. 2000. “The Seven Percent Solution.” Journal of Finance, 55(3): 1105–1131.\nChen, Hui, Winston Wei Dou, Hongye Guo, and Yan Ji. 2023. “Feedback and Contagion through Distressed Competition.”\nJournal of Finance, forthcoming.\nChen, Hui, Winston Wei Dou, Hongye Guo, and Yan Ji. 2024. “Industry Distress Anomaly.” Working papers.\nChen, Hui, Yuhan Cheng, Yanchu Liu, and Ke Tang. 2025. “Teaching Economics to the Machines.” Working papers.\nChen, Shuaiyu, Lin Peng, and Dexin Zhou. 2024. “Wisdom or Whims? Decoding Investor Trading Strategies with Large\nLanguage Models.” Working papers.\nChen, Yifei, Bryan T. Kelly, and Dacheng Xiu. 2024. “Expected Returns and Large Language Models.” Working papers.\nCho, In-Koo, and Thomas J. Sargent. 2008. “Self-Confirming Equilibria.” 407–408. Palgrave Macmillan.\nCho, Inkoo, Noah Williams, and Thomas Sargent. 2002. “Escaping Nash Inflation.” Review of Economic Studies, 69(1): 1–40.\nChristie, William G, and Paul H Schultz. 1994. “Why Do NASDAQ Market Makers Avoid Odd-Eighth Quotes?” Journal of\nFinance, 49(5): 1813–1840.\nChristie, William G., and Paul H. Schultz. 1995. “Policy Watch: Did Nasdaq Market Makers Implicitly Collude?” Journal\nof Economic Perspectives, 9(3): 199–208.\nChristie, William G, Jeffrey H Harris, and Paul H Schultz. 1994. “Why Did NASDAQ Market Makers Stop Avoiding\nOdd-Eighth Quotes?” Journal of Finance, 49(5): 1841–1860.\nColliard, Jean-Edouard, Thierry Foucault, and Stefano Lovo. 2025. “Algorithmic Pricing and Liquidity in Securities\nMarkets.” Working papers.\nCong, Lin, and Zhiguo He. 2019. “Blockchain Disruption and Smart Contracts.” Review of Financial Studies, 32(5): 1754–1797.\nCooper, David J., and Kai-Uwe Kühn. 2014. “Communication, Renegotiation, and the Scope for Collusion.” American\nEconomic Journal: Microeconomics, 6(2): 247–278.\nDolgopolov, Arthur. 2024. “Reinforcement Learning in a Prisoner’s Dilemma.” Games and Economic Behavior, 144(C): 84–103.\nDou, Winston Wei, Wei Wang, and Wenyu Wang. 2023. “The Cost of Intermediary Market Power for Distressed Borrowers.”\nWorking papers.\nDou, Winston Wei, Xiang Fang, Andrew W. Lo, and Harald Uhlig. 2023. “Macro-Finance Models with Nonlinear\nDynamics.” Annual Review of Financial Economics, 15: 407–432.\nDou, Winston Wei, Yan Ji, and Wei Wu. 2021a. “Competition, Profitability, and Discount Rates.” Journal of Financial\nEconomcis, 140(2): 582–620.\nDou, Winston Wei, Yan Ji, and Wei Wu. 2021b. “The Oligopoly Lucas Tree.” Review of Financial Studies, 35(8): 3867–3921.\nDuarte, Victor, Diogo Duarte, and Dejanir H Silva. 2024. “Machine Learning for Continuous-Time Finance.” Review of\nFinancial Studies, 37(11): 3217–3271.\nDugast, Jérôme, and Thierry Foucault. 2018. “Data Abundance and Asset Price Informativeness.” Journal of Financial\nEconomics, 130(2): 367–391.\nDugast, Jérôme, and Thierry Foucault. 2024. “Equilibrium Data Mining and Data Abundance.” Journal of Finance, 80(1): 211–\n258.\nDutta, Prajit K, and Ananth Madhavan. 1997. “Competition and Collusion in Dealer Markets.” Journal of Finance, 52(1): 245–\n276.\nFarboodi, Maryam, and Laura Veldkamp. 2020. “Long-Run Growth of Financial Data Technology.” American Economic\nReview, 110(8): 2485–2523.\nFarboodi, Maryam, and Laura Veldkamp. 2023. “Data and Markets.” Annual Review of Economics, 15: 23–40.\nFershtman, Chaim, and Ariel Pakes. 2012. “Dynamic Games with Asymmetric Information: A Framework for Empirical\nWork.” Quarterly Journal of Economics, 127(4): 1611–1661.\nFonseca, Miguel A., and Hans-Theo Normann. 2012. “Explicit vs. Tacit Collusion: The Impact of Communication in\nOligopoly Experiments.” European Economic Review, 56(8): 1759–1772.\nFudenberg, Drew, and David Levine. 1993. “Self-Confirming Equilibrium.” Econometrica, 61(3): 523–45.\nFudenberg, Drew, and David M. Kreps. 1988. “A Theory of Learning, Experimentation, and Equilibrium in Games.”\nWorking papers.\nFudenberg, Drew, and David M. Kreps. 1995. “Learning in Extensive-Form Games I. Self-Confirming Equilibria.” Games\nand Economic Behavior, 8(1): 20–55.\nFudenberg, Drew, and Eric Maskin. 1986. “The Folk Theorem in Repeated Games with Discounting or with Incomplete\nInformation.” Econometrica, 54(3): 533–54.\nGao, Zhenyu, Wei Xiong, and Jian Yuan. 2024. “Structured Beliefs and Fund Performance: An LLM-Based Approach.”\nWorking papers.\nGenesove, David, and Wallace P. Mullin. 2001. “Rules, Communication, and Collusion: Narrative Evidence from the Sugar\nInstitute Case.” American Economic Review, 91(3): 379–398.\nGoldstein, Itay, Chester S Spatt, and Mao Ye. 2021. “Big Data in Finance.” Review of Financial Studies, 34(7): 3213–3225.\nGoldstein, Itay, Emre Ozdenoren, and Kathy Yuan. 2013. “Trading Frenzies and Their Impact on Real Investment.” Journal\nof Financial Economics, 109(2): 566–582.",
          "bbox": [
            64.07999420166016,
            53.39384460449219,
            549.7173461914062,
            738.8231201171875
          ],
          "font_info": {
            "font": "URWPalladioL-Bold",
            "size": 8.975361824035645,
            "color": 0,
            "flags": 20
          }
        },
        {
          "text": "43",
          "bbox": [
            300.54498291015625,
            765.1044921875,
            311.4541015625,
            776.0136108398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        }
      ]
    },
    {
      "page_number": 46,
      "text": "Green, Edward J, and Robert H Porter. 1984. “Noncooperative Collusion under Imperfect Price Information.” Econometrica,\n52(1): 87–100.\nGreenwood, Robin, and Dimitri Vayanos. 2014. “Bond Supply and Excess Bond Returns.” Review of Financial Studies,\n27(3): 663–713.\nGreenwood, Robin, Samuel Hanson, Jeremy C Stein, and Adi Sunderam. 2023. “A Quantity-Driven Theory of Term\nPremia and Exchange Rates.” Quarterly Journal of Economics, 138(4): 2327–2389.\nGrossman, Sanford J., and Joseph E. Stiglitz. 1980. “On the Impossibility of Informationally Efficient Markets.” The\nAmerican Economic Review, 70(3): 393–408.\nHansen, Karsten T., Kanishka Misra, and Mallesh M. Pai. 2021. “Algorithmic Collusion: Supra-Competitive Prices via\nIndependent Algorithms.” Marketing Science, 40(1): 1–12.\nHansen, Lars Peter, Paymon Khorrami, and Fabrice Tourre. 2024. “Comparative Valuation Dynamics in Production\nEconomies: Long-Run Uncertainty, Heterogeneity, and Market Frictions.” Annual Review of Financial Economics, 16: 1–38.\nHarrington, Joseph E. 2018. “Developing Competition Law for Collusion by Autonomous Artificial Agents.” Journal of\nCompetition Law & Economics, 14(3): 331–363.\nHellwig, Christian, Arijit Mukherji, and Aleh Tsyvinski. 2006. “Self-Fulfilling Currency Crises: The Role of Interest\nRates.” American Economic Review, 96(5): 1769–1787.\nHolden, Craig W., and Avanidhar Subrahmanyam. 1992. “Long-Lived Private Information and Imperfect Competition.”\nJournal of Finance, 47(1): 247–270.\nHörner, Johannes, Stefano Lovo, and Tristan Tomala. 2018. “Belief-Free Price Formation.” Journal of Financial Economics,\n127(2): 342–365.\nJohnson, Justin Pappas, Andrew Rhodes, and Matthijs Wildenbeest. 2023. “Platform Design when Sellers Use Pricing\nAlgorithms.” Econometrica, 91(5): 1841–1879.\nKaniel, Ron, Zihan Lin, Markus Pelger, and Stijn Van Nieuwerburgh. 2023. “Machine-Learning the Skill of Mutual Fund\nManagers.” Journal of Financial Economics, 150(1): 94–138.\nKelly, Bryan T., Semyon Malamud, and Kangying Zhou. 2024. “The Virtue of Complexity in Return Prediction.” Journal of\nFinance, 79(1): 459–503.\nKubler, Felix, and Karl Schmedders. 2005. “Approximate versus Exact Equilibria in Dynamic Economies.” Econometrica,\n73(4): 1205–1235.\nKyle, Albert S. 1985. “Continuous Auctions and Insider Trading.” Econometrica, 53(6): 1315–1335.\nKyle, Albert S. 1989. “Informed Speculation with Imperfect Competition.” Review of Economic Studies, 56(3): 317–355.\nKyle, Albert S., and Wei Xiong. 2001. “Contagion as a Wealth Effect.” Journal of Finance, 56(4): 1401–1440.\nLambin, Xavier. 2024. “Less than Meets the Eye: Simultaneous Experiments as a Source of Algorithmic Seeming Collusion.”\nWorking papers.\nLehar, Alfred, and Christine Parlour. 2025. “Market Power and the Bitcoin Protocol.” Working papers.\nLevine, David K., Thomas R. Palfrey, and Charles R. Plott. 1991. “Siegel’s Lemma for Game Players.” Games and Economic\nBehavior, 3(2): 147–173.\nLjungqvist, Lars, and Thomas J. Sargent. 2012. Recursive Macroeconomic Theory, Third Edition. Vol. 1 of MIT Press Books. 3\ned., The MIT Press.\nLo, Andrew W., and A. Craig MacKinlay. 1999. A Non-Random Walk Down Wall Street. Princeton University Press.\nLo, Andrew W., Harry Mamaysky, and Jiang Wang. 2000. “Foundations of Technical Analysis: Computational Algorithms,\nStatistical Inference, and Empirical Implementation.” Journal of Finance, 55(4): 1705–1765.\nMarimon, Ramon, Ellen McGrattan, and Thomas J. Sargent. 1990. “Money as a Medium of Exchange in an Economy with\nArtificially Intelligent Agents.” Journal of Economic Dynamics and Control, 14(2): 329–373.\nMassarotto, Giovanna. 2025. “Detecting Algorithmic Collusion.” Ohio State Law Journal, 73.\nMildenstein, Eckart, and Harold Schleef. 1983. “The Optimal Pricing Policy of a Monopolistic Marketmaker in the Equity\nMarket.” Journal of Finance, 38(1): 218–231.\nOpp, Marcus M., Christine A. Parlour, and Johan Walden. 2014. “Markup Cycles, Dynamic Misallocation, and Amplifica-\ntion.” Journal of Economic Theory, 154: 126–161.\nPossnig, Clemens. 2024. “Reinforcement Learning and Collusion.” Working papers.\nRostek, Marzena, and Ji Hee Yoon. 2021. “Dynamic Imperfectly Competitive Markets with Private Information.” Working\npapers.\nRostek, Marzena, and Ji Hee Yoon. 2024. “Imperfect Competition in Financial Markets: Recent Developments.” Journal of\nEconomic Literature, forthcoming.\nRostek, Marzena, and Marek Weretka. 2012. “Price Inference in Small Markets.” Econometrica, 80(2): 687–711.\nRostek, Marzena, and Marek Weretka. 2015. “Dynamic Thin Markets.” Review of Financial Studies, 28(10): 2946–2992.\nRotemberg, Julio J, and Garth Saloner. 1986. “A Supergame-Theoretic Model of Price Wars during Booms.” American\nEconomic Review, 76(3): 390–407.\nRoutledge, Bryan R. 1999. “Adaptive Learning in Financial Markets.” Review of Financial Studies, 12(5): 1165–1202.\nRoutledge, Bryan R. 2001. “Genetic Algorithm Learning to Choose and Use Information.” Macroeconomic Dynamics,\n5(02): 303–325.\nSannikov, Yuliy, and Andrzej Skrzypacz. 2007. “Impossibility of Collusion under Imperfect Monitoring with Flexible\nProduction.” American Economic Review, 97(5): 1794–1823.\nSutton, Richard S., and Andrew G. Barto. 2018. Reinforcement Learning: An Introduction. The MIT Press.\nVayanos, Dimitri. 1999. “Strategic Trading and Welfare in a Dynamic Market.” Review of Economic Studies, 66(2): 219–254.\nVayanos, Dimitri, and Jean-Luc Vila. 2021. “A Preferred-Habitat Model of the Term Structure of Interest Rates.” Economet-\nrica, 89(1): 77–112.\nWaltman, Ludo, and Uzay Kaymak. 2008. “Q-learning Agents in a Cournot Oligopoly Model.” Journal of Economic Dynamics\nand Control, 32(10): 3275–3293.\nWatkins, Christopher J. C. H., and Peter Dayan. 1992. “Q-learning.” Machine Learning, 8(3): 279–292.\n44\n",
      "images": [],
      "tables": [],
      "text_blocks": [
        {
          "text": "Green, Edward J, and Robert H Porter. 1984. “Noncooperative Collusion under Imperfect Price Information.” Econometrica,\n52(1): 87–100.\nGreenwood, Robin, and Dimitri Vayanos. 2014. “Bond Supply and Excess Bond Returns.” Review of Financial Studies,\n27(3): 663–713.\nGreenwood, Robin, Samuel Hanson, Jeremy C Stein, and Adi Sunderam. 2023. “A Quantity-Driven Theory of Term\nPremia and Exchange Rates.” Quarterly Journal of Economics, 138(4): 2327–2389.\nGrossman, Sanford J., and Joseph E. Stiglitz. 1980. “On the Impossibility of Informationally Efficient Markets.” The\nAmerican Economic Review, 70(3): 393–408.\nHansen, Karsten T., Kanishka Misra, and Mallesh M. Pai. 2021. “Algorithmic Collusion: Supra-Competitive Prices via\nIndependent Algorithms.” Marketing Science, 40(1): 1–12.\nHansen, Lars Peter, Paymon Khorrami, and Fabrice Tourre. 2024. “Comparative Valuation Dynamics in Production\nEconomies: Long-Run Uncertainty, Heterogeneity, and Market Frictions.” Annual Review of Financial Economics, 16: 1–38.\nHarrington, Joseph E. 2018. “Developing Competition Law for Collusion by Autonomous Artificial Agents.” Journal of\nCompetition Law & Economics, 14(3): 331–363.\nHellwig, Christian, Arijit Mukherji, and Aleh Tsyvinski. 2006. “Self-Fulfilling Currency Crises: The Role of Interest\nRates.” American Economic Review, 96(5): 1769–1787.\nHolden, Craig W., and Avanidhar Subrahmanyam. 1992. “Long-Lived Private Information and Imperfect Competition.”\nJournal of Finance, 47(1): 247–270.\nHörner, Johannes, Stefano Lovo, and Tristan Tomala. 2018. “Belief-Free Price Formation.” Journal of Financial Economics,\n127(2): 342–365.\nJohnson, Justin Pappas, Andrew Rhodes, and Matthijs Wildenbeest. 2023. “Platform Design when Sellers Use Pricing\nAlgorithms.” Econometrica, 91(5): 1841–1879.\nKaniel, Ron, Zihan Lin, Markus Pelger, and Stijn Van Nieuwerburgh. 2023. “Machine-Learning the Skill of Mutual Fund\nManagers.” Journal of Financial Economics, 150(1): 94–138.\nKelly, Bryan T., Semyon Malamud, and Kangying Zhou. 2024. “The Virtue of Complexity in Return Prediction.” Journal of\nFinance, 79(1): 459–503.\nKubler, Felix, and Karl Schmedders. 2005. “Approximate versus Exact Equilibria in Dynamic Economies.” Econometrica,\n73(4): 1205–1235.\nKyle, Albert S. 1985. “Continuous Auctions and Insider Trading.” Econometrica, 53(6): 1315–1335.\nKyle, Albert S. 1989. “Informed Speculation with Imperfect Competition.” Review of Economic Studies, 56(3): 317–355.\nKyle, Albert S., and Wei Xiong. 2001. “Contagion as a Wealth Effect.” Journal of Finance, 56(4): 1401–1440.\nLambin, Xavier. 2024. “Less than Meets the Eye: Simultaneous Experiments as a Source of Algorithmic Seeming Collusion.”\nWorking papers.\nLehar, Alfred, and Christine Parlour. 2025. “Market Power and the Bitcoin Protocol.” Working papers.\nLevine, David K., Thomas R. Palfrey, and Charles R. Plott. 1991. “Siegel’s Lemma for Game Players.” Games and Economic\nBehavior, 3(2): 147–173.\nLjungqvist, Lars, and Thomas J. Sargent. 2012. Recursive Macroeconomic Theory, Third Edition. Vol. 1 of MIT Press Books. 3\ned., The MIT Press.\nLo, Andrew W., and A. Craig MacKinlay. 1999. A Non-Random Walk Down Wall Street. Princeton University Press.\nLo, Andrew W., Harry Mamaysky, and Jiang Wang. 2000. “Foundations of Technical Analysis: Computational Algorithms,\nStatistical Inference, and Empirical Implementation.” Journal of Finance, 55(4): 1705–1765.\nMarimon, Ramon, Ellen McGrattan, and Thomas J. Sargent. 1990. “Money as a Medium of Exchange in an Economy with\nArtificially Intelligent Agents.” Journal of Economic Dynamics and Control, 14(2): 329–373.\nMassarotto, Giovanna. 2025. “Detecting Algorithmic Collusion.” Ohio State Law Journal, 73.\nMildenstein, Eckart, and Harold Schleef. 1983. “The Optimal Pricing Policy of a Monopolistic Marketmaker in the Equity\nMarket.” Journal of Finance, 38(1): 218–231.\nOpp, Marcus M., Christine A. Parlour, and Johan Walden. 2014. “Markup Cycles, Dynamic Misallocation, and Amplifica-\ntion.” Journal of Economic Theory, 154: 126–161.\nPossnig, Clemens. 2024. “Reinforcement Learning and Collusion.” Working papers.\nRostek, Marzena, and Ji Hee Yoon. 2021. “Dynamic Imperfectly Competitive Markets with Private Information.” Working\npapers.\nRostek, Marzena, and Ji Hee Yoon. 2024. “Imperfect Competition in Financial Markets: Recent Developments.” Journal of\nEconomic Literature, forthcoming.\nRostek, Marzena, and Marek Weretka. 2012. “Price Inference in Small Markets.” Econometrica, 80(2): 687–711.\nRostek, Marzena, and Marek Weretka. 2015. “Dynamic Thin Markets.” Review of Financial Studies, 28(10): 2946–2992.\nRotemberg, Julio J, and Garth Saloner. 1986. “A Supergame-Theoretic Model of Price Wars during Booms.” American\nEconomic Review, 76(3): 390–407.\nRoutledge, Bryan R. 1999. “Adaptive Learning in Financial Markets.” Review of Financial Studies, 12(5): 1165–1202.\nRoutledge, Bryan R. 2001. “Genetic Algorithm Learning to Choose and Use Information.” Macroeconomic Dynamics,\n5(02): 303–325.\nSannikov, Yuliy, and Andrzej Skrzypacz. 2007. “Impossibility of Collusion under Imperfect Monitoring with Flexible\nProduction.” American Economic Review, 97(5): 1794–1823.\nSutton, Richard S., and Andrew G. Barto. 2018. Reinforcement Learning: An Introduction. The MIT Press.\nVayanos, Dimitri. 1999. “Strategic Trading and Welfare in a Dynamic Market.” Review of Economic Studies, 66(2): 219–254.\nVayanos, Dimitri, and Jean-Luc Vila. 2021. “A Preferred-Habitat Model of the Term Structure of Interest Rates.” Economet-\nrica, 89(1): 77–112.\nWaltman, Ludo, and Uzay Kaymak. 2008. “Q-learning Agents in a Cournot Oligopoly Model.” Journal of Economic Dynamics\nand Control, 32(10): 3275–3293.\nWatkins, Christopher J. C. H., and Peter Dayan. 1992. “Q-learning.” Machine Learning, 8(3): 279–292.",
          "bbox": [
            64.0799560546875,
            53.39519500732422,
            549.7142333984375,
            745.5001220703125
          ],
          "font_info": {
            "font": "URWPalladioL-Bold",
            "size": 8.880810737609863,
            "color": 0,
            "flags": 20
          }
        },
        {
          "text": "44",
          "bbox": [
            300.54498291015625,
            765.1044921875,
            311.4541015625,
            776.0136108398438
          ],
          "font_info": {
            "font": "URWPalladioL-Roma",
            "size": 10.909099578857422,
            "color": 0,
            "flags": 4
          }
        }
      ]
    }
  ],
  "full_text": "=== 페이지 1 ===\nNBER WORKING PAPER SERIES\nAI-POWERED TRADING, ALGORITHMIC COLLUSION, AND PRICE EFFICIENCY\nWinston Wei Dou\nItay Goldstein\nYan Ji\nWorking Paper 34054\nhttp://www.nber.org/papers/w34054\nNATIONAL BUREAU OF ECONOMIC RESEARCH\n1050 Massachusetts Avenue\nCambridge, MA 02138\nJuly 2025\nWe thank Tobias Adrian, Kerry Back, Snehal Banerjee, Hui Chen, Jean-Edouard Colliard,  Will \nCong, Antoine Didisheim, Itamar Drechsler, Maryam Farboodi, Slava Fos, Paolo Fulghieri, Joao \nGomes, Mark Grinblatt, Ming Guo, Wei Jiang, Chris Jones, Scott Joslin, Joe Harrington, Larry \nHarris, Zhiguo He, Harrison Hong, Mariana Khapko, Leonid Kogan, Pete Kyle, Tse-Chun Lin, \nDeborah Lucas, Ye Luo, Semyon Malamud, Andrey Malenko, George Malikov, Albert Menkveld, \nJonathan Parker, Lasse Pedersen, Paul Romer, Nick Roussanov, Tom Sargent, Antoinette Schoar, \nHyun-Song Shin, Rob Stambaugh, Eric Talley, Anton Tsoy, Stijn Van Nieuwerburgh, Dimitri \nVayanos, Laura Veldkamp, Jiang Wang, Neng Wang, Xian Wu, Liyan Yang, Jacob Yunger, David \nZhang, and seminar and conference participants at AsianFA, ASU Sonoran Winter Finance \nConference, BIS, BIS Meeting of Heads of Financial Stability, BI-SHoF Conference, Boston \nCollege, CFTRC, CFEA, CICF, CMU, Columbia, Cubist Systematic Strategies (Point72), CUFE, \nDuke/UNC Asset Pricing Conference, EFA, Fed Board, FINRA, FIRS, Florida International \nUniversity, FMA Asia/Pacific Conference, Frankfurt School of Finance and Management, Fudan, \nGeorge Mason, Harvard University, HKU, HKUST, HK Conference for Fintech and AI, IESE \nBarcelona Workshop on AI in Finance, IMF-WIFPR Conference, Imperial College, Jackson Hole \nFinance Conference, Johns Hopkins Carey Finance Conference, LSE, Melbourne Asset Pricing \nMeeting, MIT, MFA, NBER Summer Institute (Asset Pricing), Nordic Fintech Symposium, NTU \nConference on AI for Finance, NYU/Penn Law and Finance Conference, OECD, Olin Finance \nConference at WashU, OSU, Oxford, PKU, PKU/PHBS Sargent Institute Macro-Finance \nWorkshop, QES Global Quant and Macro Investing Conference, QRFE Workshop on Market \nMicrostructure, Fintech and AI, Renmin University, Rice University, Shanghai Jiao Tong \nUniversity (SAIF & Antai), SFS Cavalcade North America, SHUFE, Toronto Macro/Finance \nConference, Tsinghua (PBCSF & SEM), UCLA, UIC Finance Conference, UIUC, UT Austin, \nUniversity of Houston, University of Macau, University of Mannheim, University of Miami, \nUniversity of Minnesota, University of Toronto, University of Zurich, USC, WashU, Western \nUniversity, WFA, and Wharton for their comments. Dou is grateful for the financial supports \nfrom the Golub Faculty Scholar Award at Wharton. The views expressed herein are those of the \nauthors and do not necessarily reflect the views of the National Bureau of Economic Research.\nNBER working papers are circulated for discussion and comment purposes. They have not been \npeer-reviewed or been subject to the review by the NBER Board of Directors that accompanies \nofficial NBER publications.\n© 2025 by Winston Wei Dou, Itay Goldstein, and Yan Ji. All rights reserved. Short sections of text, \nnot to exceed two paragraphs, may be quoted without explicit permission provided that full credit, \nincluding © notice, is given to the source.\n\n\n=== 페이지 2 ===\nAI-Powered Trading, Algorithmic Collusion, and Price Efficiency\nWinston Wei Dou, Itay Goldstein, and Yan Ji\nNBER Working Paper No. 34054\nJuly 2025\nJEL No. D43, G10, G14, L13\nABSTRACT\nThe integration of algorithmic trading with reinforcement learning, termed AI-powered trading, is \ntransforming financial markets. Alongside the benefits, it raises concerns for collusion. This study \nfirst develops a model to explore the possibility of collusion among informed speculators in a \ntheoretical environment. We then conduct simulation experiments, replacing the speculators in the \nmodel with informed AI speculators who trade based on reinforcement-learning algorithms. We \nshow that they autonomously sustain collusive supra-competitive profits without agreement, \ncommunication, or intent. Such collusion undermines competition and market efficiency. We \ndemonstrate that two separate mechanisms are underlying this collusion and characterize when \neach one arises.\nWinston Wei Dou\nUniversity of Pennsylvania\nThe Wharton School\nand NBER\nwdou@wharton.upenn.edu\nItay Goldstein\nUniversity of Pennsylvania\nThe Wharton School\nand NBER\nitayg@wharton.upenn.edu\nYan Ji\nHong Kong University of Science\nand Technology (HKUST) \njiy@ust.hk\nA data appendix is available at http://www.nber.org/data-appendix/w34054\nA SSRN Link is available at https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4452704\n\n\n=== 페이지 3 ===\n1\nIntroduction\nThe integration of algorithmic trading with reinforcement learning (RL) algorithms, often termed AI-\npowered trading, has the potential to reshape financial markets and poses new regulatory challenges.\nWhile traditional algorithmic trading relies on static, hardcoded rules defined by humans, RL-based\ntrading algorithms autonomously optimize their strategies through self-learning, trial-and-error\ninteractions with the market and adapt in real time based on observed outcomes. Such adoption of AI\nalgorithms in trade execution has recently gained significant momentum and its future progression\nseems unavoidable.1\nOne of the most pressing regulatory concerns related to the adoption of AI is the risk of AI\ncollusion. As we discuss in the literature review below, AI collusion has been a concern in areas\noutside financial markets and it poses particular risks in financial markets. We define AI collusion as\na scenario where autonomous, self-interested RL algorithms independently learn to coordinate their\ntrading in a way that secures supra-competitive profits, without explicit agreements, communication,\nor pre-programmed intent. Such algorithmic collusion could benefit a small group of sophisticated\nspeculators equipped with advanced technologies, while harming broader market participants by\nundermining competition, liquidity, and market efficiency.\nWhat makes AI collusion particularly challenging to regulators is that it falls outside the scope\nof existing antitrust enforcement frameworks,2 which focus on detecting explicit communication or\nevidence of shared intent (e.g., Harrington, 2018; Massarotto, 2025). This focus reflects the prevailing\nview that communication is important for humans to sustain collusion.3 As a result, AI collusion,\ndespite yielding similar anti-competitive outcomes, remains largely unaddressed under current\nlaw. This legal gap is particularly salient in financial markets, where the boundary between illegal\ncommunication used for manipulation and lawful communication necessary for enhancing market\nefficiency and stability is inherently difficult to define and detect. But before evaluating these issues,\nwe need a better understanding of whether AI collusion in securities trading can arise in the first\nplace, given the unique nature and structure of the financial market, and if so, then how it is affected\nby the parameters of the market.\nIn this article, we show that AI collusion in securities trading can robustly arise. Our analysis\nstarts with a model to analyze the possibilities of collusion in equilibrium without considering AI\nagents. We then conduct simulation experiments with RL algorithms trading in an environment\nsimilar to the model and explore the patterns of collusion they achieve. We show that there are two\nfundamentally distinct algorithmic mechanisms through which collusion is achieved across a range\nof market environments: one based on price-trigger strategies, and the other driven by over-pruning\nbias in learning. We systematically characterize the conditions under which each mechanism prevails.\nBoth algorithmic mechanisms underlying AI collusion have counterparts in economic theory and can\n1For example, the Securities and Exchange Commission (SEC) recently approved Nasdaq’s RL-based, AI-driven order\ntype; major digital platforms have begun deploying RL trading bots; and leading hedge funds and trading powerhouses\nare increasingly adopting AI for trading.\n2While securities trading is primarily governed by securities laws, Section 1 of the Sherman Act applies to collusive\npractices that suppress competition in financial markets. Overlap arises when manipulative conduct has anti-competitive\neffects, triggering dual enforcement by the Department of Justice (DOJ) and SEC.\n3This is rooted in historical case studies and experimental research on human tacit collusion (e.g., Levine, Palfrey and\nPlott, 1991; Genesove and Mullin, 2001; Fonseca and Normann, 2012; Charness et al., 2014; Cooper and Kühn, 2014).\n1\n\n\n=== 페이지 4 ===\nbe interpreted through game-theoretic equilibrium concepts. We analyze the resulting AI collusive\nequilibrium using extensive simulations and provide heuristic justification for how these algorithmic\nmechanisms operate.\nTheoretical Benchmarks.\nWe start by developing a model that incorporates key ingredients of\ntrading in financial markets. We provide theoretical analysis of this model as benchmark, and then\nuse it as basis for our simulation experiments with RL algorithms. Our model builds on the influential\nframework of Kyle (1985), in which an informed speculator trades against noise traders, and a market\nmaker sets prices to minimize pricing errors based on the information gleaned from the total order\nflow. We start from the static framework of Kyle (1985) and extend it in the following ways that are\ncritical for the exploration of collusion in trading.\nFirst, instead of a single informed speculator operating in a one-period market, we consider\noligopolistic informed speculators who trade repeatedly across periods, with each period involving\na different short-lived asset.4 At the beginning of each period, each informed speculator receives a\nprivate signal about the fundamental value of that period’s short-lived asset, which is realized at\nthe end of the period. Clearly, the introduction of multiple oligopolistic speculators who interact\nrepeatedly reflects realistic market settings, such as quantitative hedge funds and proprietary trading\nfirms engaged in trading that happens at increasingly higher frequencies. These features are essential\nfor studying how collusion may arise in financial markets.\nSecond, we introduce a continuum of atomistic, information-insensitive investors who trade\nthe asset and collectively generate a downward-sloping demand curve within each trading period\n(similar to Kyle and Xiong, 2001; Vayanos and Vila, 2021). These investors, such as retail traders\nusing technical analysis or institutional investors seeking hold-to-maturity positions for hedging\nshort-term risks, are typically unresponsive to real-time information about the asset’s fundamental\nvalue. Instead, they trade against the current price and in the direction of the asset’s expected\nlong-term value. While we do not endogenize the behavior of these information-insensitive investors,\nthey need not be behaviorally biased. They may find it optimal not to pay attention to short-term\nfluctuations or may behave this way for institutional reasons. As discussed above, these traders\nresemble different types of investors in real-world markets. This feature, together with the next one,\ninjects inefficiency into the pricing mechanism of Kyle (1985), which as we show, is a critical element\nfor a key mechanism for collusion.\nThird, trading occurs through the market maker who sets the market price and holds inventory\nto clear the market. The market maker observes the total order flow from informed speculators and\nnoise traders, along with the deterministic order flow schedule of information-insensitive investors\nas a function of price. Given this information, the market maker sets the market price optimally to\nminimize a weighted average of inventory costs and pricing errors. Hence, unlike in Kyle (1985),\ninventory costs play a role in the pricing mechanism, which is a realistic feature of financial markets.\nHaving the information-insensitive traders alongside this concern for inventory costs is what injects\ninefficiency to the price, which will be important for the analysis of collusion.\nWe analyze the theoretical model and generate some novel results about the possibility of collusion\n4Our repeated trading setup is distinct from dynamic trading frameworks with a long-lived asset traded over multiple\nrounds within each period (e.g., Kyle, 1985; Holden and Subrahmanyam, 1992; Rostek and Weretka, 2015).\n2\n\n\n=== 페이지 5 ===\nin financial market trading. We first consider two theoretical benchmarks to characterize the steady-\nstate behavior of informed speculators: the non-collusive Nash equilibrium benchmark and the perfect\ncartel benchmark. The non-collusive Nash equilibrium refers to the one-shot Nash equilibrium of the\nstage game, in which no one can profitably deviate. Here, every speculator is trading to maximize\ncurrent trading profit, not taking into account the effect on the profit of others. In contrast, the\nperfect cartel represents the outcome in which informed speculators act collectively as a monopolist\nto maximize joint profits. Relative to the non-collusive Nash equilibrium, informed speculators in the\ncartel trade less aggressively on the information about asset, as this enables them to make higher\ncollective profits. A collusive equilibrium, if it arises, would lie between these two benchmarks. We\ndefine such an equilibrium by two features: (i) informed speculators earn supra-competitive profits\nthat exceed those obtained in the non-collusive Nash equilibrium by trading less aggressively on\nsignals; and (ii) each speculator has the option to deviate for unilateral one-period gains, with such\ndeviations imposing losses on others.\nA collusive trading equilibrium can be sustained as a subgame perfect Nash equilibrium in our\nframework as a result of price-trigger strategies. When market prices are sufficiently informative,\nspeculators can imperfectly infer others’ trades from market price movements, enabling tacit coordi-\nnation. Specifically, speculators trade less aggressively on their information, knowing that a deviation\nto a more aggressive strategy is likely to lead to the price shooting over the trigger, which will lead\nthe other speculators to punish them by reverting to the aggressive strategy in the non-collusive\nNash equilibrium. This form of collusion was introduced by Green and Porter (1984) and Abreu,\nPearce and Stacchetti (1986). Importantly, the viability of this equilibrium hinges critically on high\nprice informativeness, which is a central concept in the context of financial markets. We show that\nsustaining a collusive Nash equilibrium via price-trigger strategies becomes impossible when noise\ntrading risk is high or when information-insensitive investors are only weakly present. Intuitively,\nhigh noise trading risk leads to low price informativeness, weakening the effectiveness of prices\nas monitoring devices. Moreover, when the information-insensitive investors are not prominent,\nspeculators must trade conservatively on private signals to preserve information rents, reducing price\ninformativeness and rendering prices ineffective for detecting deviations, regardless of the level of\nnoise trading risk. This characterization of when price-trigger collusive equilibria are possible is\nnovel in the literature on financial-market trading.\nOther possibilities of collusive equilibria arise outside the concept of a Nash equilibrium. Specifi-\ncally, following the concept of experience-based equilibrium (Fershtman and Pakes, 2012), informed\nspeculators may trade less aggressively on their private signals because of a learning bias that leads\nthem to undervalue the payoff from aggressive trading. The bias persists because learning is based\nsolely on realized outcomes along the equilibrium path, while off-path strategies are insufficiently\nrevisited or updated. As a result, the learning process reinforces outcome evaluations that are\ninternally consistent with observed on-path data but fails to correct for underexplored off-path\nstrategies. We show that such equilibria exist for the entire parameter space, not depending on how\nprominent noise traders or information-insensitive traders are.\nAlgorithmic Mechanisms That Lead to AI Collusion.\nIn the main part of the paper, we examine\nwhether informed speculators, each governed by an independent and self-interested AI algorithm,\n3\n\n\n=== 페이지 6 ===\ncan reach the collusive outcomes described above without explicit agreements, communication, or\npre-programmed intent. To do so, we run simulation experiments using autonomous, model-free\nQ-learning algorithms that replace the informed speculators in the theoretical framework. Unlike\ntheir theoretical counterparts, these algorithms rely on RL to determine how to trade on private\nsignals, rather than on rationality or strategic foresight. Q-learning serves as a foundational basis\nfor many RL algorithms that have significantly advanced the AI field. It is valued for its simplicity,\ntransparency, and economic interpretability.\nWe provide additional details about the algorithms in Section 2. As described there, in each\nperiod, an algorithm selects an action (i.e., quantity traded) based on the state it faces (more on the\nstate variables below). It stores and updates estimated values for each state-action pair, including both\noptimal and suboptimal actions. These values are referred to as estimated Q-values, and together\nthey form the estimated Q-matrix over the discrete state and action space. At the start of each\nperiod, the algorithm observes the realized state and uses it to update one cell in the Q-matrix\ncorresponding to the state-action pair from the previous period. The realized state may depend\non both the prior state and action. The update is a weighted average of past experience and new\ninformation, incorporating both the reward just received and the estimated continuation value based\non the newly realized state. At the end of each period, the algorithm selects an action according to a\nstandard exploration-exploitation rule. Exploitation involves choosing the action with the highest\nestimated Q-value for the current state, while exploration involves selecting a random action. The\ninterplay between exploration and exploitation is a defining feature of RL algorithms and is critical\nfor effective learning. Typically, the likelihood of exploration gradually declines to zero, while that of\nexploitation increases toward one. In our simulation experiments, the Q-learning algorithms use a\nstate vector that includes (i) the lagged market price, (ii) the lagged fundamental value, and (iii) the\ncurrent fundamental value. Because market prices are endogenously determined through interactions\namong algorithms, noise traders, information-insensitive investors, and the pricing rule, the system is\nhighly complex and does not yield easily predictable outcomes.\nOur simulation experiments show that AI collusion arises across a wide range of market pa-\nrameters and RL hyperparameters. It emerges through two distinct algorithmic mechanisms, each\ncorresponding to one of the two theoretical collusion mechanisms discussed above and occurring in a\ndifferent region of the market parameter space. One mechanism is based on price-trigger strategies,\nclosely approximating the collusive Nash equilibrium sustained by such strategies. The other results\nfrom a learning bias that leads to the over-pruning of aggressive strategies, aligning with the collusive\nexperience-based equilibrium. We refer to the former as AI collusion driven by “artificial intelligence,”\nand the latter as AI collusion driven by “artificial stupidity.” We elaborate below on the conditions\nunder which each mechanism arises and explain how it emerges.\nSimilar to the predictions from the theoretical model described above, our simulation experiments\nshow that an AI collusive equilibrium sustained by price-trigger strategies emerges robustly in\nenvironments with low noise trading risk and a significant presence of information-insensitive\ninvestors.\nIn such environments, the lagged price, as an endogenous state variable, is highly\ninformative about whether all algorithms traded conservatively in the previous period, which is a\nkey requirement in the theory for sustaining price-trigger strategies. Given that the RL algorithms do\nnot know whom they are playing against or how their payoffs are generated — they simply track\n4\n\n\n=== 페이지 7 ===\nstates, their own actions, and their own realized payoffs — it is natural to ask how they converge to\nan outcome that closely resembles the one predicted by the fully rational model.\nThe intuition is as follows. After the exploration-intensive phase, the algorithms assign higher\nestimated Q-values to aggressive strategies, where they trade strongly on news about the fundamental,\nas these strategies yield much higher payoffs when played against opponents who randomly choose\nto trade aggressively. Hence, as the system transitions into the exploitation-intensive phase, the\nalgorithms consistently select aggressive trading strategies when they trade against each other, and\nprices move strongly with fundamentals as a result. This leads the estimated Q-values of aggressive\nstrategies to gradually decline, as they converge towards their non-collusive Nash equilibrium levels\nwhen the aggressive strategy is commonplace among the algorithms. At the same time, occasional\nbut ongoing exploration reveals to the algorithms that conservative trading strategies yield higher\nestimated Q-values than aggressive ones in states where lagged prices respond only moderately\nto lagged fundamentals. As a result, the algorithms gradually converge to adopting conservative\nstrategies when others do the same, mirroring collusive behavior. A feedback loop reinforces this\noutcome: in these states, all algorithms select conservative strategies during exploitation, which\ncauses similar states to recur, where lagged prices respond only moderately to fundamentals. Finally,\nfor this pattern to amount to price-trigger collusive behavior, a form of “punishment” following large\nprice responses to fundamentals is needed. Indeed, we observe that all algorithms shift to aggressive\ntrading following such a price response. This occurs because the algorithms recognize the pattern that\nwhen prices respond strongly to fundamentals, trading aggressively is still the best option. Overall,\nthe trading behavior thus exhibits mostly conservative trading with moderate price reactions but\nthere are occasional reversions to punishment phases characterized by aggressive trading behavior.\nThis pattern emerges even though the algorithms lack the strategic sophistication of the fully rational\ninformed speculators in the model. This is why we refer to it as AI collusion through “artificial\nintelligence.”\nImportantly, the convergence to this pattern relies on the informativeness of prices. In envi-\nronments with high noise trading risk or a limited presence of information-insensitive investors,\nboth of which result in low price informativeness, the price-trigger mechanism breaks down. This\nis because the link between the fundamental value, the action, and the price becomes too noisy\nfor the RL process to reliably distinguish patterns where conservative behavior leads to moderate\nprice responses to fundamentals from those where aggressive behavior leads to strong responses.\nInterestingly, we find that across a wide range of such settings, AI collusion still emerges, but through\na learning bias that systematically over-prunes aggressive strategies.\nThe intuition for this particular form of learning bias lies in the asymmetry of estimated Q-\nvalue updates in response to noise trading shocks, a feature inherent to RL due to its reliance on\nexploitation. When noise traders happen to trade in the same direction as the algorithm’s trade,\nalgorithms submitting aggressive trades incur large losses, which become more severe as noise\ntrading risk increases. The algorithm then sharply lowers the estimated Q-value of that strategy,\ntreating it as a very poor action. This discourages the algorithm from revisiting the strategy, thereby\nlocking in the downward bias on its estimated value. Conversely, when noise traders happen to\ntrade in the opposite direction of the algorithm’s trade, the algorithm earns large profits and may\ninitially overestimate the Q-value. However, because exploitation leads to frequent reuse of strategies\n5\n\n\n=== 페이지 8 ===\nwith high estimated Q-values, the algorithm continually revisits this action, allowing the estimated\nQ-value to be eventually corrected through sufficient further updates. In environments where trading\noutcomes are dominated by random noise rather than informed trading, this asymmetry in the\nexploitation process becomes especially pronounced and cannot be effectively corrected through\nexploration. Aggressive trading strategies, being more exposed to noise trading shocks, are more\nlikely to be prematurely pruned. This asymmetry causes the algorithm to develop a biased value\nsystem that consistently favors conservative trading strategies. Given the nature of competition\namong algorithms, they end up collectively benefiting from this bias, leading to a collusive outcome.\nThis is why we refer to the behavior as AI collusion through “artificial stupidity.”\nThe pervasiveness of AI collusion in our simulation experiments has first-order implications for\nmarket outcomes, and so is highly relevant for the purpose of market regulation. We show that\na greater extent of collusion, characterized by higher supra-competitive profits for the algorithms,\nleads to lower market liquidity, lower price informativeness, and higher mispricing, regardless of\nwhich algorithmic mechanism the AI collusion is based on. To better understand the drivers of AI\ncollusion, we conduct extensive simulation experiments by varying different market parameters. In\nprice-trigger AI collusion, collusion capacity increases when the number of informed speculators falls,\nnoise trading risk decreases, or the subjective discount factor increases. In contrast, over-pruning\nAI collusion shows different patterns: fewer informed speculators have similar effects, but lower\nnoise trading risk reduces collusion, and the subjective discount factor has little impact. These results\nalign with the underlying algorithmic mechanisms explained above and are strongly consistent\nwith what we would expect given their theoretical underpinnings. We also examine the role of RL\nhyperparameters, including the weight put on recent experience relative to past information in the\nupdating process and the rate of exploration decay. Across a broad range of values, collusive behavior\nand supra-competitive profits remain robust under both algorithmic mechanisms for AI collusion.\nContributions and Related Literature.\nThis article uncovers the economic foundations and algo-\nrithmic mechanisms of AI collusion in securities trading, focusing on its effects on price formation\nand market efficiency. These issues are central to current regulatory uncertainty, as AI represents a\nfundamentally different form of intelligence. Unlike humans, whose decisions reflect logic, emotion,\nand beliefs about others’ beliefs, AI relies on pattern recognition and optimization. As a result,\nexisting frameworks based on human behavior may not capture the strategic dynamics or equilibrium\nbehavior of AI traders, highlighting the need to study the algorithmic behavior — or “psychology” —\nof machines (Goldstein, Spatt and Ye, 2021).\nOur work follows recent work on AI collusion in retail markets (e.g., Calvano et al., 2020, 2021;\nJohnson, Rhodes and Wildenbeest, 2023). The financial-market setting is fundamentally different as it\nexhibits asymmetric information, noise trading, and a price-setting mechanism that is facilitated by\nmarket makers who consider the details of the environment. Hence, we extend the simulation-based\nAI experimental framework from the retail-market environment to the financial-market environment\nby replacing assumptions of near-perfect information and fixed demand curves with a setting\ncharacterized by substantial asymmetric information and strategically adaptive demand curves\nshaped by market makers’ price discovery. As discussed above, our setting is characterized by two\nkey parameters: the level of noise trading risk and the extent of information-insensitive investor\n6\n\n\n=== 페이지 9 ===\npresence. We identify two distinct algorithmic mechanisms through which AI collusion can occur and\nsystematically characterize when each of them arises as a function of these parameters and others.\nOur model results present novel contribution to the theoretical literature on financial-market trading,\nand our simulation-based experimental results have no parallel in the emerging literature on AI\ncollusion mentioned above.\nWhile the price-trigger collusion is shown in the simpler setting of Calvano et al. (2020, 2021),\nwe show that it only holds when there is small noise trading risk and strong information-insensitive\ninvestor presence. Yet, when this mechanism fails, AI collusion typically arises through a distinct\nchannel: a learning bias driven by the over-pruning of aggressive strategies. In the terminology of\nCalvano et al. (2020), this latter channel may not count as collusion, as it arises from a learning bias,\neven though it satisfies the two defining features of a collusive equilibrium described above. However,\nit is important to note that it is equally robust and has largely the same implications for trading\nprofits, market liquidity, price informativeness, and mispricing. Hence, understanding how and\nwhen the two mechanisms emerge is of equally high importance. Others have studied algorithmic\nmechanisms, which generate supra-competitive profits without the punishment trigger (e.g., Waltman\nand Kaymak, 2008; Hansen, Misra and Pai, 2021; Abada and Lambin, 2023; Asker, Fershtman and\nPakes, 2024; Banchio and Mantegazza, 2024; Dolgopolov, 2024; Lambin, 2024), but they largely rely\non simplifying restrictions on the algorithmic capacity. We provide a detailed discussion of these\nworks in Online Appendix 1. On the other hand, the over-pruning bias we uncover arises in a highly\nsophisticated environment, complementing the range of parameters where price-trigger collusion\narises, and points to a pervasive feature of the RL framework: the asymmetric effect of exploitation,\nwhereby adverse and beneficial shocks influence learning differently.\nThere are a few early works that investigate the effects that related algorithms may have on\nfinancial or money markets (e.g., Marimon, McGrattan and Sargent, 1990; Routledge, 1999, 2001).\nHowever, they either explore adaptive learning algorithms or more basic RL algorithms than ours.\nThey do not develop implications such as we develop here regarding collusion and its effects on\nmarket efficiency. A related contemporaneous work, Colliard, Foucault and Lovo (2025), studies\ninteractions among Q-learning algorithms but focuses on stateless AI market makers. In contrast, we\nstudy AI-powered informed speculators using Q-learning with endogenous state variables, such as\npast prices. Unlike them, we uncover the different algorithmic mechanisms that drive AI collusion\nand characterize when they dominate. Cartea et al. (2022b) also analyze stateless RL in market making\nusing a multi-armed bandit algorithm.\nFurthermore, our paper contributes to the rapid growing literature on the impact of AI and\nbig data on the efficiency and functioning of financial markets (e.g., Goldstein, Spatt and Ye, 2021;\nFarboodi and Veldkamp, 2023, for literature review). Recent studies theoretically examine how data\nabundance and advances in information processing technologies affect price informativeness and\nmarket liquidity (e.g., Dugast and Foucault, 2018; Farboodi and Veldkamp, 2020; Dugast and Foucault,\n2024). Another strand of the literature demonstrates that advanced machine learning techniques can\neffectively extract predictive signals or latent economic structures from high-dimensional public data,\nwhich are otherwise difficult to detect using traditional methods (e.g., Kaniel et al., 2023; Cao et al.,\n2024; Chen, Kelly and Xiu, 2024; Gao, Xiong and Yuan, 2024; Kelly, Malamud and Zhou, 2024; Chen\net al., 2025). In contrast, our paper focuses on understanding the behavior of AI agents that replace\n7\n\n\n=== 페이지 10 ===\nhumans. We examine the resulting AI equilibrium, shaped by algorithmic interactions, highlighting\nthe importance of examining this equilibrium when assessing the overall impact of AI adoption on\nmarket efficiency.\nFinally, our paper is closely related to the literature on imperfect competition in financial markets.\nRostek and Yoon (2024) provide a recent review of the theory of imperfectly competitive financial\nmarkets, covering influential early contributions such as Kyle (1989) and Vayanos (1999), which focus\non non-collusive equilibria. Theoretical works that study the effect of coordination or collusion among\nmajor market participants on market microstructure dynamics under a repeated game framework\ninclude Dutta and Madhavan (1997), Carlin, Lobo and Viswanathan (2007), and Hörner, Lovo and\nTomala (2018), among others. The common feature of these models is that supra-competitive trading\nprofits are sustained through the threat of punishment. In addition to these models that focus on\nmarket microstructure dynamics, there are other papers that theoretically analyze collusion in financial\nmarkets due to FinTech (e.g., Cong and He, 2019). Several papers provide supporting evidence for\ncollusion in financial markets across various settings (e.g., Christie and Schultz, 1994, 1995; Christie,\nHarris and Schultz, 1994; Chen and Ritter, 2000; Dou, Wang and Wang, 2023; Bryzgalova, Pavlova and\nSikorskaya, 2025; Lehar and Parlour, 2025). We provide new theoretical results characterizing when\ncollusion can be sustained in financial-market environments and contribute further by showing that\nautonomous, self-interested AI-powered trading algorithms can learn to coordinate, even without\nany agreement, communication, or intention.\n2\nAI-Powered Trading Algorithms\nWhile RL encompasses different variants (e.g., Watkins and Dayan, 1992; Sutton and Barto, 2018),\nwe choose to focus on Q-learning for several reasons. First, Q-learning serves as a foundational\nframework for numerous dynamically sophisticated RL algorithms, upon which many recent AI\nbreakthroughs are built.5 Second, it is widely adopted in practice. Third, it is valued for its simplicity,\ntransparency, and economic interpretability.\n2.1\nBellman Equation and Q-Function\nIn a multi-agent Markov decision process environment, there are I agents, indexed by i = 1, · · · , I.\nThe state of the environment is represented by a vector s, which evolves according to a Markov\nprocess. Each agent makes decisions based on the current state, which in turn evolves partly due\nto the collective actions of all agents within the system. Agent i’s intertemporal optimization is\ncharacterized by the Bellman equation and solved recursively via dynamic programming:\nVi(s) = max\nxi∈X\n\b\nE [πi|s, xi] + ρE\n\u0002\nVi(s′)|s, xi\n\u0003\t\n,\n(2.1)\nwhere xi ∈X is the action taken by agent i, with X denoting the set of available actions, πi is the\npayoff received by agent i that depends on the chosen action xi as well as the actions of other agents,\n5Q-learning and other dynamically sophisticated RL algorithms take into account the possibility that actions lead to\nstate transitions and internalize that an action taken in a given state can affect future states and rewards. In contrast,\nmulti-armed bandit algorithms, a class of stateless RL methods, are not dynamically sophisticated: they do not incorporate\nany notion of state and therefore ignore the possibility that actions influence future decision-making environments.\n8\n\n\n=== 페이지 11 ===\nand s, s′ ∈S represent the states in the current and the next period, respectively, with S denoting the\nset of states. The state vector s may depend on agent-specific conditions and private signals faced by\neach agent i, for all i. The first term on the right-hand side, E [πi|s, xi], is agent i’s expected payoff\nin the current period, and the second term, ρE [Vi(s′)|s, xi], is agent i’s continuation value, with ρ\ncapturing the subjective discount factor.\nEquation (2.1) represents the recursive formulation of dynamic control problems (e.g., Bellman,\n1954; Ljungqvist and Sargent, 2012). It characterizes behavior along the equilibrium path, where\nthe optimal value function Vi(s) depends only on the current state s. In contrast, the Q function,\ndenoted by Qi(s, xi), extends the value function to each possible state-action pair, allowing evaluation\nof outcomes not only on the equilibrium path but also for counterfactual or off-path actions. By\ndefinition, the Q-function value for a given (s, xi) corresponds to the right-hand side of equation (2.1):\nQi(s, xi) = E [πi|s, xi] + ρE\n\u0002\nVi(s′)|s, xi\n\u0003\n.\n(2.2)\nIntuitively, the Q-function value, Qi(s, xi), can be interpreted as the quality of action xi in state s. The\noptimal value of a state, Vi(s), is the maximum of all the possible Q-function values of state s. That\nis, Vi(s) ≡maxx′∈X Qi(s, x′). By substituting Vi(s′) with maxx′∈X Qi(s′, x′) in equation (2.2), we can\nestablish a recursive formula for the Q-function as follows:\nQi(s, xi) = E\n\u0014\nπi + ρ max\nx′∈X Qi(s′, x′)\n\f\f\f\fs, xi\n\u0015\n.\n(2.3)\nWhen both |S| and |X| are finite, the Q-function can be represented as an |S| × |X| matrix, which\nis often referred to as the Q-matrix.\n2.2\nQ-Learning Algorithm\nIf agent i possessed knowledge of its Q-matrix, determining the optimal actions for any given state\ns would be straightforward. In essence, Q-learning estimates the Q-matrix when the conditional\ndistribution E [·|s, xi] and off-equilibrium observations (s, xi) are limited. By design, the Q-learning\nalgorithm addresses both challenges simultaneously: it uses the law of large numbers to learn the\nunderlying distribution from repeated experiences, while its trial-and-error experiments generates\ncounterfactual outcomes for state-action pairs that may not occur along the equilibrium path.\nAgent i’s iterative experimentation begins with an arbitrary initial estimated Q-matrix, bQi,0, and\nrecursively updates it from bQi,t to bQi,t+1 in iteration t + 1 as follows:\nbQi,t+1(st, xi,t) = (1 −α) bQi,t(st, xi,t)\n|\n{z\n}\nPast knowledge\n+ α\n\u0014\nπi,t + ρ max\nx′∈X\nbQi,t(st+1, x′)\n\u0015\n,\n|\n{z\n}\nNew information from experimentation\n(2.4)\nwhere α ∈[0, 1] captures the forgetting rate.6 Upon agent i choosing action xi,t in state st and\nobserving the payoff πi,t, the update from bQi,t to bQi,t+1 at the pair (st, xi,t) occurs immediately after\n6The forgetting rate α determines how quickly past experiments are discounted. For consistent learning, α must decay\nto zero to ensure convergence of the estimated Q-matrix bQi,t as t grows large. A smaller α improves asymptotic accuracy\nbut slows convergence, reflecting a higher learning capacity at the expense of greater computational cost.\n9\n\n\n=== 페이지 12 ===\nthe next state st+1 is drawn from the Markov transition distribution at the beginning of iteration t + 1,\nconditional on the state st, the chosen action xi,t, and the collective actions of all agents in iteration t.\nEquation (2.4) indicates that for agent i in iteration t + 1, only the value of the estimated Q-\nmatrix bQi,t(s, x) corresponding to the state-action pair (st, xi,t) is updated to bQi,t+1(st, xi,t). All other\nstate-action pairs remain unchanged. In other words, bQi,t+1(s, x) = bQi,t(s, x) for cases where s ̸= st\nor x ̸= xi,t. The updated value bQi,t+1(st, xi,t) is computed as a weighted average of accumulated\nknowledge based on the previous experiments, bQi,t(st, xi,t), and learning based on a new experiment,\nπi,t + ρ maxx′∈X bQi,t(st+1, x′). A key distinction between the Q-learning recursive algorithm (2.4)\nand the Bellman recursive equation (2.1) lies in how they treat expectations for future payoffs and\ncontinuation Q-values. Q-learning algorithm (2.4) does not form expectations about the continuation\nvalue because the Markovian transition probabilities from st to st+1 are unknown. Instead, it updates\nthe Q-value using the actual realized payoff and the maximum Q-value of the randomly realized\nstate st+1 at the beginning of iteration t + 1.\nIt is crucial to note that the forgetting rate α plays a significant role in the Q-learning algorithm,\nbalancing past knowledge with new information from experimentation. A higher α not only indicates\na greater impact of present learning on the Q-value update but also implies that the algorithm forgets\npast knowledge more quickly, potentially leading to biased learning. To elaborate intuitively, let τ be\nthe number of times that the Q-value of the state-action pair (s, x) has been updated in the past. As\nτ →∞, the estimated Q-value of (s, x) is approximately equal to\nbQi,tτ+1(s, x) ≈\nτ−1\n∑\nh=0\nα(1 −α)h\n\u0014\nπi,tτ−h + ρ max\nx′∈X\nbQi,tτ−h\n\u0000stτ−h+1, x′\u0001\u0015\n,\n(2.5)\nwhere th represents the period in which the estimated Q-value of (s, x) receives the h-th update.\nClearly, when α is not close to 0, the weights α(1 −α)h decay rapidly as τ increases, diminishing\nthe influence of past data. This weakens the applicability of the law of large numbers, leading to\nsubstantial bias in estimating E[·|s, xi] for future payoffs and continuation Q-values. Conversely,\na smaller α slows the decay, preserving more past information and reducing bias. However, this\nrequires significantly more iterations to achieve convergence, increasing computational costs.\n2.3\nExperimentation\nUpon state st being realized at the beginning of iteration t, agent i chooses an action xi,t, at the end of\nthe iteration, according to either an exploitation or exploration mode, as follows:\nxi,t =\n(\nargmaxx∈X bQi,t(st, x),\nwith prob. 1 −εt,\n(exploitation)\nex ∼uniform distribution on X,\nwith prob. εt.\n(exploration)\n(2.6)\nTo determine the mode, we employ the simple ε-greedy method. As outlined in equation (2.6), after\nthe state st is realized in iteration t, agent i follows either the exploration or exploitation mode with\nexogenous probabilities εt and 1 −εt, respectively. In the exploitation mode, agent i chooses its action\nto maximize the estimated Q-value based on st in iteration t, given by xi,t = argmaxx∈X bQi,t(st, x). In\ncontrast, in the exploration mode, agent i randomly chooses its action ex from the set of all possible\n10\n\n\n=== 페이지 13 ===\nvalues in X, each with equal probability.7 Exploration enables the algorithm to experiment with\nactions that appear suboptimal under the estimated Q-values, bQi,t, in iteration t. Sufficient exploration\nis crucial for accurately approximating the true Q-matrix and mitigating learning bias, as it ensures\nthat all state-action pairs are sufficiently sampled, especially in complex environments. However, this\ncomes with a tradeoff: while it enhances learning accuracy, it also increases computational burden\nand introduces noise, which can hinder convergence in multi-agent settings. To manage this tradeoff,\nthe exploration probability εt is set to decrease monotonically toward zero as t increases.\nWe focus on asynchronous learning, defined by (2.4) and (2.6), which requires no knowledge of the\nunderlying economic environment or information structure. In contrast, model-based synchronous\nlearning updates all (s, x) pairs simultaneously in each iteration, assuming precise knowledge of the\nenvironment’s structure, such as transition probabilities and payoff functions (e.g., Asker, Fershtman\nand Pakes, 2022, 2024). Model-based approaches are typically vulnerable to misspecification.\n3\nModel and Laboratory Design\nTo set up the laboratory for our simulation experiments, we develop a model that incorporates only the\nminimal set of ingredients necessary to capture the economic context of securities trading and reveal\nkey insights. Our model builds on the influential framework of Kyle (1985), highlighting financial\nmarkets as mechanisms for information aggregation, facilitated by market makers’ price discovery.\nThis mechanism compels informed speculators to trade conservatively on private signals, thereby\nkeeping price informativeness sufficiently low to preserve information rents. This informational\nperspective, central to financial market competition, goes beyond the traditional focus on product\nmarket competition among pricing algorithms (e.g., Calvano et al., 2020).\nSpecifically, our model introduces two deviations from the Kyle (1985) baseline framework. First,\nwe consider a setting with oligopolistic informed speculators in a repeated trading environment,\nengaging in trading different short-lived assets from one period to the next, rather than a single in-\nformed speculator operating in a one-period market.8 Second, we incorporate information-insensitive\ninvestors (e.g., Kyle and Xiong, 2001; Vayanos and Vila, 2021) and market makers with inventory cost\nconsiderations. Together, these elements expand upon the efficient pricing baseline model of Kyle\n(1985) by introducing potential price inefficiencies.\n3.1\nEconomic Environment\nModel Setup.\nTime is discrete, indexed by t = 1, 2, ..., and runs forever. There are I ≥2 risk-neutral\ninformed speculators, indexed by i ∈{1, · · · , I}, a representative noise trader, a representative\ninformation-insensitive investor, and a representative market maker. The environment is stationary,\nand all exogenous shocks are independent and identically distributed across periods.\nIn each period t, a short-lived asset is traded, reaching expiration at the end of the period with\nits fundamental value vt realized. The fundamental value vt is distributed as N(v, σ2\nv), where we\n7For simplicity, we use a uniform distribution, though smarter choices could improve Q-learning.\n8Our repeated trading setup is distinct from a multi-round dynamic trading framework involving a long-term asset\ntraded within a relatively prolonged period (e.g., Kyle, 1985; Holden and Subrahmanyam, 1992; Rostek and Weretka, 2015).\n11\n\n\n=== 페이지 14 ===\nset v ≡σv ≡1 for simplicity.9 The noise trader’s order flow ut is distributed as N(0, σ2\nu), where σu\ndenotes the magnitude of noise trading risk.\nEach informed speculator i knows vt perfectly but does not observe the noise trader’s order flow\nut when submitting a trade. Speculators understand that their order flow xi,t influences the market\nprice pt by altering the total order flow, thereby (i) shifting the market-clearing condition and (ii)\npartially revealing their private signals about vt to other participants in the asset market. Specifically,\ninformed speculator i solves:\nVi(st) = max\nxi,t E [(vt −pt)xi,t + ρVi(st+1)|st, xi,t] ,\n(3.1)\nwhere Vi(st) denotes the optimal value function of speculator i in state st, achieved by selecting\nthe best trading order flow xi,t. The term (vt −pt)xi,t represents the trading profit (or loss), while\nρVi(st+1) is the discounted continuation value for the next-period state st+1, with ρ ∈(0, 1) being the\nsubjective discount factor.\nIn equation (3.1), the state variable st encapsulates all relevant information required for informed\nspeculators’ decision-making. Specifically, st includes variables such as vt, vt−1, pt−1, yt−1, zt−1, as\nwell as other historical variables if necessary. The quantity yt ≡∑I\ni=1 xi,t + ut is the total order flow,\nconsisting of order flows from both informed speculators and noise traders. Although yt becomes\nobservable after all trades from informed speculators and noise traders are submitted in period t, its\ncomponents cannot be separately identified, making it impossible to distinguish the informed order\nflow from the noise trading flow. The quantity zt is the demand of information-insensitive investors,\nwhose collective demand curve is given by:\nzt = −ξ(pt −v), with ξ ≥0.\n(3.2)\nThe same specification is adopted by Kyle and Xiong (2001), who justify it through the optimal\nportfolio choice made by a rational yet information-insensitive investor under certain assumptions.10\nThese investors can be rational, even though they do not infer fundamental information from the\nmarket price pt or others’ trading behaviors, unlike the rational-expectations uninformed investors in\nthe models of Grossman and Stiglitz (1980) and Kyle (1989). As discussed in Kyle and Xiong (2001),\nthe logic behind specification (3.2) is straightforward: the information-insensitive investor, focusing\non the ex-ante expected fundamental value v, buys more as pt −v becomes more negative, perceiving\nthe asset as undervalued. Including information-insensitive investors in a noisy rational expectations\nframework is intended to capture relevant institutional frictions and rigid, technical-analysis-driven\ntrading responses to price reversal signals.11\nTrading occurs through the market maker, who sets the market price pt to absorb order flow while\nminimizing inventory costs and pricing errors. Specifically, the market maker observes the total order\n9For conciseness, the notations v and σv will be omitted in this manuscript when not needed for comprehension.\n10To derive the functional form of the aggregate demand curve of information-insensitive investors, one approach is to\nassume CARA utility maximization without any learning or strategic trading, as detailed in Online Appendix 2.1. Studies\nindicate that information-insensitive investors with low price elasticity of demand play an important role in shaping asset\nprices (e.g., Greenwood and Vayanos, 2014; Vayanos and Vila, 2021; Greenwood et al., 2023).\n11This approach has been commonly adopted in the literature (e.g., Hellwig, Mukherji and Tsyvinski, 2006; Goldstein,\nOzdenoren and Yuan, 2013).\n12\n\n\n=== 페이지 15 ===\nflow, yt, from informed speculators and the noise trader, as well as the order flow schedule, zt, of\ninformation-insensitive investors, which is a deterministic function of the market price pt, specified\nin (3.2). Given this information, the market maker sets pt to minimize inventory costs and pricing\nerrors, solving the following objective function:\nmin\npt E\n\u0014\n(yt + zt)2 + θ(pt −vt)2\n\f\f\f\fyt\n\u0015\n,\n(3.3)\nwhere θ > 0 represents the weight that the market maker places on minimizing pricing errors. Here,\nE [·|yt] denotes the market maker’s expectation over vt, conditioned on the observed combined order\nflow yt and its understanding of the behavior of informed speculators in equilibrium.\nTo clear the market, the market maker assumes the position −(yt + zt), incurring quadratic\ninventory costs, (yt + zt)2, consistent with the existing literature, such as Mildenstein and Schleef\n(1983). The term θ(pt −vt)2 reflects the market maker’s attempt to minimize pricing errors due\nto asymmetric information. The parameter θ acts as a reduced-form measure of the benefits from\nreducing these errors, such as attracting greater trading flows. The first-order condition leads to\npt =\nξ\nξ2 + θ yt +\nξ2\nξ2 + θ v +\nθ\nξ2 + θ E [vt|yt] .\n(3.4)\nIn our analyses, we treat θ as a universally fixed, positive constant with a tiny magnitude. By fixing\nθ, we exclude it from the comparative-static analysis. With a positive constant θ, our model gains\nconceptual coherence by offering two meaningful extreme benchmarks. As ξ approaches infinity, the\nprice pt converges to v + ξ−1yt, determined by the market clearing condition yt + zt = 0, as in Kyle\nand Xiong (2001). Conversely, as ξ decreases towards zero, pt shifts to the efficient price E[vt|yt],\nas in Kyle (1985).12 Incorporating the market maker captures financial markets as mechanisms for\naggregating information, where sophisticated players infer fundamental values from the collective\nactions of others, integrating this information into the market price, as highlighted by Kyle (1985).\nInterpreting the Model through a Specific Market Setting.\nOur model reflects realistic market\nenvironments, particularly those involving quantitative hedge funds and proprietary trading firms\noperating at increasingly short horizons. While the theoretical framework applies broadly to real-\nworld settings, we anchor our simulation experiments in a concrete example to illustrate the economic\nrelevance of AI-driven trading algorithms. In each period t, a new short-lived security is introduced\nand traded, such as a close-to-maturity option or futures contract. These contracts expire at the end\nof the period, with their payoff equal to the fundamental value vt. Close-to-maturity derivatives are\namong the most actively traded across the maturity spectrum, making them a natural focal point for\nstudying algorithmic trading behavior.\nBelow, we elaborate on each of the four types of market participants in this concrete real-world\nexample. First, informed speculators, such as quantitative hedge funds and proprietary trading firms,\nspecialize in extracting private signals about the final payoff of close-to-maturity options and futures,\nvt, using proprietary or public data powered by advanced technologies.13 These informed speculators\n12Further discussions are provided in Online Appendix 2.1.\n13Conceptually, “private signals” here include not only information derived from proprietary sources but also predictive\n13\n\n\n=== 페이지 16 ===\ntypically operate with two teams: (i) a research team that generates private signals about vt, and (ii)\nan execution team that converts trading signals into strategically executed orders to maximize trading\nprofits. Like the structure of Kyle models, our framework assumes that valuable private signals\nare already available, while focusing on the strategic execution of trades based on these signals. In\nother words, the AI-powered trading algorithms analyzed in this article are those employed by the\nexecution team to convert private signals into strategic trading orders. These algorithms operate\nafter the research team has generated the signals and focus on optimizing execution based on their\ninformational content.\nSecond, information-insensitive investors, such as retail investors employing technical analysis\nand institutional investors seeking hold-to-maturity positions to hedge short-term risks, typically\nremain unresponsive to real-time fundamental information related to the terminal payoff vt of close-\nto-maturity options and futures. Retail investors using technical analysis base their trades strictly on\nobserved price patterns in the market (e.g., Lo and MacKinlay, 1999; Lo, Mamaysky and Wang, 2000;\nChen, Peng and Zhou, 2024). The demand specification (3.2) captures the essence of certain technical\nanalysis strategies, assuming that a positive spread pt −v indicates overbought conditions with prices\nlikely to fall, whereas a negative spread pt −v indicates oversold conditions with prices likely to rise.\nSpecifically, the demand specification captures technical analysis tools that provide signals for likely\nprice reversals. Additionally, information-insensitive investors include institutions such as pension\nfunds, insurance companies, and mutual funds, which may purchase close-to-maturity derivatives\nand hold them to expiration as hedges against near-term risks. These investors tend to increase long\npositions when the hedge cost pt is lower.\nThird, noise traders, by contrast, make trading decisions unrelated to fundamental information\nor technical analysis. Instead, their trades are driven by factors such as liquidity needs, portfolio\nrebalancing, market sentiment, or rumors.\nFourth, market makers in close-to-maturity options and futures markets play a critical role by\nproviding liquidity, facilitating trades, and enhancing price discovery. Market makers are sophisticated\nindividuals and institutions that use advanced algorithms and robust risk management techniques.\nTheir primary function in our model is to support price discovery by integrating information from\nother market participants’ trading behaviors into the market price.\n3.2\nTheoretical Benchmarks\nWe consider three theoretical benchmarks to characterize the steady-state behavior of informed\nspeculators: the non-collusive Nash equilibrium, the perfect cartel, and the collusive equilibrium,\ndenoted by N, M, and C in the superscripts of variable notations, respectively.\nBenchmark I: Non-Collusive Nash Equilibrium.\nThis describes the one-shot Nash equilibrium in\nthe stage game of repeated trading, where each informed speculator i, leveraging private signal vt,\ntrading signals extracted from vast amounts of public data using advanced technologies such as machine learning (ML)\nand large language models (LLMs). While the underlying data may be publicly available, the ability to process and extract\nvaluable predictive trading signals from it remains beyond the reach of most investors.\n14\n\n\n=== 페이지 17 ===\nmaximizes its expected profit by solving:\nxN(vt) = argmax\nxi∈X\nE[(vt −pN(yt))xi|vt],\nunder the assumption that other speculators adhere to the equilibrium strategy xN(vt). Here, pN(yt)\ndenotes the equilibrium market price as a function of the total flow yt. Specifically, speculator i chooses\noptimal xi, while accounting for its effect on the equilibrium price, expressed as pN(yt) = v + λNyt,\nwhere yt = xi + (I −1)xN(vt) + ut. Speculators recognize that λN is dependent on market parameters\nand focus on the linear strategy xN(vt) ≡χN(vt −v) in equilibrium. That is, each informed speculator\nmaximizes its current-period payoff given others’ actions, without considering how current actions\nmay affect future payoffs or behavior. In this equilibrium, no one can profitably deviate. Details are\nin Online Appendix 2.1.\nBenchmark II: Perfect Cartel Benchmark.\nThis benchmark describes a scenario where informed\nspeculators operate as a monopolistic cartel. The cartel, leveraging private signal vt, maximizes its\nexpected profit by solving:\nxM(vt) = argmax\nx∈X\nE[(vt −pM(yt))x|vt],\nfully accounting for the impact of trading flow x on the equilibrium price pM(yt) = v + λMyt, where\nyt = Ix + ut. Speculators recognize that λM is determined by market parameters and focus on the\nlinear strategy xM(vt) ≡χM(vt −v) in equilibrium. Details are in Online Appendix 2.1.\nBenchmark III: Collusive Equilibrium.\nBelow, we define the economic concept of collusive equilib-\nrium in terms of agents’ behaviors, rather than the intent typically emphasized in legal definitions.\nDefinition 3.1 (Collusive Equilibrium). A collusive equilibrium is characterized by two key properties:\n(i) agents achieve collective supra-competitive profits that exceed those obtained in the non-collusive Nash\nequilibrium, and (ii) agents have the option to deviate from equilibrium actions for short-term gains, and such\ndeviations impose costs on others.\nIn our model, two distinct economic mechanisms can theoretically sustain a collusive equilib-\nrium: the collusive Nash equilibrium via price-trigger strategies and the collusive experience-based\nequilibrium via learning bias. We explore their existence and theoretical properties in Section 3.3.\n3.3\nTwo Mechanisms Underlying Collusive Equilibrium\nCollusive Nash Equilibrium Sustained by Price-Trigger Strategies.\nWith sufficiently high price\ninformativeness, informed speculators can imperfectly infer order flows of others from market prices,\nenabling tacit collusion.14 Price-trigger collusion was introduced by Green and Porter (1984) and\nAbreu, Pearce and Stacchetti (1986).15 We formalize this theoretical concept below.\n14Under certain conditions, prices can even reveal others’ private values in equilibrium (Rostek and Weretka, 2012), and\nact as a sufficient statistic for inferring others’ behavior following unilateral deviations (Rostek and Yoon, 2021).\n15The study of tacit collusion via grim-trigger strategies with observable actions, initiated by Fudenberg and Maskin\n(1986) and Rotemberg and Saloner (1986), has been further developed in recent finance research, including asset pricing\n15\n\n\n=== 페이지 18 ===\nDefinition 3.2 (Collusive Nash Equilibrium through Price-Trigger Strategies). A collusive equilibrium\nin trading, sustained by price-trigger strategies, is a subgame perfect Nash equilibrium with two regimes: the\ncollusive regime and the punishment regime. In the collusive regime, informed speculators implicitly coordinate\nby submitting less aggressive order flows than in the non-collusive Nash equilibrium. If prices cross a critical\nthreshold, signaling a suspected deviation, the system shifts to the punishment regime, characterized by the\nnon-collusive equilibrium, where profits are significantly lower than in the collusive regime.\nIn the collusive regime, informed speculators adopt a trading strategy, xC(vt) ≡χC(vt −v) in\nperiod t, which is less aggressive than that in the non-collusive Nash equilibrium (i.e., χC < χN).\nWhen selecting χC, they anticipate the corresponding equilibrium market price to be\npC\nt = v + φC(vt −v) + λCut,\n(3.5)\nwhere φC and λC measure the market price’s sensitivity to vt −v and ut, respectively. This reflects\ninformed speculators’ understanding of how φC and λC depend on market parameters and the\nequilibrium trading strategy xC(vt). If vt > v and the observed market price pt exceeds the critical\nthreshold for the price-trigger strategy, defined as qC\n+(vt) ≡E\n\u0002\npC\nt |vt\n\u0003 + λCσuω, i.e., pt > qC\n+(vt), then\nspeculators revert to the punishment regime, characterized by the non-collusive Nash equilibrium,\nin period t + 1 with probability η. Likewise, if vt < v and pt falls below the lower threshold,\nqC\n−(vt) ≡E[pC\nt |vt] −λCσuω, i.e., pt < qC\n−(vt), then they may also revert to the punishment regime\nin period t + 1 with probability η. Upon entering the punishment regime at t + 1, they will remain\nthere with the same probability η in each period until t + T. Thus, the triple (η, ω, T) characterizes\nan implicit coordination scheme among informed speculators. The space of price-trigger strategies is\nΩ≡{(η, ω, T) : η ∈[0, 1], ω ∈[0, ¯ω], T ∈N}.\nWe now explain why it is sufficient, without loss of generality, to restrict attention to the strategy\nspace Ωwith a sufficiently large but finite upper bound ¯ω in our analysis of the collusive Nash\nequilibrium. First, Sannikov and Skrzypacz (2007, Lemma 3) show that a tail test with a bang-bang\nproperty is the optimal mechanism for maximizing expected continuation payoffs while maintaining\nincentives against single-period deviations. Building on this insight, we focus on price-trigger\nstrategies that serve as tail tests with bang-bang properties in our trading setting and support the\ncollusive Nash equilibrium. Second, for a price-trigger strategy to be effective in deterring deviations\n(that is, to function as a powerful tail test), the associated test must have non-negligible test size (type\nI error). This requirement, grounded in the Neyman-Pearson lemma, implies that if the test size\n(type I error) is too small, the strategy becomes ineffective at detecting deviations and thus fails to\ndiscipline behavior. In particular, as long as the upper bound ¯ω is set sufficiently high, the test size\nbecomes nearly zero for all ω > ¯ω,16 making the strategy incapable of sustaining tacit collusion at\nsuch high ω values. Therefore, no meaningful strategy is omitted by focusing on Ωwith a sufficiently\nlarge but finite ¯ω. Additional technical details are provided in Online Appendix 2.1.\nCollusive Experience-Based Equilibrium Sustained by Learning Bias.\nCollusive trading behavior,\nas outlined in Definition 3.1, can also emerge as an outcome of an experience-based equilibrium\nstudies (e.g., Opp, Parlour and Walden, 2014; Dou, Ji and Wu, 2021a,b; Chen et al., 2023, 2024).\n16e.g., 1 −Φ( ¯ω) < 10−15 when ¯ω = 8.\n16\n\n\n=== 페이지 19 ===\ndefined by Fershtman and Pakes (2012), which is closely related to the concept of self-confirming\nequilibrium (e.g., Fudenberg and Levine, 1993; Battigalli et al., 2015).17 Specifically, an experience-\nbased equilibrium is characterized by: (i) a recurrent Markovian state process, (ii) an optimization\ncondition requiring strategies to be optimized based on potentially incorrect outcome evaluations,\nand (iii) a consistency condition requiring that expected discounted net cash flows under the true\ndistribution, generated by optimal strategies on the equilibrium path, align with on-path evaluations.\nCrucially, this condition applies only to on-path outcomes. Players’ beliefs or evaluations about\noff-path outcomes need not align with expected discounted cash flows under the true distribution,\nallowing for significant biases. In sum, as long as on-path evaluations match historically observed\noutcomes, these biases can persist and, in turn, sustain the equilibrium path.\nWe formalize the theoretical concept of collusive experience-based equilibrium sustained by\nlearning bias below.\nDefinition 3.3 (Collusive Experience-Based Equilibrium through Learning Bias). A collusive equilibrium\nin trading, sustained by learning bias, is an experience-based equilibrium in which informed speculators\nsystematically undervalue aggressive trading strategies due to an incorrect outcome evaluation system. This\nsystem remains uncorrected as learning is confined to outcomes observed along the equilibrium path. A notable\ncase of such an equilibrium arises from a specific form of learning bias — over-perceived aversion to noise\ntrading risk. In this case, the outcome evaluation system is biased solely by the perceived disutility associated\nwith aversion to noise trading risk: −ς\n2χ2σ2\nu, where ς > 0 represents the degree of over-perceived aversion and\nχ > 0 reflects the aggressiveness of the trading strategy x(vt) ≡χ(vt −v).\n3.4\nExistence of Collusive Equilibrium\nExistence of Collusive Nash Equilibrium Sustained by Price-Trigger Strategies.\nSustaining coordina-\ntion through price-trigger strategies hinges critically on high price informativeness to enable effective\nmonitoring. Proposition 3.1 below demonstrates the impossibility of sustaining a collusive Nash\nequilibrium via price-trigger strategies in a financial market when noise trading risk, captured by σu,\nis large or when the presence of information-insensitive investors, captured by ξ, is small relative to\nθ, defined in Equation (3.3).\nWhen noise trading risk σu is large, noise trading flow ut dominates price fluctuations, as shown\nin (3.5), overshadowing informed trading and reducing price informativeness. This situation parallels\noligopolistic product market competition with latent random price shocks (as in Abreu, Milgrom and\nPearce, 1991; Sannikov and Skrzypacz, 2007). Applying the same economic logic, high noise trading\nrisk in financial markets undermines market prices as a monitoring tool, making it impossible to\nsustain a collusive trading equilibrium through price-trigger strategies in financial markets.\nMore importantly, our paper provides new insights into the conditions that enable or prevent tacit\ncollusion in financial market trading, which can be fundamentally distinct from tacit collusion in\nproduct pricing in goods markets, as studied by Abreu, Milgrom and Pearce (1991) and Sannikov\nand Skrzypacz (2007). Specifically, when ξ is small relative to θ, reflecting a minimal presence of\ninformation-insensitive investors, the market maker’s objective in (3.3) focuses on price discovery, with\n17See also Fudenberg and Kreps (1988), Fudenberg and Kreps (1995), Cho, Williams and Sargent (2002), and Cho and\nSargent (2008) for influential early contributions.\n17\n\n\n=== 페이지 20 ===\nminimal emphasis on inventory cost minimization. This environment closely aligns with the standard\nKyle (1985) benchmark, which conceptualizes financial markets as mechanisms for information\naggregation, where sophisticated participants infer fundamental values from the collective actions\nof others and incorporate this information into prices. In such an environment, informed investors,\nunderstanding how financial markets aggregate information into prices, must trade strategically and\ncautiously on private signals to secure meaningful information rents. This deliberate and restrained\ntrading reduces price informativeness, weakening prices as effective monitoring tools. As a result,\nit becomes impossible to sustain a collusive trading equilibrium through price-trigger strategies in\nfinancial markets, regardless of the level of noise trading risk σu.\nProposition 3.1 (Feasibility of Price-Trigger Strategies). With all other parameters held constant, a collusive\nNash equilibrium sustained by price-trigger strategies is not feasible if ξ is small relative to θ or if σu is large.\nConversely, such an equilibrium exists only if ξ is sufficiently large relative to θ and σu is sufficiently small.\nThe detailed proof is provided in Online Appendix 2.3.\nExistence of Collusive Experience-Based Equilibrium Sustained by Learning Bias.\nIn contrast to\nthe collusive Nash equilibrium sustained by price-trigger strategies in Proposition 3.1, a collusive\nequilibrium driven by learning bias, especially through the self-confirming learning process, can\nrobustly arise as an experience-based equilibrium, as shown in Proposition 3.2.\nProposition 3.2 (Existence of Collusion Through Learning Bias). A collusive experience-based equilibrium\nsustained by learning bias, with any trading strategy χC ∈[χM, χN), exists for all ξ ≥0 and σu ≥0. In\nthis equilibrium, informed speculators uniformly undervalue aggressive trading strategies due to an incorrect\noutcome evaluation system, which remains uncorrected as learning is based solely on observed outcomes along\nthe equilibrium path. In particular, such a collusive experience-based equilibrium can be sustained by learning\nbias induced by over-perceived aversion to noise trading risk, characterized by the over-perceived aversion\ncoefficient ς, as introduced in Definition 3.3, with an equilibrium trading strategy χC ∈[χM, χN).\nThe detailed proof is provided in Online Appendix 2.4.\n3.5\nThe Impact of Collusive Informed Trading on Market Efficiency\nTo assess, based on the simulation experimental outcomes, whether informed AI speculators engage\nin tacitly collusive trading through price-trigger strategies or learning bias, we derive testable\ntheoretical properties of the collusive equilibrium corresponding to each of these two distinct\neconomic mechanisms.\nProposition 3.3 (Supra-Competitive Nature of Collusion). Let πM, πC, and πN represent the expected\nprofits of informed speculators in the perfect cartel benchmark, the collusive equilibrium (sustained either by\nprice-trigger strategies or learning bias), and the non-collusive equilibrium, respectively. These profits satisfy:\n∆C ≡πC −πN\nπM −πN ∈(0, 1].\n(3.6)\nwhere ∆C represents the normalized trading profitability of informed speculators in the collusive equilibrium.\n18\n\n\n=== 페이지 21 ===\nThe detailed proof is provided in Online Appendix 2.5.\nDefinition 3.4. The price informativeness, market liquidity, and mispricing are measured, respectively, by\nI ≡var(xt)\nvar(ut),\nL ≡\n\u0014∂|mt|\n∂ut\n\u0015−1\n,\nand\nE ≡|E[pt|vt] −vt| ,\n(3.7)\nwhere xt, zt, ut, and mt ≡−(yt + zt) denote the total order flow of informed speculators, information-\ninsensitive investors, noise traders, and market makers, respectively, and pt denotes the market price.\nNext, we examine how ∆C, IC, LC, and E C vary across different market structures and information\nenvironments within the collusive equilibrium, driven by two distinct mechanisms.\nProposition 3.4 (Market Structures and Collusive Trading: Consequences for Market Efficiency). The\ntwo collusion mechanisms yield similar implications when I changes, differing implications when ρ varies, and\nopposing implications when σu changes:\n(i) If a collusive Nash equilibrium sustained by price-trigger strategies exists, the following holds in this\nequilibrium when I is sufficiently large:\nρ ↓,\nσu ↑,\nor\nI ↑\n=⇒\n∆C ↓\n(i.e., collusion capacity ↓)\n=⇒\nIC/I M ↑,\nLC/LM ↑,\nand\nE C/E M ↓\n(i.e., market efficiency ↑),\n(3.8)\nwhere C and M represent the collusive Nash equilibrium and the perfect cartel benchmark, respectively.\n(ii) If a collusive experience-based equilibrium sustained by over-perceived aversion to noise trading risk\nexists, the following holds in this equilibrium:\nσu ↓,\nor\nI ↑\n=⇒\n∆C ↓\n(i.e., collusion capacity ↓)\n=⇒\nIC/I M ↑,\nLC/LM ↑,\nand\nE C/E M ↓\n(i.e., market efficiency ↑),\n(3.9)\nwhere C and M represent the collusive experience-based equilibrium and the perfect cartel benchmark,\nrespectively. The result for LC/LM holds when ξ is sufficiently large. Importantly, ρ does not affect ∆C,\nIC/I M, LC/LM, or E C/E M in this equilibrium.\nThe detailed proof is provided in Online Appendix 2.6.\n4\nSimulation Experiments on AI Trading Algorithms\nAs a proof of concept, this section presents simulation experiments to test whether informed AI\nspeculators, equipped with autonomous model-free Q-learning algorithms, can achieve and sustain\ncollusive behavior under asymmetric information and an adaptive asset demand curve that endoge-\nnously responds to their trading strategies. We specifically examine whether such collusive behavior\nby AI speculators can arise without explicit agreement, communication, or pre-programmed intent.\n19\n\n\n=== 페이지 22 ===\n4.1\nAlgorithms as Experimental Subjects\nInformed AI Speculators.\nWe now analyze the behavior of the algorithms as experimental subjects.\nSpecifically, these experiments replace the theoretical agents, referred to as “informed speculators” in\nthe model, as detailed in Section 3, with Q-learning algorithms, as described in Section 2.\nThe dimensionality of the state vector st directly impacts the learning capacity and efficiency\nof Q-learning algorithms. High-dimensional state spaces create computational challenges, often\nrequiring deep learning techniques for function approximation and effective exploration.18 To ensure\nnumerical tractability, transparency, and highlight key insights, we select a minimal set of state\nvariables, st ≡{pt−1, vt−1, vt}, which capture the information advantage of informed speculators and\nenable AI collusion through price-trigger strategies, akin to the theoretical benchmark of the collusive\nNash equilibrium in Definition 3.2.19 In this setup, informed AI speculators make trading decisions in\nperiod t based on the current private signal vt and a one-period memory of the previous fundamental\nvalue vt−1 and price pt−1. In our simulation experiments, we find that expanding the state variable st\nby incorporating additional variables, such as lagged order flows or extended histories of market\nprices and fundamental values, strengthens tacit collusion among informed AI speculators through\nprice-trigger strategies, resulting in higher trading profits. By limiting st to pt−1, vt−1, and vt, we\nimpose a stringent bar for Q-learning algorithms to achieve AI collusion sustained by price-trigger\nstrategies.\nAdaptive Market Maker.\nThe market maker does not know the distributions of randomness. It\nstores and analyzes historical data on the asset’s value and price, the order flows from information-\ninsensitive investors, and the combined order flows from informed AI speculators and the noise\ntrader, i.e., Dt ≡{vt−τ, pt−τ, zt−τ, yt−τ}Tm\nτ=1, where Tm is a large integer. The market maker estimates\nthe demand curve of information-insensitive investors and the conditional expectation of the asset’s\nvalue, E [vt|yt], using the following linear regression models, respectively:\nzt−τ = ξ0 −ξ1pt−τ + ϵz,t−τ, and vt−τ = γ0 + γ1yt−τ + ϵv,t−τ, where τ = 1, · · · , Tm.\n(4.1)\nHere, ϵz,t−τ and ϵv,t−τ represent the residual terms from linear regressions. The estimated coefficients\nbξ0,t, bξ1,t, bγ0,t, and bγ1,t are based on the rolling-window dataset Dt in period t. The pricing rule\nadaptively follows the optimal policy through a plug-in procedure:\nbpt(y) = bγ0,t + bλty with bλt = θbγ1,t + bξ1,t\nθ + bξ2\n1,t\n,\n(4.2)\nwhere θ is defined in (3.3).\nOur results remain robust even when the market maker employs\nQ-learning algorithms (see Online Appendix 4.11).\nProtocol for Simulation-Based Experiments.\nWe summarize the experimental protocol as follows.\nAt t = 0, each informed AI speculator i ∈{1, · · · , I} is assigned with an arbitrary initial Q-matrix\n18RL algorithms, augmented by deep learning techniques to address high-dimensionality challenges, form the backbone\nof many successful real-world AI applications, including “AlphaGo.”\n19Tracking both pt−1 and vt−1, rather than just pt−1, helps informed AI speculators assess potential deviations in period\nt −1 by comparing pt−1 against vt−1.\n20\n\n\n=== 페이지 23 ===\nbQi,0 and state s0. Then, the economy evolves from t to t + 1 according to the following steps:\n(1) In period t, each informed AI speculator i independently enters exploration with probability εt\nor exploitation with probability 1 −εt, submitting order flow xi,t, as in (2.6).\n(2) The noise trader submits its order flow ut, which is randomly drawn from N(0, σ2\nu).\n(3) The market maker analyzes the historical data Dt ≡{vt−τ, pt−τ, zt−τ, yt−τ}Tm\nτ=1 to estimate bpt(y)\naccording to (4.2). Upon observing yt = ∑I\ni=1 xi,t + ut, the market price is set at pt = bpt(yt).\n(4) Observing pt, information-insensitive investors submit their aggregate order flow zt in accor-\ndance with (3.2). Each informed AI speculator i realizes its profits πi,t = (vt −pt)xi,t.\n(5) At the start of period t + 1, the state variable transitions from st = {pt−1, vt−1, vt} to st+1 =\n{pt, vt, vt+1}, where vt+1 is independently drawn from N(v, σ2\nv). Each informed AI speculator i\nupdates its Q-value for (st, xi,t) using the recursive rule in (2.4).\nMerits of Simulation-Based Experiments for Algorithms.\nThe interaction among (i) AI speculators\nusing Q-learning with lagged prices as endogenous state variables, (ii) an adaptive market maker\nlearning from historical data, and (iii) randomness from noise traders and stochastic asset values\nmakes it extremely difficult, if not impossible, to prove general results on convergence or long-run\nbehavior. As in prior work (e.g., Calvano et al., 2020), our simulation-based approach is well-suited to\nstudy algorithmic behavior, strategic interaction, and resulting equilibrium outcomes. First, no general\nconvergence results exist for environments of this complexity, let alone closed-form characterizations\nof their asymptotic behavior.\nSecond, although stochastic approximation theorems can, in principle, establish convergence in\ncertain simplified settings, they are generally not applicable to settings of this complexity. Moreover,\nthey rely on strict regularity conditions for the algorithms, such as decaying hyperparameters over\ntime, which are rarely satisfied in practice. For example, hyperparameters are often held constant\nin real-world applications.\nAs a result, the steady-state behavior observed through numerical\nconvergence may be more practically relevant than the theoretical limit derived under idealized\nconditions.20 In real-world applications, particularly in robotics and securities trading, RL algorithms\noperating in multi-agent environments face several practical challenges. These include the absence\nof theoretical guarantees on convergence and decriptions of equilibrium properties, the need for\ncostly exploration, the inherently slow pace of learning, and the high cost and limited availability\nof real-world data. These factors make real-time training impractical. Consequently, training RL\nalgorithms in simulation-based synthetic environments has become a widely adopted approach in\npractice. This aligns closely with the spirit of our simulation-based experiments. For example, hedge\nfunds often use simulated financial markets to train RL-based execution strategies before deploying\nthem in live trading, just as autonomous vehicles are first trained in virtual environments using\nsimulated data before operating in the real world.\nThird, even if a theoretical analysis of a multi-agent system with Q-learning algorithms in a\nrepeated game setting like ours were feasible, despite being widely regarded as intractable, the\n20Simulation-based algorithmic experiments fundamentally differ from numerical solutions of theoretical equilibria (e.g.,\nKubler and Schmedders, 2005; Dou et al., 2023; Duarte, Duarte and Silva, 2024; Hansen, Khorrami and Tourre, 2024).\n21\n\n\n=== 페이지 24 ===\nmathematical proofs would provide little insight into why or how algorithms reach a collusive\nequilibrium. This is because such analyses typically rely on stochastic approximation methods, which\nfocus on verifying high-level regularity conditions and technical details.21\nTo complement our simulation-based experiments across various trading environment specifica-\ntions in the general model, we provide clear intuitions and heuristic justifications for the numerical\nconvergence of multiple informed AI speculators using Q-learning algorithms, as well as for the\nsteady-state properties of the resulting AI trading equilibrium, within a simplified model. The results\nare presented in Sections 5 and 6, with heuristic justifications provided in Online Appendix 3.\n4.2\nNumerical Specifications\nWe detail the numerical setup of our simulations, including the discretization of state and action\nspaces, Q-matrix initialization, parameter selection, and convergence criteria.\nDiscretization of State and Action Spaces.\nWe approximate the distribution N(v, σv) using nv grid\npoints, V = {v1, · · · , vnv}, with equal probabilities assigned to each grid. The grid points are located\naccording to vk = v + σvΦ−1((2k −1)/(2nv)) for k = 1, · · · , nv, where Φ−1 is the inverse cumulative\ndensity function of the standard normal distribution.22 We discretize the choice space of informed AI\nspeculator i for order flow xi using grids based on the optimal trading strategies in two benchmarks:\nthe non-collusive Nash equilibrium, xN = (v −v)/[(I + 1)λ], and the perfect cartel benchmark,\nxM = (v −v)/(2Iλ). Specifically, we discretize the interval [xM −ι(xN −xM), xN + ι(xN −xM)] for\nv > v and [xN −ι(xM −xN), xM + ι(xM −xN)] for v < v into nx equally spaced grid points, denoted\nby X = {x1, · · · , xnx}. The parameter ι > 0 enables informed AI speculators to choose order flows\nthat exceed the boundaries set by the theoretical benchmarks xM and xN, offering flexibility to explore\nstrategies beyond these theoretical limits. The grid points of the market price p are determined\nsimilarly to those for xi, with adjustments to account for the noise trader’s impact on market prices.\nSpecifically, the upper bound is set at pH = v + λN \u0000I max{xM, xN} + 1.96σu\n\u0001\nand the lower bound\nat pL = v + λN \u0000I min{xM, xN} −1.96σu\n\u0001\n, corresponding to the 5% and 95% percentiles of the noise\ntrader’s order flow distribution, N(0, σu). The interval [pL −ι(pH −pL), pH + ι(pH −pL)] is then\ndiscretized into np grid points, denoted by P = {p1, · · · , pnp}.\nInitial Q-Matrix and States.\nWe initialize the Q-matrix at t = 0 with the discounted payoff that\ninformed AI speculator i would earn if other informed AI speculators randomize their actions\nuniformly over the grid points in X, and the noise trading flow is set to zero, which corresponds\nto the expected value of the distribution N(0, σ2\nu).23 Specifically, for each informed AI speculator\n21Recent studies have established convergence of Q-learning algorithms to (collusive) Nash equilibria in simplified\nmodels, typically in 2 × 2 Prisoner’s Dilemma settings (e.g., Cartea et al., 2022a; Possnig, 2024). These proofs rely heavily\non existing stochastic approximation results and focus on technical verification with little intuitive explanation of the\nalgorithmic mechanisms behind convergence.\n22The results remain robust under alternative discretization schemes.\n23Different initial values for the Q-matrix have minimal impact on the results. For example, assigning high initial values\nencourages Q-learning algorithms to explore all actions thoroughly in the early learning phase, as subsequent iterations\ngradually reduce these values toward their theoretical true levels. This approach accelerates the learning process and\neffectively facilitates thorough exploration early on and exploitation in later stages.\n22\n\n\n=== 페이지 25 ===\ni = 1, · · · , I, we set its initial Q-matrix bQi,0 at t = 0 as follows:\nbQi,0(s, x) =\n1\n(1 −ρ)nx ∑\nx−i∈X\nh\nv −(v + λN(x + (I −1)x−i))\ni\nx,\nfor s = (p, v, v) ∈P × V × V and x ∈X. The initial states of our simulation, s0 = {p−1, v−1, v0}, are\nrandomized uniformly over P × V × V.\nSpecification of Exploration Rates.\nWe consider the state-dependent ε-greedy scheme:\nεt(v) = e−βt(v),\n(4.3)\nwhere β > 0 governs the speed that informed AI speculators’ exploration rate diminishes over time\nand t(v) captures the number of times that the system visited v ∈V in the past.\nParameter Values.\nThe parameters used in our numerical experiments are categorized into four\ngroups based on their roles. First, “environment parameters” describe the underlying economic\nenvironment and, importantly, their values are unknown to both the informed AI speculators and\nthe market maker. In the baseline calibration, we set I = 2 and ξ = 500, and consider two different\nvalues for σu, which are σu = 10−1 and σu = 102, representing trading environments with low and\nhigh noise trading risk, respectively. Later, we examine the implications of varying these parameters.\nSecond, “preference parameters” include the subjective discount factor for informed AI specula-\ntors, ρ, and the market maker’s weight on the pricing error term, θ. We set ρ at a relatively high level,\nρ = 0.95, to reflect the high-frequency trading environment. We examine the implications of varying\nρ values in Section 6. We fix θ ≡0.1 as a universal constant throughout our simulation experiments.\nThird, “discretization parameters” detail the methods used to discretize the system for simulation\nexperiments. We set nv = 10. Under this discretization, the standard deviation of vt is bσv =\nq\nn−1\nv\n∑nv\nk=1(vk −v)2 = 0.938, which is close to the theoretical value σv = 1.24 We set ι = 0.1, nx = 15,\nand np = 31.25 We set Tm = 10, 000 for the market maker. Increasing Tm does not alter any results.\nLastly, “hyperparameters” consist of α and β. Like in any machine learning algorithms, hyperpa-\nrameters (or tuning parameters) are crucial for controlling the learning process of RL algorithms. In\nour baseline calibration, we set α = 0.01 and β = 5 × 10−7. All results are robust to choosing different\nvalues of α and β so long as they are in the reasonable range that ensures sufficiently good learning\noutcomes. Our baseline choice of β = 5 × 10−7 implies that any action x ∈X is, on average, visited\njust due to random exploration by nv\nnx\n1\n1 −exp(−5 × 10−7) ≈1, 333, 333 times before exploration\ncompletes. In Online Appendix 4.12, we conduct experiments with varying values of α and β. We\nalso study scenarios where informed AI speculators adopt different values of α. In Online Appendix\n4.13, we consider two-tier Meta Q-learning algorithms that enable informed AI speculators to learn\nthe optimal α for the lower-tier agent as part of the upper-tier agent’s optimal decision.\n24In the remainder of this paper, the non-collusive Nash equilibrium and perfect cartel benchmark are computed using\nbσv, to ensure consistency with the discretization scheme of vt used in the simulation experiments.\n25Our choice of np ≈2nx ensures that, all else equal, a one-grid point change in one informed AI speculator’s order flow\nwill result in a change in price pt over the grid defined by P.\n23\n\n\n=== 페이지 26 ===\nCriterion for Numerical Convergence.\nEach experiment contains Nsim = 1, 000 independent simula-\ntion sessions. We adopt a stringent criterion for convergence: all informed AI speculators’ optimal\nstrategies must remain unchanged for 1, 000, 000 consecutive periods within a single session, and all\nNsim sessions must continue running until each meets this convergence condition. The number of\nperiods required for convergence varies substantially across experiments, depending on parameter\nvalues, and can also differ significantly across sessions within the same experiment. Across simulation\nexperiments, convergence occurs within a range of approximately 20 million to 50 billion periods.26\n5\nAI Trading Equilibrium: Outcomes from Simulation Experiments\nIn this section, we present the results of simulation experiments that examine the behavior of AI-\npowered trading algorithms within a theoretical laboratory framework and explore the properties of\nAI trading equilibrium. Building on the theoretical benchmarks in Sections 3.3 and 3.4, Section 5.1\nillustrates the exploration-exploitation tradeoff in RL algorithms that underpins the two algorithmic\nmechanisms driving AI equilibria, and Section 5.2 provides an overview of simulation results across\nvarious cases defined by different levels of σu and ξ. Section 5.3 presents simulation experiments in\ntrading environments with a strong presence of information-insensitive investors (ξ is large relative\nto θ). In contrast, Section 5.4 focuses on simulation experiments in environments with a minimal\npresence of information-insensitive investors (ξ is small relative to θ). Section 5.5 further elaborates\non the intuitions behind how AI collusion arises through two distinct algorithmic mechanisms\ncorresponding to the two economic mechanisms. Finally, Section 5.6 provides a discussion on the\nrole of information-insensitive investors.\n5.1\nTwo Distinct Algorithmic Mechanisms behind AI Collusion\nParallel to the two economic mechanisms underlying collusive equilibrium in trading, as defined in\nDefinitions 3.2 and 3.3, our simulation experiments with Q-learning algorithms reveal two distinct\nalgorithmic mechanisms through which informed AI speculators can autonomously learn to achieve\na collusive trading equilibrium. The first mechanism is AI collusion via price-trigger strategies,\napproximating the collusive Nash equilibrium sustained by such strategies, as defined in Definition\n3.2. The second is AI collusion driven by over-pruning bias in learning, which mirrors the collusive\nexperience-based equilibrium arising from a learning bias caused by over-perceived aversion to noise\ntrading risk, as defined in Definition 3.3.\nWhich algorithmic mechanism prevails, and consequently which type of AI equilibrium emerges,\ndepends on the effectiveness of the exploration-exploitation tradeoff in the RL algorithm. Similar to\nthe bias-variance tradeoff in supervised learning and high-dimensional statistics, this tradeoff aims to\nbalance pruning the action space and reducing outcome variability. In RL, exploration (i.e., trying\nnew actions) is essential to minimize bias in estimating the optimal action, while exploitation (i.e.,\nselecting the optimal actions based on past experience) reduces noise in received rewards, thereby\nlowering variability in the estimation of the optimal action. Similar to shrinkage techniques in\n26Our programs are written in C++, using −O2 to optimize the compiling process. We use a high-powered computing\nserver cluster with 400 CPU cores. Completing all simulation sessions in one experiment can take up to 6 hours.\n24\n\n\n=== 페이지 27 ===\nsupervised learning and high-dimensional statistics, exploitation narrows the choice space to improve\nconvergence speed and reduce variance, although it may introduce some bias.\nDrawing on the theoretical results establishing the existence of collusive equilibria sustained\nby two distinct economic mechanisms, as summarized in Propositions 3.1 and 3.2, the type of\nAI equilibrium reached by the system of RL algorithms after convergence depends on two key\nfactors: the risk of noise trading flows, captured by σu, and the presence of information-insensitive\ninvestors, measured by ξ. Together, these parameters determine the informativeness of market prices,\nwhich is shaped by the underlying economic structure and, in turn, affects the effectiveness of the\nexploration-exploitation tradeoff.\nAI collusion through the price-trigger-strategy mechanism becomes the dominant steady state\nwhen the exploration-exploitation tradeoff functions effectively, guiding learning without introducing\nsignificant bias. In this setting, a system of algorithms autonomously learns to sustain a collusive\nAI equilibrium that approximates a Nash equilibrium, even though each algorithm unilaterally\nmaximizes its own trading profit. Crucially, each algorithm not only learns how the state vector\n(i.e., the “environment”) responds to its trading behavior in effect but also integrates this knowledge\ninto its profit optimization process. This dynamic sophistication allows the algorithms to converge\nto a steady-state equilibrium that extends beyond the non-collusive Nash equilibrium. For this\nexploration-exploitation tradeoff to function effectively, price informativeness must be sufficiently\nhigh, which in turn requires a low σu and a high ξ. Intuitively, when price informativeness is high,\nthe information obtained from occasional exploration is more reliable. This allows exploitation to\nbetter focus on optimal trading strategies, while any bias introduced by exploitation can be effectively\ncorrected through exploration. Further intuition is provided in Section 5.5.\nAI collusion through the over-pruning learning bias mechanism emerges as the dominant steady\nstate when the exploration-exploitation tradeoff fails to effectively guide the estimation of optimal\ntrading strategies, resulting in significant bias. In this case, the system of algorithms does not converge\nto a collusive AI equilibrium that approximates a Nash equilibrium. Instead, an imbalance between\nexploration and exploitation causes the systematic over-pruning of aggressive trading strategies,\nresulting in a collusive AI equilibrium driven by over-pruning bias. This outcome closely parallels\nthe theoretical collusive experience-based equilibrium, which arises from a learning bias induced by\nover-perceived aversion to noise trading risk. The exploration-exploitation tradeoff fails to effectively\nguide estimation when price informativeness is not sufficiently high, which can result from a high\nσu or a low ξ. Importantly, as long as ξ is low, price informativeness remains endogenously low,\nregardless of the level of σu. Intuitively, when price informativeness is low, information obtained\nfrom occasional exploration can be misleading, causing exploitation to become trapped in unilaterally\nsuboptimal strategies that are collectively supra-competitive. In such cases, the significant bias\nintroduced by exploitation cannot be effectively corrected through exploration. Further intuition is\nprovided in Section 5.5.\nTo illustrate how over-pruning bias arises from an imbalance between exploration and exploitation,\nconsider environments with low ξ or high σu, where market prices and trading profits are predomi-\nnantly driven by noise trading shocks ut. In these settings, the behavior of RL algorithms depends\ncritically on how they process feedback from such shocks. Exploitation introduces asymmetries into\nthe learning process, depending on whether a shock is adverse or beneficial. An adverse noise trading\n25\n\n\n=== 페이지 28 ===\nshock moves in the same direction as the informed AI speculator’s trade, causing substantial trading\nlosses and sharply reducing the estimated Q-value of the chosen action. In contrast, a beneficial\nshock moves in the opposite direction, generating significant trading profits and potentially inflating\nthe estimated Q-value, though this overestimation is more likely to be corrected over time through\ncontinued and repeated exploitation.\nMore precisely, following an adverse noise trading shock, the algorithm often classifies the\nchosen strategy as a “disastrous action,” assigning it a significantly low Q-value. Exploitation\nthen discourages the algorithm from revisiting this strategy in subsequent iterations, reinforcing the\ndownward bias and preventing correction for such off-equilibrium-path actions. In contrast, following\na beneficial shock, the algorithm tends to label the strategy as a “fantastic action” and assigns it\nan inflated Q-value. Because exploitation promotes repeated use of high-Q-value strategies, the\nalgorithm continues to select and update this strategy, eventually correcting any initial overestimation.\nAggressive strategies, by their nature, are more exposed to noise trading shocks, making them\nespecially vulnerable to this asymmetric learning dynamic. As a result, they tend to be persistently\nundervalued and prematurely pruned from the set of candidate optimal strategies, reinforcing the\nover-pruning bias. Consequently, informed AI speculators gravitate toward more conservative trading\nstrategies, consistent with the collusive behavior described in Definitions 3.1 and 3.3.\nOne way to interpret the asymmetric effect of exploitation is that it effectively makes RL algo-\nrithms risk-averse to randomness in their rewards. In decision theory, risk aversion arises from\nthe asymmetric impact of adverse and beneficial shocks. Similarly, in RL, exploitation discourages\nrevisiting poorly rated strategies while reinforcing successful ones, leading to an asymmetric impact\nof adverse and beneficial shocks on the learning process. This asymmetry, in turn, causes aggressive\ntrading strategies — more exposed to noise trading shocks — to be prematurely pruned from the set\nof potential optimal strategies, reinforcing over-pruning bias in learning. As a result, the algorithm\nbehaves as if it were risk-averse, opting against aggressive strategies that expose profits to high risk.\n5.2\nKey Findings on AI Collusion\nWe begin with an overview of the key simulation findings, summarized in Figure 1, before digging\ninto the details of our simulation experiments in Sections 5.3 and 5.4, followed by a discussion of\nthe intuitions behind the AI collusive equilibrium in Section 5.5 and heuristic justifications in Online\nAppendix 3. To comprehensively characterize the AI collusive equilibrium, we classify all possible\ntrading environments into three cases: (i) high ξ and low σu, (ii) high ξ and high σu, and (iii) low ξ.\nThe corresponding theoretical benchmarks and key simulation findings are summarized as follows:\n(i) High ξ & low σu: Both a collusive Nash equilibrium via price-trigger strategies and a collusive\nexperience-based equilibrium via learning bias can theoretically be achieved by informed\nspeculators in such environments, as established in Propositions 3.1 and 3.2. However, in our\nsimulations, informed AI speculators using Q-learning consistently converge to an AI collusive\nequilibrium sustained by price-trigger strategies, rather than one driven by over-pruning bias.\n(ii) High ξ & high σu: No collusive Nash equilibrium sustained by price-trigger strategies exists in\ntheory, whereas a collusive experience-based equilibrium driven by learning bias can theoreti-\ncally be achieved by informed speculators in such environments, as established in Propositions\n26\n\n\n=== 페이지 29 ===\nTheory: Non-Collusive Nash Equilibrium\nCollusion (price-trigger strategies)  \nCollusion (learning bias)\nAI: Non-Collusive Nash Equilibrium\nCollusion (price-trigger strategies)              \n“artificial intelligence” \nCollusion (over-pruning bias in learning)    \n“artificial stupidity”\nTheory: Non-Collusive Nash Equilibrium\nCollusion (price-trigger strategies) \nCollusion (learning bias)     \nAI: Non-Collusive Nash Equilibrium\nCollusion (price-trigger strategies)  \n“artificial intelligence” \nCollusion (over-pruning bias in learning)    \n“artificial stupidity”\nLow\nHigh\nLow\nHigh\nPresence of information-insensitive \ninvestors (𝝃)\nNoise trading risk (𝝈𝒖)\nNote: The symbol “✓” indicates that the equilibrium exists, while “×” indicates that it does not. The presence of\ninformation-insensitive investors, ξ, is the slope coefficient of the asset demand curve, as specified in (3.2), while the noise\ntrading risk, σu, denotes the standard deviation of the noise trading flow, ut.\nFigure 1: Summary of our main findings.\n3.1 and 3.2. Consistent with these theoretical benchmarks, simulations show that multiple\ninformed AI speculators using Q-learning converge solely to an AI collusive equilibrium driven\nby over-pruning bias in learning, rather than one sustained by price-trigger strategies.\n(iii) Low ξ: No collusive Nash equilibrium sustained by price-trigger strategies exists in theory,\nwhereas a collusive experience-based equilibrium driven by learning bias can still theoretically\nbe achieved by informed speculators in such environments, regardless of the level of σu > 0,\nas established in Propositions 3.1 and 3.2. Consistent with these theoretical benchmarks,\nsimulations demonstrate that multiple informed AI speculators using Q-learning converge\nsolely to an AI collusive equilibrium driven by over-pruning bias in learning, rather than one\nsustained by price-trigger strategies. Notably, the results in this case are the same as those in\ncase (ii), characterized by high ξ and high σu.\n5.3\nSimulation Experiments in Trading Environments with High ξ\nThis section presents simulation results for cases (i) and (ii) described in Section 5.2. In trading\nenvironments where ξ is large relative to θ, indicating a significant presence of information-insensitive\ninvestors, the market maker primarily sets the market price to minimize inventory costs, rather than\nto reduce pricing errors, as described in (3.4).\nU-Shaped Profitability in AI Collusion: Two Distinct Mechanisms.\nPanel A of Figure 2 plots the\naverage ∆C as log σu varies from −5 to 5 along the x-axis. The horizontal dotted line represents the\ntheoretical benchmark for a perfect cartel (∆M ≡1), while the horizontal dash-dotted line indicates\n27\n\n\n=== 페이지 30 ===\n-5\n-3\n-1\n1\n3\n5\n0\n0.2\n0.4\n0.6\n0.8\n1\n1.2\n-5\n-3\n-1\n1\n3\n5\n0\n0.2\n0.4\n0.6\n0.8\n1\n1.2\n ''Artificial intelligence'':\n Collusion via price-trigger\n strategies \n ''Artificial stupidity'':\nCollusion via over-pruning\nbias in learning\nFigure 2: Two distinct mechanisms behind AI collusion.\nthe benchmark for a non-collusive Nash equilibrium (∆N ≡0). The solid U-shaped line between 0\nand 1 represents the average normalized trading profitability of informed AI speculators, that is, the\naverage value of ∆C across all Nsim = 1, 000 simulation sessions. The average value of ∆C reflects the\ncollusion capacity of the informed AI speculators. The grey area around the solid line represents the\nrange of ∆C from the 1st to the 99th percentile across all Nsim simulation sessions.27\nThe normalized profitability of AI trading, ∆C, lies between 0 and 1, suggesting that a collusive\nequilibrium with significant supra-competitive profits, as defined in Definition 3.1, emerges robustly,\nirrespective of the noise trading risk level, σu. Importantly, the normalized trading profitability, ∆C,\nand the noise trading risk, σu, exhibit a strong U-shaped relationship, indicating that AI-driven\ncollusive trading is particularly pronounced when σu is either high or low. However, the algorithmic\nmechanisms underlying these AI collusion patterns differ significantly between the high and low σu\nscenarios, as discussed in Section 5.1 and further detailed in Section 5.5. This distinction is evident\nfrom the opposing relationships between σu and ∆C in these two scenarios. When noise trading risk\nσu is low, collusion capacity, as reflected in ∆C, decreases as σu increases. In contrast, when noise\ntrading risk σu is high, collusion capacity, as reflected by ∆C, increases with σu.\nPanel B of Figure 2 shows the proportion of the Nsim parallel simulation sessions that converge to a\nspecific type of AI collusive equilibrium. Collusive equilibria sustained by price-trigger strategies are\nrepresented by the solid line, while those sustained by over-pruning bias in learning are represented\nby the dashed line. In each simulation session, the type of AI collusion is identified based on the\ndefining features of price-trigger AI collusion and over-pruning AI collusion, as determined by the\nimpulse response patterns described in Figure 3.28 The results show that when σu is low, nearly all\nsimulation sessions converge to an AI collusive equilibrium sustained by price-trigger strategies,\n27The U-shaped pattern in the normalized trading profitability of informed AI speculators remains highly robust across\ndifferent levels of ξ, as demonstrated in Figure IA.4 in Online Appendix 4.6.\n28Additional details on the classification are provided in Online Appendix 4.5.\n28\n\n\n=== 페이지 31 ===\nwith almost none converging to an equilibrium sustained by over-pruning bias in learning. As σu\nincreases, the proportion of sessions converging to price-trigger AI collusion decreases, while the\nproportion converging to over-pruning learning bias AI collusion rises. At high levels of σu, nearly\nall sessions converge to an AI collusive equilibrium sustained by over-pruning bias in learning, with\nalmost none converging to an AI collusive equilibrium sustained by price-trigger strategies.\nThe simulation results illustrated in Panel B are consistent with the theoretical benchmarks\nestablished in Propositions 3.1 and 3.2. Theoretically, when ξ is large and σu is small, both a collusive\nNash equilibrium sustained by price-trigger strategies and a collusive experience-based equilibrium\ndriven by over-perceived aversion to noise trading risk can exist. However, Proposition 3.4 reveals that\nin low noise trading risk environments (i.e., low σu), the collusion capacity of informed speculators,\nas measured by their normalized trading profitability ∆C, is typically high in a price-trigger Nash\nequilibrium but low in an experience-based equilibrium sustained by the over-perceived aversion\nto noise trading risk. Consequently, informed AI speculators in such environments autonomously\nlearn to achieve an AI collusive equilibrium sustained by price-trigger strategies rather than one\ndriven by over-pruning bias in learning, as explained in Section 5.1, with further intuition and\nheuristic justification detailed in Section 5.5. In contrast, as shown by Propositions 3.1 and 3.2, when\nξ is large and σu is large, only a collusive experience-based equilibrium driven by over-perceived\naversion to noise trading risk can be sustained, while a collusive Nash equilibrium sustained by\nprice-trigger strategies becomes theoretically infeasible. Consequently, informed AI speculators in\nsuch environments autonomously learn to achieve an AI collusive equilibrium driven by over-pruning\nbias in learning rather than one sustained by price-trigger strategies, as explained in Section 5.1, with\nfurther intuition and heuristic justification detailed in Section 5.5.\nThe U-shaped relationship between ∆C and σu becomes clear when analyzing Panels A and B\nof Figure 2 together. In Panel A, the circles (◦) represent the average ∆C conditioned on simulation\nsessions classified as price-trigger AI collusive equilibria, while the diamonds (⋄) represent the\naverage ∆C conditioned on simulation sessions classified as over-pruning AI collusive equilibria.\nWhen noise trading risk is low (i.e., log σu ≤1), informed AI speculators sustain collusion mainly\nthrough price-trigger strategies, achieving significant supra-competitive profits. As σu increases, the\ncollusion capacity, reflected in normalized trading profitability ∆C, decreases. This decline occurs\nbecause higher noise trading risk reduces the informativeness of market prices, making it increasingly\nchallenging to sustain collusive trading through price-trigger strategies. These findings align with\nthe theoretical benchmark established in Proposition 3.4.\nIn contrast, when noise trading risk is high (i.e., log σu ≥3), informed AI speculators sustain\ncollusion mainly through over-pruning bias in learning, also achieving substantial supra-competitive\nprofits. As σu increases, the collusion capacity, reflected in normalized trading profitability ∆C, also\nincreases. This occurs because higher noise trading risk disrupts the balance between exploration and\nexploitation by amplifying the asymmetric effects of exploitation on the learning of aggressive trading\nstrategies in response to beneficial and adverse noise trading shocks. Specifically, it exacerbates\nthis asymmetry to the point where these effects become increasingly difficult to correct through\nexploration updates. As a result, higher noise trading risk reinforces over-pruning bias, making\naggressive trading strategies even less viable. As highlighted in Section 5.1, the asymmetric effect\nof exploitation can be interpreted as risk aversion embedded in algorithms toward randomness\n29\n\n\n=== 페이지 32 ===\nin rewards. Intuitively, greater noise trading risk further discourages algorithms from selecting\naggressive trading strategies. These simulation findings are consistent with the theoretical benchmark\nestablished in Proposition 3.4.\nTo further provide direct evidence of the two AI collusion mechanisms across environments with\nlow and high noise trading risk, as demonstrated in Figure 2, we conduct impulse response analyses\nthroughout the remainder of this section using our simulation experiments. We begin by showing that\nin low noise trading risk scenarios, informed AI speculators autonomously learn to sustain collusive,\nsupra-competitive trading profits through price-trigger strategies, without requiring any form of\nagreement, communication, or pre-programmed intent. To be more precise, we emphasize that, while\nthis AI collusive equilibrium resembles the collusive Nash equilibrium sustained by price-trigger\nstrategies, as described in Definition 3.2 and Proposition 3.1, it does not fully satisfy the requirements\nof subgame perfect Nash equilibrium.29 We then show that in high noise trading risk scenarios,\ninformed AI speculators still sustain collusive, supra-competitive trading profits, but through a\ndifferent mechanism: over-pruning bias in learning.30 This AI collusive equilibrium corresponds to\nthe collusive experience-based equilibrium sustained by over-perceived aversion to noise trading risk,\nas described in Definition 3.3 and Proposition 3.2.\nImpulse Responses: AI Collusion via Price-Trigger Strategies When σu Is Low.\nWe first examine\nhow the trained informed AI speculators respond to an exogenous shock in the noise order flow,\nwhich influences the asset’s market price through the market maker’s endogenous and adaptive\npricing rule. At t = 0, all Nsim simulation sessions have converged. The market price of the asset, pt,\nis determined by the market maker’s adaptive pricing rule, which responds to the random variables\nvt and ut along each simulation path, independently across the parallel simulation paths. At t = 3,\nan unexpected exogenous shock, ushock, is introduced to the noise order flow ut, simultaneously\nand uniformly affecting all Nsim simulation sessions. This shock is designed to adversely impact the\ntrading profits of informed AI speculators, with ushock > 0 when vt > v and ushock < 0 when vt < v.\nAs a result, the market price pt rises unexpectedly if vt > v and falls unexpectedly if vt < v, with\nthe magnitude of the price change determined by the size of ushock. Each impulse-response curve\nin a panel represents the average impulse response dynamics across Nsim independent simulation\nsessions.31 The cross-sectional distribution of path-by-path impulse response dynamics across Nsim\nsimulation sessions is provided in Online Appendix 4.4.\nPanel A of Figure 2 shows that, in environments with a significant presence of information-\ninsensitive investors (here, ξ = 500) and low noise trading risk (specifically, σu = 10−1), the average\nvalue of ∆C across Nsim parallel simulation paths is approximately 0.75. Under these conditions,\ninformed AI speculators achieve average trading profits that are about 10% higher than those in the\nnon-collusive equilibrium benchmark.\n29Our numerical tests suggest that this AI collusive equilibrium is approximately Nash, meaning no local deviation is\npreferred. Numerical tests are detailed in Online Appendix 4.10.\n30In both scenarios, the equilibrium is classified as an experience-based equilibrium, based on the formal tests proposed\nby Fershtman and Pakes (2012). Details of these tests are provided in Online Appendix 4.2. This is unsurprising, as the\nexperience-based equilibrium framework is broader and encompasses subgame perfect Nash equilibrium as a special case.\n31Each of the Nsim simulation sessions averages 10,000 simulation paths to smooth out the randomness of vt and ut,\nensuring a reasonable comparison with the impulse response analysis based on the deterministic model of Calvano et al.\n(2020), which has no information asymmetry or stochastic economic environment.\n30\n\n\n=== 페이지 33 ===\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n0.02\n0.04\n0.06\n0.08\n1\n2\n3\n4\n5\n6\n7\n8\n9\n-0.105\n-0.085\n-0.065\n-0.045\n-0.025\n-0.005\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n0.01\n0.02\n0.03\n0.04\n0.05\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n0.02\n0.04\n0.06\n0.08\n1\n2\n3\n4\n5\n6\n7\n8\n9\n-0.105\n-0.085\n-0.065\n-0.045\n-0.025\n-0.005\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n0.01\n0.02\n0.03\n0.04\n0.05\nNote: All plots correspond to a trading environment with ξ = 500, indicating a significant presence of information-\ninsensitive investors, and σu = 10−1, representing a low noise trading risk level. Panels A and D depict the percentage\ndeviation of the asset’s price from its long-run mean, expressed as (ept −E[ept])/E[ept], where ept = (pt −v) × sgn(vt −v),\nand sgn(·) is the sign function ensuring ept > 0. Panels B and E depict the percentage deviation of average profits from their\nlong-run mean for each informed AI speculator, expressed as (πi,t −E[πi,t])/E[πi,t]. Panels C and F depict the percentage\ndeviation of order flows from the long-run mean for each informed AI speculator, defined as (exi,t −E[exi,t])/E[exi,t], where\nexi,t = xi,t × sgn(vt −v). The sign function ensures that exi,t > 0.\nFigure 3: Impulse response function (IRF) following an exogenous noise trading shock ushock for\nσu = 10−1 under Q-learning (left column) and the theoretical benchmark (right column).\nTo examine how informed AI speculators behave in steady-state equilibrium, we analyze their\nimpulse responses to exogenous shocks of varying magnitudes. In the “small deviation” experiment,\n|ushock| is approximately 0.25% of the average magnitude of informed AI speculators’ order flow |xi,t|,\nresulting in a minor impact on the asset price pt at t = 3. In contrast, in the “medium deviation,”\n“large deviation,” and “ultra large deviation” experiments, |ushock| corresponds to roughly 2.5%,\n11.5%, and 15.0% of the average |xi,t|, respectively, leading to progressively larger changes in pt.\nTo provide direct evidence that the behavior of informed AI speculators in equilibrium aligns\nclosely with a theoretical collusive Nash equilibrium sustained by price-trigger strategies, we present\nthe impulse responses to the exogenous shocks mentioned above for AI-powered trading in the left\n31\n\n\n=== 페이지 34 ===\ncolumn of Figure 3, alongside the corresponding theoretical benchmarks in the right column. For a\nmeaningful comparison, Panels D through F use the same magnitudes of unexpected price deviations\nat t = 3 as those in the simulation experiments shown in Panels A to C. Additionally, all shared\nparameters between the theoretical benchmarks and the simulation experiments are set to identical\nvalues. The parameters (T, ω, η), which specify the price-trigger punishment scheme in theory, are\nnot relevant to the structure of the Q-learning simulations. Here, we set T = 2 to align with the\ntwo-period punishment observed in the Q-learning experiments, ω = 2.826 to achieve an average\nprofitability ∆C of approximately 0.75, and η = 0.327 to match the average order flow deviation in\nthe “ultra large deviation” case at t = 4 in the Q-learning simulations. This side-by-side comparison\nhighlights the strong resemblance between the AI collusive equilibrium and the corresponding\ntheoretical benchmarks of collusive Nash equilibrium sustained by price-trigger strategies.\nThe price-trigger punishment scheme is evident throughout Panels A to C. Specifically, immedi-\nately after the shock at t = 3 (starting at t = 4), the responses display two defining characteristics of\nprice-trigger strategies, as outlined in Definition 3.2 and Proposition 3.1. These features of trigger-type\nstrategies, also reflected in the theoretical benchmark shown in Panels D to F, are as follows: (i) there\nis, on average, no response when the price deviation at t = 3 is small (i.e., the “small deviation”\nscenario, represented by the solid curve), and (ii) when the price deviation at t = 3 is sufficiently large,\nAI speculators respond by adopting similarly aggressive trading strategies starting at t = 4, despite\nsignificant differences in the deviation’s magnitude at t = 3 (i.e., the “medium deviation,” “large\ndeviation,” and “ultra large deviation” cases, represented by the dotted, dashed, and dash-dotted\ncurves, respectively).\nTo further validate the price-trigger punishment scheme among informed AI speculators, Panel A\nshows that for large and ultra-large price deviations, the percentage deviation of the asset’s price\nat t = 4 decreases relative to t = 3 but remains above the long-run mean. In the medium deviation\ncase, the percentage deviation at t = 4 surpasses that at t = 3. Notably, in the medium, large, and\nultra-large cases, price deviations at t = 4 converge to similar magnitudes, driven by comparable\norder flow deviations at t = 4, as shown in Panel C. In contrast, for the small deviation case, both the\nasset price and informed AI speculators’ profits revert to the long-run mean at t = 4. These nuanced\npatterns of the AI collusive equilibrium closely align with those of the collusive Nash equilibrium\nsustained by price trigger strategies, as depicted in Panels D through F.\nWe emphasize that, although the Q-learning algorithms rely only on the one-period lagged market\nprice pt−1 and fundamental value vt−1 for their decisions at period t, the punishment can extend\nbeyond a single period. Panels A through C of Figure 3 illustrate that informed AI speculators\ncontinue to enforce punishment at t = 5, albeit significantly weaker on average than at t = 4. This\npattern demonstrates that informed AI speculators learn to sustain the collusive equilibrium using\nprice-trigger strategies, where the punishment scheme generally lasts for more than one period.\nTo confirm that the price-trigger strategy employed by informed AI speculators in Panels A\nthrough C of Figure 3 is indeed the driving force behind the collusive, supra-competitive trading\nprofitability observed in Figure 2 under low noise trading risk, we disable the AI speculators’ ability\nto use lagged market prices as a monitoring tool. This is accomplished by removing the lagged\nmarket price pt−1 from the state variable st used for decision-making at period t. Our findings reveal\nthat even in environments with both a significant presence of information-insensitive investors (i.e., a\n32\n\n\n=== 페이지 35 ===\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n0.02\n0.04\n0.06\n0.08\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n0.01\n0.02\n0.03\n0.04\n0.05\nNote: Both plots are based on Q-learning simulation experiments in a trading environment with ξ = 500, indicating a\nsignificant presence of information-insensitive investors, and σu = 102, indicating high noise trading risk.\nFigure 4: Impulse response function (IRF) of informed AI speculators using Q-learning algorithms\nfollowing an exogenous noise trading shock ushock for σu = 102.\nhigh ξ) and low noise trading risk (i.e., a low σu), the price-trigger punishment scheme cannot be\nlearned, and the collusion capacity, measured by ∆C, drops to zero.\nImpulse Responses: No AI Collusion via Price-Trigger Strategies When σu Is High.\nNext, we\ndemonstrate that the collusive, supra-competitive trading profitability observed under high noise\ntrading risk (i.e., high σu) in Figure 2 is not driven by price trigger strategies, in contrast to the low\nnoise trading risk (i.e., low σu) scenario. The setup of simulation experiments in Figure 4 is the same\nas that in Figure 3 for a straightforward comparison. In Figure 4, we investigate the average IRF\nover the Nsim simulation paths in the environment with high noise trading risk (i.e., σu = 102). A\ncomparison between Panel B of Figure 4 and Panel C of Figure 3 shows that informed AI speculators\ndo not respond at all to the exogenous shock to noise trading flow (ushock) when σu is high, let alone\nrespond according to price-trigger strategies. This finding is consistent with the theoretical result\nof Proposition 3.1, which states that a collusive Nash equilibrium sustained through price-trigger\nstrategies does not exist in an environment with high noise trading risk.\nImpulse Responses: AI Collusion via Over-Pruning Bias When σu Is High.\nLastly, we investigate\nhow informed AI speculators achieve and sustain supra-competitive profits despite being unable to\nlearn and employ price-trigger strategies under high noise trading risk (i.e., high σu). Our analysis\ndemonstrates that informed AI speculators can reach an AI collusive equilibrium through over-\npruning bias in learning. This behavior corresponds to the theoretical collusive experience-based\nequilibrium, sustained by an over-perceived aversion to noise trading risk, as described in Definition\n3.3 and Proposition 3.2. To illustrate this, we compare the IRFs following a unilateral trading deviation\nby one informed AI speculator in two environments: one with low noise trading risk (σu = 10−1) and\nthe other with high noise trading risk (σu = 102), as shown in Figure 5. Specifically, we exogenously\nforce a single informed AI speculator, labeled as i, to deviate from its learned optimal strategy for\none period at t = 3, uniformly across all Nsim simulation paths. This one-period deviation at t = 3 is\ndesigned to increase the contemporaneous trading profit of the deviating speculator. Concretely, we\nexogenously increase the order flow of the deviating speculator by xi,shock if vt > v and reduce its\n33\n\n\n=== 페이지 36 ===\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n0.01\n0.02\n0.03\n0.04\n1\n2\n3\n4\n5\n6\n7\n8\n9\n-0.02\n-0.01\n0\n0.01\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n0.01\n0.02\n0.03\n0.04\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n0.01\n0.02\n0.03\n0.04\n1\n2\n3\n4\n5\n6\n7\n8\n9\n-0.02\n-0.01\n0\n0.01\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n0.01\n0.02\n0.03\n0.04\nNote: All the plots are based on simulation experiments using Q-learning algorithms in a trading environment with\nξ = 500, indicating a significant presence of information-insensitive investors.\nFigure 5: Impulse response function (IRF) following a unilateral deviation in trading order flows\nxi,shock, shown for σu = 10−1 (left column) and σu = 102 (right column) under Q-learning.\norder flow by xi,shock if vt < v.\nServing as a benchmark for comparison, Panels A through C of Figure 5 show the IRF following a\nunilateral deviation by AI speculator i (solid line) at t = 3, under the low noise trading risk scenario\n(σu = 10−1). Panel C specifically illustrates the exogenous deviation that forces AI speculator i (solid\nline) to trade more aggressively at t = 3, while the other AI speculator (dashed line) maintains its\noriginal trading behavior at t = 3. As shown in Panel A, the aggressive trading by AI speculator i\ncauses the market price pt to rise at t = 3. Panel B illustrates that the deviating AI speculator (solid\nline) achieves higher profits, while the non-deviating AI speculator (dashed line) incurs losses at\nt = 3. According to Definition 3.1, which formally defines a collusive equilibrium, the IRF results\nsupport the findings in Figure 2. Together, they show that informed AI speculators can interact and\nlearn to sustain such an equilibrium in low noise trading risk environments. More importantly, the\nresponses of informed AI speculators to this unilateral deviation in subsequent periods, starting\n34\n\n\n=== 페이지 37 ===\nfrom t = 4, further reinforce the findings of Figure 3, confirming that the AI collusive equilibrium is\nsustained by price-trigger strategies, closely resembling the behavior of a collusive Nash equilibrium\nthrough price-trigger strategies. Specifically, at t = 4, Panel C shows that both AI speculators, on\naverage, engage in equally aggressive trading as a form of punishment for the deviation that occurs\nat t = 3. As shown in Panel B, this behavior results in losses for both AI speculators at t = 4 due to\nthe sharp increase in the market price.\nIn a parallel comparison to the simulation experiments under the low noise trading risk scenario\n(σu = 10−1), Panels D through F of Figure 5 show the IRF for the same experiment, conducted under\nthe high noise trading risk scenario (σu = 102). Specifically, Panel F illustrates AI speculator i being\nforced to trade more aggressively at t = 3, while the other AI speculator (dashed line) maintains its\noriginal trading behavior at t = 3. Panel D shows that this aggressive trading by AI speculator i drives\nthe market price pt higher at t = 3. Consistent with the pattern in Panel B, Panel E demonstrates that\nthe deviating AI speculator (solid line) achieves higher profits at t = 3, while the non-deviating AI\nspeculator (dashed line) incurs losses at t = 3. According to Definition 3.1, these IRF results support\nthe findings of Figure 2, demonstrating that informed AI speculators can still reach an AI collusive\nequilibrium in environments with high noise trading risk. However, while the immediate reactions\nat t = 3 are similar to those in the low noise trading risk scenario, the subsequent responses from\nt = 4 onward differ significantly. The deviating AI speculator reverts to its original trading order\nflow, while the non-deviating AI speculator’s behavior remains unchanged, as shown in Panel F.\nImportantly, we emphasize that the pattern observed in Panel F, where the non-deviating AI\nspeculator remains unresponsive to the deviation behavior, is highly robust. This holds even though,\nas shown in Panel E, the deviating AI speculator exploits the non-deviating one at t = 3 by imposing\ncosts on it. This provides clear evidence that the AI collusive equilibrium in the high noise trading\nrisk scenario is not driven by price-trigger strategies, which theoretically sustain a collusive Nash\nequilibrium. Instead, this AI collusive equilibrium closely mirrors a theoretical collusive experience-\nbased equilibrium, sustained by over-perceived aversion to noise trading risk. Consistent with\nthe experience-based equilibrium, the persistent over-pruning bias in learning prevents the AI\nequilibrium from being altered through new trial-and-error observations within a single period. In\nOnline Appendix 4.2, we formally verify that the AI collusive equilibrium meets the criteria of an\nexperience-based equilibrium, following the methodology of Fershtman and Pakes (2012).\n5.4\nSimulation Experiments in Trading Environments with Low ξ\nThe previous section covers cases (i) and (ii) described in Section 5.1. This section provides evi-\ndence that over-pruning bias, rather than price-trigger strategies, drives AI collusion in the trading\nenvironment of case (iii), where a low ξ leads to strong price discovery by market makers.\nIn a parallel comparison to the simulation experiments with a high ξ value (ξ = 500) in Figure 5,\nFigure 6 presents the IRFs for the same experiment, where an informed AI speculator deviates at\nt = 3 by trading more aggressively (solid line in Panels C and F), conducted in a trading environment\nwith a low ξ value (ξ = 5). Specifically, the left column corresponds to a trading environment with\nσu = 10−1, while the right column corresponds to one with σu = 102. The patterns observed in both\ncolumns of Figure 6 are the same as those in the right column of Figure 5. The immediate reversion\nat t = 4 is highly robust regardless of the level of σu, even though the deviating AI speculator exploits\n35\n\n\n=== 페이지 38 ===\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n5\n10\n15\n20\n10-3\n1\n2\n3\n4\n5\n6\n7\n8\n9\n-0.02\n-0.01\n0\n0.01\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n0.01\n0.02\n0.03\n0.04\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n5\n10\n15\n20\n10-3\n1\n2\n3\n4\n5\n6\n7\n8\n9\n-0.02\n-0.01\n0\n0.01\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n0.01\n0.02\n0.03\n0.04\nNote: All the plots are based on simulation experiments using Q-learning algorithms in a trading environment with ξ = 5,\nreflecting a minimal presence of information-insensitive investors.\nFigure 6: Impulse response function (IRF) following a unilateral deviation in trading order flows\nxi,shock in the trading environment with ξ = 5, shown for σu = 10−1 (left column) and σu = 102 (right\ncolumn) under Q-learning.\nthe non-deviating AI speculator at t = 3 by imposing costs on it, as shown in Panels B and E.\nThese patterns clearly show that the AI collusive equilibrium in a low-ξ environment is not driven\nby price-trigger strategies. Instead, it is sustained by over-pruning bias against aggressive strategies,\nclosely resembling a theoretical experience-based equilibrium driven by over-perceived aversion to\nnoise trading risk. In Online Appendix 4.2, following Fershtman and Pakes (2012), we formally verify\nthat the AI collusive outcome meets the criteria for an experience-based equilibrium.\n5.5\nIntuition Behind AI Collusion and Its Underlying Algorithmic Mechanisms\nThis section explains why AI collusion through price-trigger strategies or over-pruning bias in\nlearning either occurs or does not occur across three trading environments: (i) high ξ and low σu, (ii)\nhigh ξ and high σu, and (iii) low ξ. Detailed explanations are provided in Online Appendix 3.\n36\n\n\n=== 페이지 39 ===\nCase (i): Low σu and High ξ.\nWhy cannot an AI collusive equilibrium sustained by over-pruning\nbias emerge in such environments? When σu is low and ξ is high, noise trading flows have minimal\nimpact on an informed AI speculator’s profit. This allows the exploration-exploitation tradeoff\nto operate effectively, mitigating over-pruning bias against aggressive strategies. Since algorithms\nrarely incur large losses from noise trading shocks, even when exploring aggressive strategies, these\nstrategies are not prematurely pruned and remain in the learning process. As a result, they are\nproperly evaluated and retained, preventing the emergence of AI collusion through over-pruning\nbias. Further details are provided in Result 1 of Online Appendix 3.1.1.\nWe now explain why an AI collusive equilibrium sustained by price-trigger strategies emerges in\nsuch environments, focusing on how informed AI speculators achieve it using Q-learning algorithms.\nHigh price informativeness is essential, as it ensures that market prices reflect the trading order flow of\ninformed speculators. This allows algorithms to condition their strategies on the unobserved actions\nof others, indirectly, through observed prices. In these environments, aggressive trading strategies\nmake the market price pt moves strongly with the fundamental value vt, and this strong alignment\nis reflected in the next period’s state vector, defined as st+1 = {pt, vt, vt+1}. Conversely, when all\nalgorithms trade conservatively, the price pt responds only moderately to vt, and this moderate\nalignment is similarly captured in the state vector st+1 = {pt, vt, vt+1}. Thus, from the perspective\nof the next period, the lagged price pt, as an endogenous state variable, becomes informative about\nwhether all algorithms traded conservatively in period t. This informativeness is a necessary condition\nfor price-trigger strategies to be effective. Model-free Q-learning algorithms do not logically infer the\nrelationship between lagged prices and others’ past order flows. Instead, they focus solely on learning\nthe optimal trading strategy for a given state. Nonetheless, their update rules inherently account for\nhow current trading behavior is mechanically connected with the next period’s price state, and this\nconnection is incorporated into the Q-value update, as shown in (2.4). This is a process of pattern\nrecognition, not logical reasoning. It fundamentally differs from logic-based human coordination,\nwhich requires understanding punishment-for-deviation causality and logically inferring others’\nactions from prices.\nIn addition, for algorithms to adopt price-trigger strategies, they must first learn to assign very\nlow Q-values to aggressive trading strategies across all states. This learning process unfolds in\ntwo distinct phases. In the early phase, when exploration dominates (i.e., exploration rates remain\nhigh for all algorithms), strategies are selected largely at random, and Q-values are updated based\non realized payoffs. During this phase, aggressive strategies tend to receive higher Q-values than\nconservative ones. This is because aggressive strategies yield much higher payoffs when played\nagainst opponents who randomly choose to trade aggressively. This asymmetry causes algorithms\nto assign higher Q-values to aggressive trading strategies than conservative ones early on. As\nthe exploration rate gradually declines to zero, the system transitions into a phase dominated\nby exploitation. Algorithms begin to consistently choose actions with higher learned Q-values.\nThus, early in this exploitation-intensive phase, algorithms continue to favor aggressive strategies\ninherited from the earlier exploration-intensive phase. They then settle on a state-action pair in\nwhich lagged market prices move strongly with lagged fundamentals and trading flows respond\naggressively to current private signals about fundamental values. This dynamic persists because\neven when the system occasionally enters states where lagged prices respond only moderately to\n37\n\n\n=== 페이지 40 ===\nlagged fundamentals, algorithms continue to select aggressive actions, which push the market, in\nthe next period, back to states where lagged prices respond strongly to lagged fundamentals. These\nactions result in both low immediate profits and weak continuation values. Consequently, over many\niterations, the Q-values of aggressive trading strategies gradually decline across all states, whether\ncharacterized by lagged prices strongly tracking lagged fundamentals or only moderately responding\nto them, due to persistently poor outcomes in both immediate profits and continuation values.\nLastly, for algorithms to adopt price-trigger strategies, they must eventually learn to assign\nvery high Q-values to conservative trading in states where lagged prices respond only moderately\nto lagged fundamentals. How does this occur? As discussed earlier, over many iterations, the\nQ-values of aggressive strategies in states where lagged prices respond only moderately to lagged\nfundamentals gradually decline to very low levels and eventually fall below those of conservative\nstrategies in the same states. Once this shift occurs, the algorithms begin to reinforce the state-action\npair characterized by lagged prices responding only moderately to fundamentals and conservative\ntrading in response to current fundamental signals. They consistently choose conservative actions in\nthese states, which keeps the market anchored in this region of the state space and yields both high\nimmediate rewards and increasingly strong continuation values. Over iterations, this reinforcement\ndrives the Q-values for this state-action pair to converge to very high levels. See Result 2 in Online\nAppendix 3.1.1 for details.\nCase (ii): High σu and High ξ.\nWe first explain why no AI collusive equilibrium sustained by\nprice-trigger strategies exists when σu is high, even if ξ is large. When σu is high, the state variable\npt becomes very noisy, providing little useful information for the Q-learning algorithms to track.\nConsequently, the algorithms learn to make optimal decisions with minimal reliance on the state\nvariables, effectively behaving as if no state variable is being used. In this scenario, the optimization\nproblem becomes effectively static, and the Q-learning algorithms operate more like bandit algorithms,\nlacking dynamic sophistication. When price is not an informative state variable, the mechanism\nbehind price-trigger strategies becomes ineffective, as the state variable pt is now primarily driven by\nnoise trading flows ut rather than by the trading behavior of informed AI speculators. As a result, no\nAI collusive equilibrium sustained by price-trigger strategies can be achieved by multiple informed\nAI speculators using Q-learning algorithms when σu is high, even if ξ is large. More details can be\nfound in Result 3 of Online Appendix 3.1.2.\nHowever, AI collusion still arises in this environment, but through a different algorithmic mech-\nanism. Specifically, it is sustained by a learning bias that systematically over-prunes aggressive\nstrategies. This bias results from an inherent asymmetry in the way Q-values are updated following\nnoise trading shocks, a generic feature of RL due to its reliance on exploitation.\nWhen noise trading flows move in the same direction as the algorithm’s trade, they tend to cause\nlarge losses for the algorithm. In response, the algorithm sharply lowers the Q-value of the associated\nstrategy, treats it as a “disastrous action,” and avoids selecting it in future iterations, which locks in\nthe downward bias. By contrast, when noise trading flows move in the opposite direction as the\nalgorithm’s trade, the algorithm may record large profits and significantly overestimate the Q-value,\ntreating the strategy as a “fantastic action.” Because exploitation leads to frequent reuse of high\nQ-value strategies, the algorithm continually revisits this action, allowing its Q-value to be gradually\n38\n\n\n=== 페이지 41 ===\ncorrected through subsequent updates.\nIn environments where trading outcomes are driven primarily by random noise rather than\ninformed behavior, exploration cannot effectively correct the asymmetry in the learning process\ncaused by the exploitation scheme of RL algorithms. This imbalance between exploration and\nexploitation leads to the premature pruning of aggressive strategies because their higher exposure to\nnoise trading shocks makes them more susceptible to exploitation-driven undervaluation. As a result,\nthe algorithm converges to a biased Q-value system that systematically favors conservative trading.\nSee Result 4 in Online Appendix 3.1.2 for further discussion.\nCase (iii): Low ξ.\nWe now explain why no AI collusive equilibrium sustained by price-trigger\nstrategies can arise when ξ is low, regardless of the level of σu. In this setting, the minimal presence\nof information-insensitive investors forces market makers to prioritize price discovery. As a result,\nAI speculators must trade conservatively to preserve information rents, leading to endogenously\nlow price informativeness. The equilibrium price becomes dominated by noise trading shocks and\nfails to serve as a useful state variable for Q-learning algorithms. This lack of price informativeness\nundermines the sustainability of price-trigger strategies, following the algorithmic mechanism\ndescribed in case (ii). See Result 5 in Online Appendix 3.2 for further details.\nWhy, then, can an AI collusive equilibrium sustained by over-pruning bias still arise under the\nsame low-ξ condition? As discussed above, when ξ is low, the equilibrium price is endogenously\ndominated by noise trading shocks, as in case (ii). Although the underlying reason for low price\ninformativeness differs, the consequence for the RL process is the same: the exploitation-driven\nlearning asymmetry disproportionately penalizes aggressive strategies due to their higher exposure\nto noise trading shocks. See Result 6 in Online Appendix 3.2 for further details.\n5.6\nWinners and Losers: The Role of Information-Insensitive Investors\nWe now examine who gains and who loses from AI collusion, and how this depends on the role\nof information-insensitive investors, captured by ξ, across three distinct trading environments. In\ncase (i), with high ξ and low σu, the AI collusive equilibrium is driven by price-trigger strategies.\nHere, informed AI speculators primarily trade against information-insensitive investors, who absorb\nmost of their order flow. In the simulation with ξ = 500 and σu = 10−1, each informed AI speculator\nearns an average profit of approximately 54, totaling a loss of about 108 for information-insensitive\ninvestors. Noise traders and market makers earn near-zero profits.\nIn case (ii), with high ξ and high σu, the AI collusion is sustained by the over-pruning bias\nmechanism. Here, informed AI speculators earn supra-competitive profits from trading against both\ninformation-insensitive investors and noise traders. In the simulation with ξ = 500 and σu = 102,\neach informed AI speculator earns about 54 on average, derived from average losses of 88 from\ninformation-insensitive investors and 20 from noise traders. Market makers again break even.\nThe contrast between σu = 10−1 and σu = 102, holding ξ = 500 fixed, illustrates the shift in the\nmechanism sustaining AI collusion, from price-trigger strategies to over-pruning bias. To further\nexplore this shift, we conduct additional simulations under an extreme case with σu = 2.5 × 102.\nWhen noise traders submit large orders that generate substantial losses for themselves, information-\ninsensitive investors begin trading more in line with informed AI speculators. In this case, each\n39\n\n\n=== 페이지 42 ===\n2\n3\n4\n5\n6\n7\n8\n9\n0\n0.2\n0.4\n0.6\n0.8\n1\n2\n3\n4\n5\n6\n7\n8\n9\n1\n1.5\n2\n2.5\n3\n3.5\n2\n3\n4\n5\n6\n7\n8\n9\n0\n2\n4\n6\n8\n10\n2\n3\n4\n5\n6\n7\n8\n9\n0\n0.2\n0.4\n0.6\n0.8\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n0.2\n0.4\n0.6\n0.8\n1\n2\n3\n4\n5\n6\n7\n8\n9\n1\n1.5\n2\n2.5\n3\n3.5\n2\n3\n4\n5\n6\n7\n8\n9\n0\n5\n10\n15\n2\n3\n4\n5\n6\n7\n8\n9\n0\n0.2\n0.4\n0.6\n0.8\n1\nNote: Parameters are set according to the baseline economic environment specified in Section 4.2.\nFigure 7: Implications of the number of informed AI speculators.\ninformed AI speculator earns about 54.5, while information-insensitive investors gain roughly 16,\ntogether extracting approximately 125 in total losses from noise traders. Market makers continue to\nearn near-zero profits.\nNotably, in our model, information-insensitive investors can be interpreted as retail investors\nwho follow technical analysis (see Section 3.1). Our results align with empirical evidence from Chen,\nPeng and Zhou (2024), which shows that AI-driven strategies earn profits primarily by exploiting\nsentiment among retail investors using technical analysis. Their finding that such investors may earn\npositive trading profits in high-noise environments is also consistent with our simulation outcomes.\nIn case (iii), with low ξ, AI collusion sustained by price-trigger strategies does not arise. Instead,\nan AI collusive equilibrium driven by over-pruning bias emerges robustly, similar to case (ii). In\nthis case, informed AI speculators earn supra-competitive profits primarily from trading against\nnoise traders, rather than from exploiting information-insensitive investors. In the simulation with\nξ = 5 and σu = 2, each informed AI speculator earns about 0.54 on average, derived from average\nlosses of 1.08 from noise traders. Market makers again earn near-zero profits. By design, the role of\ninformation-insensitive investors in this environment is negligible.\n6\nComparative Statics of AI Equilibrium\nEffect of the Number of Informed AI Speculators (I).\nFigure 7 shows how the AI equilibrium changes\nas I increases from 2 to 9 in the baseline environment under both low and high noise trading risk\nconditions. Panels A to D focus on the scenario with low noise trading risk (i.e., σu = 10−1), revealing\nthe following patterns as I increases: ∆decreases (for I ≥4), IC/I M and LC/LM both increase,\n40\n\n\n=== 페이지 43 ===\n0.05 0.2 0.35 0.5 0.65 0.8 0.95\n0\n0.2\n0.4\n0.6\n0.8\n1\n0.05 0.2 0.35 0.5 0.65 0.8 0.95\n1\n1.2\n1.4\n1.6\n1.8\n0.05 0.2 0.35 0.5 0.65 0.8 0.95\n1\n1.2\n1.4\n1.6\n1.8\n2\n0.05 0.2 0.35 0.5 0.65 0.8 0.95\n0.7\n0.8\n0.9\n1\n0.05 0.2 0.35 0.5 0.65 0.8 0.95\n0\n0.2\n0.4\n0.6\n0.8\n1\n0.05 0.2 0.35 0.5 0.65 0.8 0.95\n1\n1.2\n1.4\n1.6\n1.8\n0.05 0.2 0.35 0.5 0.65 0.8 0.95\n1\n1.2\n1.4\n1.6\n1.8\n2\n0.05 0.2 0.35 0.5 0.65 0.8 0.95\n0.7\n0.8\n0.9\n1\nNote: Parameters are set according to the baseline economic environment specified in Section 4.2.\nFigure 8: Implications of the subjective discount factor.\nwhile E C decreases. These findings are consistent with the theoretical results in Proposition 3.4 for\ncollusive Nash equilibrium sustained by price-trigger strategies.\nFor comparisons, in panels E to H, we focus on the environment with high noise trading risk (i.e.,\nσu = 102). In this environment, informed AI speculators achieve supra-competitive profits due to\nAI collusion through over-pruning bias in learning. These panels reveal the following patterns as I\nincreases: ∆decreases, IC/I M and LC/LM both increase, while E C decreases. These findings are\nconsistent with the theoretical results in Proposition 3.4 for collusive experience-based equilibrium\nsustained by over-perceived aversion against noise trading risk.\nEffect of Subjective Discount Factor (ρ).\nFigure 8 illustrates how the AI equilibrium changes as\nρ increases from 0.05 to 0.95 in the baseline environment under both low and high noise trading\nrisk conditions. Panels A to D focus on the low noise trading risk scenario (i.e., σu = 10−1) and\nreveal the following patterns as ρ increases: ∆rises, IC/I M and LC/LM both decline, while E C\nincreases. These findings are consistent with the theoretical results in Proposition 3.4 for collusive\nNash equilibrium sustained by price-trigger strategies and, more broadly, with the Folk theorem for\nrepeated games.\nIn sharp contrast, Panels E to H show that ρ has little effects on the AI equilibrium when noise\ntrading risk is high (i.e., σu = 102). The insignificant impact of ρ in this environment is due to the\nalgorithmic property that ρ does not meaningfully affect the magnitude of over-pruning learning\nbiases. These findings are consistent with the theoretical results in Proposition 3.4 for collusive\nexperience-based equilibrium sustained by over-perceived aversion against noise trading risk.\n41\n\n\n=== 페이지 44 ===\n7\nConclusions\nThis paper shows that AI collusion in securities trading can robustly emerge through two distinct\nalgorithmic mechanisms: one based on price-trigger strategies, and the other driven by over-pruning\nbias in learning. We characterize the conditions under which each mechanism prevails and show that\nboth correspond to established game-theoretic equilibrium concepts. This highlights a fundamental\ninsight about AI: algorithms relying solely on pattern recognition can exhibit behavior that closely\nresembles logical and strategic reasoning.\nFinancial markets differ from product markets in their role as platforms for information aggrega-\ntion and price discovery, with market makers playing a central role. The over-pruning bias identified\nin this paper is not the result of specific, nonstandard algorithmic assumptions or limitations, but a\ngeneric feature of RL that persists even in sophisticated settings.\nThese findings raise new and pressing policy and regulatory challenges.\nWhile restricting\nalgorithmic complexity or memory capacity may help deter price-trigger AI collusion, such measures\ncan inadvertently exacerbate over-pruning bias by amplifying distorted learning dynamics that\nprematurely eliminate aggressive yet efficient strategies from the set of potentially optimal options.\nAs a result, well-intentioned constraints may unintentionally undermine market efficiency. Designing\neffective guardrails for AI in financial markets requires a deep and rigorous understanding of how\nalgorithmic learning dynamics interact with the structure of trading environments to govern machine\nbehavior and shape the resulting AI-driven equilibrium.\nThis study serves as a proof of concept for analyzing AI-driven manipulation risks in financial\nmarkets and opens the door to a broader research agenda. Future work should extend this qualitative\nframework into a full-scale, data-driven quantitative model, incorporating estimated synthetic trading\nenvironments and state-of-the-art RL strengthened by deep learning techniques. Such developments\nwould enable quantitative assessments of AI’s impact on market efficiency. In parallel, extending\nthe framework to incorporate bubbles and crashes would offer valuable insights into the role of\nAI-powered trading in amplifying or dampening market instability.\nReferences\nAbada, Ibrahim, and Xavier Lambin. 2023. “Artificial Intelligence: Can Seemingly Collusive Outcomes Be Avoided?”\nManagement Science, 69(9): 5042–5065.\nAbreu, Dilip, David Pearce, and Ennio Stacchetti. 1986. “Optimal Cartel Equilibria with Imperfect Monitoring.” Journal of\nEconomic Theory, 39(1): 251–269.\nAbreu, Dilip, Paul Milgrom, and David Pearce. 1991. “Information and Timing in Repeated Partnerships.” Econometrica,\n59(6): 1713–1733.\nAsker, John, Chaim Fershtman, and Ariel Pakes. 2022. “Artificial Intelligence, Algorithm Design, and Pricing.” AEA Papers\nand Proceedings, 112: 452–56.\nAsker, John, Chaim Fershtman, and Ariel Pakes. 2024. “The Impact of Artificial Intelligence Design on Pricing.” Journal of\nEconomics & Management Strategy, 33(2): 276–304.\nBanchio, Martino, and Giacomo Mantegazza. 2024. “Artificial Intelligence and Spontaneous Collusion.” Working papers.\nBattigalli, Pierpaolo, Simone Cerreia-Vioglio, Fabio Maccheroni, and Massimo Marinacci. 2015. “Self-Confirming\nEquilibrium and Model Uncertainty.” American Economic Review, 105(2): 646–77.\nBellman, Richard Ernest. 1954. The Theory of Dynamic Programming. Santa Monica, CA:RAND Corporation.\nBryzgalova, Svetlana, Anna Pavlova, and Taisiya Sikorskaya. 2025. “Strategic Arbitrage in Segmented Markets.” Journal of\nFinancial Economics, 166(104008).\nCalvano, Emilio, Giacomo Calzolari, Vincenzo Denicoló, and Sergio Pastorello. 2020. “Artificial Intelligence, Algorithmic\nPricing, and Collusion.” American Economic Review, 110(10): 3267–3297.\nCalvano, Emilio, Giacomo Calzolari, Vincenzo Denicoló, and Sergio Pastorello. 2021. “Algorithmic Collusion with\nImperfect Monitoring.” International Journal of Industrial Organization, 79(C).\n42\n\n\n=== 페이지 45 ===\nCao, Sean, Wei Jiang, Junbo Wang, and Baozhong Yang. 2024. “From Man vs. Machine to Man + Machine: The Art and\nAI of Stock Analyses.” Journal of Financial Economics, 160(103910).\nCarlin, Bruce Ian, Miguel Sousa Lobo, and S Viswanathan. 2007. “Episodic Liquidity Crises: Cooperative and Predatory\nTrading.” Journal of Finance, 62(5): 2235–2274.\nCartea, Álvaro, Patrick Chang, José Penalva, and Harrison Waldon. 2022a. “The Algorithmic Learning Equations: Evolving\nStrategies in Dynamic Games.” Working papers.\nCartea, Álvaro, Patrick Chang, Mateusz Mroczka, and Roel Oomen. 2022b. “AI-Driven Liquidity Provision in OTC\nFinancial Markets.” Quantitative Finance, 22(12): 2171–2204.\nCharness, Gary, Francesco Feri, Miguel A. Meléndez-Jiménez, and Matthias Sutter. 2014. “Experimental Games on\nNetworks: Underpinnings of Behavior and Equilibrium Selection.” Econometrica, 82(5): 1615–1670.\nChen, Hsuan-Chi, and Jay R. Ritter. 2000. “The Seven Percent Solution.” Journal of Finance, 55(3): 1105–1131.\nChen, Hui, Winston Wei Dou, Hongye Guo, and Yan Ji. 2023. “Feedback and Contagion through Distressed Competition.”\nJournal of Finance, forthcoming.\nChen, Hui, Winston Wei Dou, Hongye Guo, and Yan Ji. 2024. “Industry Distress Anomaly.” Working papers.\nChen, Hui, Yuhan Cheng, Yanchu Liu, and Ke Tang. 2025. “Teaching Economics to the Machines.” Working papers.\nChen, Shuaiyu, Lin Peng, and Dexin Zhou. 2024. “Wisdom or Whims? Decoding Investor Trading Strategies with Large\nLanguage Models.” Working papers.\nChen, Yifei, Bryan T. Kelly, and Dacheng Xiu. 2024. “Expected Returns and Large Language Models.” Working papers.\nCho, In-Koo, and Thomas J. Sargent. 2008. “Self-Confirming Equilibria.” 407–408. Palgrave Macmillan.\nCho, Inkoo, Noah Williams, and Thomas Sargent. 2002. “Escaping Nash Inflation.” Review of Economic Studies, 69(1): 1–40.\nChristie, William G, and Paul H Schultz. 1994. “Why Do NASDAQ Market Makers Avoid Odd-Eighth Quotes?” Journal of\nFinance, 49(5): 1813–1840.\nChristie, William G., and Paul H. Schultz. 1995. “Policy Watch: Did Nasdaq Market Makers Implicitly Collude?” Journal\nof Economic Perspectives, 9(3): 199–208.\nChristie, William G, Jeffrey H Harris, and Paul H Schultz. 1994. “Why Did NASDAQ Market Makers Stop Avoiding\nOdd-Eighth Quotes?” Journal of Finance, 49(5): 1841–1860.\nColliard, Jean-Edouard, Thierry Foucault, and Stefano Lovo. 2025. “Algorithmic Pricing and Liquidity in Securities\nMarkets.” Working papers.\nCong, Lin, and Zhiguo He. 2019. “Blockchain Disruption and Smart Contracts.” Review of Financial Studies, 32(5): 1754–1797.\nCooper, David J., and Kai-Uwe Kühn. 2014. “Communication, Renegotiation, and the Scope for Collusion.” American\nEconomic Journal: Microeconomics, 6(2): 247–278.\nDolgopolov, Arthur. 2024. “Reinforcement Learning in a Prisoner’s Dilemma.” Games and Economic Behavior, 144(C): 84–103.\nDou, Winston Wei, Wei Wang, and Wenyu Wang. 2023. “The Cost of Intermediary Market Power for Distressed Borrowers.”\nWorking papers.\nDou, Winston Wei, Xiang Fang, Andrew W. Lo, and Harald Uhlig. 2023. “Macro-Finance Models with Nonlinear\nDynamics.” Annual Review of Financial Economics, 15: 407–432.\nDou, Winston Wei, Yan Ji, and Wei Wu. 2021a. “Competition, Profitability, and Discount Rates.” Journal of Financial\nEconomcis, 140(2): 582–620.\nDou, Winston Wei, Yan Ji, and Wei Wu. 2021b. “The Oligopoly Lucas Tree.” Review of Financial Studies, 35(8): 3867–3921.\nDuarte, Victor, Diogo Duarte, and Dejanir H Silva. 2024. “Machine Learning for Continuous-Time Finance.” Review of\nFinancial Studies, 37(11): 3217–3271.\nDugast, Jérôme, and Thierry Foucault. 2018. “Data Abundance and Asset Price Informativeness.” Journal of Financial\nEconomics, 130(2): 367–391.\nDugast, Jérôme, and Thierry Foucault. 2024. “Equilibrium Data Mining and Data Abundance.” Journal of Finance, 80(1): 211–\n258.\nDutta, Prajit K, and Ananth Madhavan. 1997. “Competition and Collusion in Dealer Markets.” Journal of Finance, 52(1): 245–\n276.\nFarboodi, Maryam, and Laura Veldkamp. 2020. “Long-Run Growth of Financial Data Technology.” American Economic\nReview, 110(8): 2485–2523.\nFarboodi, Maryam, and Laura Veldkamp. 2023. “Data and Markets.” Annual Review of Economics, 15: 23–40.\nFershtman, Chaim, and Ariel Pakes. 2012. “Dynamic Games with Asymmetric Information: A Framework for Empirical\nWork.” Quarterly Journal of Economics, 127(4): 1611–1661.\nFonseca, Miguel A., and Hans-Theo Normann. 2012. “Explicit vs. Tacit Collusion: The Impact of Communication in\nOligopoly Experiments.” European Economic Review, 56(8): 1759–1772.\nFudenberg, Drew, and David Levine. 1993. “Self-Confirming Equilibrium.” Econometrica, 61(3): 523–45.\nFudenberg, Drew, and David M. Kreps. 1988. “A Theory of Learning, Experimentation, and Equilibrium in Games.”\nWorking papers.\nFudenberg, Drew, and David M. Kreps. 1995. “Learning in Extensive-Form Games I. Self-Confirming Equilibria.” Games\nand Economic Behavior, 8(1): 20–55.\nFudenberg, Drew, and Eric Maskin. 1986. “The Folk Theorem in Repeated Games with Discounting or with Incomplete\nInformation.” Econometrica, 54(3): 533–54.\nGao, Zhenyu, Wei Xiong, and Jian Yuan. 2024. “Structured Beliefs and Fund Performance: An LLM-Based Approach.”\nWorking papers.\nGenesove, David, and Wallace P. Mullin. 2001. “Rules, Communication, and Collusion: Narrative Evidence from the Sugar\nInstitute Case.” American Economic Review, 91(3): 379–398.\nGoldstein, Itay, Chester S Spatt, and Mao Ye. 2021. “Big Data in Finance.” Review of Financial Studies, 34(7): 3213–3225.\nGoldstein, Itay, Emre Ozdenoren, and Kathy Yuan. 2013. “Trading Frenzies and Their Impact on Real Investment.” Journal\nof Financial Economics, 109(2): 566–582.\n43\n\n\n=== 페이지 46 ===\nGreen, Edward J, and Robert H Porter. 1984. “Noncooperative Collusion under Imperfect Price Information.” Econometrica,\n52(1): 87–100.\nGreenwood, Robin, and Dimitri Vayanos. 2014. “Bond Supply and Excess Bond Returns.” Review of Financial Studies,\n27(3): 663–713.\nGreenwood, Robin, Samuel Hanson, Jeremy C Stein, and Adi Sunderam. 2023. “A Quantity-Driven Theory of Term\nPremia and Exchange Rates.” Quarterly Journal of Economics, 138(4): 2327–2389.\nGrossman, Sanford J., and Joseph E. Stiglitz. 1980. “On the Impossibility of Informationally Efficient Markets.” The\nAmerican Economic Review, 70(3): 393–408.\nHansen, Karsten T., Kanishka Misra, and Mallesh M. Pai. 2021. “Algorithmic Collusion: Supra-Competitive Prices via\nIndependent Algorithms.” Marketing Science, 40(1): 1–12.\nHansen, Lars Peter, Paymon Khorrami, and Fabrice Tourre. 2024. “Comparative Valuation Dynamics in Production\nEconomies: Long-Run Uncertainty, Heterogeneity, and Market Frictions.” Annual Review of Financial Economics, 16: 1–38.\nHarrington, Joseph E. 2018. “Developing Competition Law for Collusion by Autonomous Artificial Agents.” Journal of\nCompetition Law & Economics, 14(3): 331–363.\nHellwig, Christian, Arijit Mukherji, and Aleh Tsyvinski. 2006. “Self-Fulfilling Currency Crises: The Role of Interest\nRates.” American Economic Review, 96(5): 1769–1787.\nHolden, Craig W., and Avanidhar Subrahmanyam. 1992. “Long-Lived Private Information and Imperfect Competition.”\nJournal of Finance, 47(1): 247–270.\nHörner, Johannes, Stefano Lovo, and Tristan Tomala. 2018. “Belief-Free Price Formation.” Journal of Financial Economics,\n127(2): 342–365.\nJohnson, Justin Pappas, Andrew Rhodes, and Matthijs Wildenbeest. 2023. “Platform Design when Sellers Use Pricing\nAlgorithms.” Econometrica, 91(5): 1841–1879.\nKaniel, Ron, Zihan Lin, Markus Pelger, and Stijn Van Nieuwerburgh. 2023. “Machine-Learning the Skill of Mutual Fund\nManagers.” Journal of Financial Economics, 150(1): 94–138.\nKelly, Bryan T., Semyon Malamud, and Kangying Zhou. 2024. “The Virtue of Complexity in Return Prediction.” Journal of\nFinance, 79(1): 459–503.\nKubler, Felix, and Karl Schmedders. 2005. “Approximate versus Exact Equilibria in Dynamic Economies.” Econometrica,\n73(4): 1205–1235.\nKyle, Albert S. 1985. “Continuous Auctions and Insider Trading.” Econometrica, 53(6): 1315–1335.\nKyle, Albert S. 1989. “Informed Speculation with Imperfect Competition.” Review of Economic Studies, 56(3): 317–355.\nKyle, Albert S., and Wei Xiong. 2001. “Contagion as a Wealth Effect.” Journal of Finance, 56(4): 1401–1440.\nLambin, Xavier. 2024. “Less than Meets the Eye: Simultaneous Experiments as a Source of Algorithmic Seeming Collusion.”\nWorking papers.\nLehar, Alfred, and Christine Parlour. 2025. “Market Power and the Bitcoin Protocol.” Working papers.\nLevine, David K., Thomas R. Palfrey, and Charles R. Plott. 1991. “Siegel’s Lemma for Game Players.” Games and Economic\nBehavior, 3(2): 147–173.\nLjungqvist, Lars, and Thomas J. Sargent. 2012. Recursive Macroeconomic Theory, Third Edition. Vol. 1 of MIT Press Books. 3\ned., The MIT Press.\nLo, Andrew W., and A. Craig MacKinlay. 1999. A Non-Random Walk Down Wall Street. Princeton University Press.\nLo, Andrew W., Harry Mamaysky, and Jiang Wang. 2000. “Foundations of Technical Analysis: Computational Algorithms,\nStatistical Inference, and Empirical Implementation.” Journal of Finance, 55(4): 1705–1765.\nMarimon, Ramon, Ellen McGrattan, and Thomas J. Sargent. 1990. “Money as a Medium of Exchange in an Economy with\nArtificially Intelligent Agents.” Journal of Economic Dynamics and Control, 14(2): 329–373.\nMassarotto, Giovanna. 2025. “Detecting Algorithmic Collusion.” Ohio State Law Journal, 73.\nMildenstein, Eckart, and Harold Schleef. 1983. “The Optimal Pricing Policy of a Monopolistic Marketmaker in the Equity\nMarket.” Journal of Finance, 38(1): 218–231.\nOpp, Marcus M., Christine A. Parlour, and Johan Walden. 2014. “Markup Cycles, Dynamic Misallocation, and Amplifica-\ntion.” Journal of Economic Theory, 154: 126–161.\nPossnig, Clemens. 2024. “Reinforcement Learning and Collusion.” Working papers.\nRostek, Marzena, and Ji Hee Yoon. 2021. “Dynamic Imperfectly Competitive Markets with Private Information.” Working\npapers.\nRostek, Marzena, and Ji Hee Yoon. 2024. “Imperfect Competition in Financial Markets: Recent Developments.” Journal of\nEconomic Literature, forthcoming.\nRostek, Marzena, and Marek Weretka. 2012. “Price Inference in Small Markets.” Econometrica, 80(2): 687–711.\nRostek, Marzena, and Marek Weretka. 2015. “Dynamic Thin Markets.” Review of Financial Studies, 28(10): 2946–2992.\nRotemberg, Julio J, and Garth Saloner. 1986. “A Supergame-Theoretic Model of Price Wars during Booms.” American\nEconomic Review, 76(3): 390–407.\nRoutledge, Bryan R. 1999. “Adaptive Learning in Financial Markets.” Review of Financial Studies, 12(5): 1165–1202.\nRoutledge, Bryan R. 2001. “Genetic Algorithm Learning to Choose and Use Information.” Macroeconomic Dynamics,\n5(02): 303–325.\nSannikov, Yuliy, and Andrzej Skrzypacz. 2007. “Impossibility of Collusion under Imperfect Monitoring with Flexible\nProduction.” American Economic Review, 97(5): 1794–1823.\nSutton, Richard S., and Andrew G. Barto. 2018. Reinforcement Learning: An Introduction. The MIT Press.\nVayanos, Dimitri. 1999. “Strategic Trading and Welfare in a Dynamic Market.” Review of Economic Studies, 66(2): 219–254.\nVayanos, Dimitri, and Jean-Luc Vila. 2021. “A Preferred-Habitat Model of the Term Structure of Interest Rates.” Economet-\nrica, 89(1): 77–112.\nWaltman, Ludo, and Uzay Kaymak. 2008. “Q-learning Agents in a Cournot Oligopoly Model.” Journal of Economic Dynamics\nand Control, 32(10): 3275–3293.\nWatkins, Christopher J. C. H., and Peter Dayan. 1992. “Q-learning.” Machine Learning, 8(3): 279–292.\n44"
}