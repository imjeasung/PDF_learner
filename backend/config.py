# í”„ë¡œì íŠ¸ ì„¤ì • ê´€ë¦¬ ëª¨ë“ˆ
# ëª¨ë“  ì„¤ì •ê°’ì„ ì¤‘ì•™ì—ì„œ ê´€ë¦¬í•˜ì—¬ í•˜ë“œì½”ë”©ì„ ì œê±°í•©ë‹ˆë‹¤.

import os
from typing import List
from dotenv import load_dotenv

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

class Settings:
    """í”„ë¡œì íŠ¸ ì„¤ì • í´ë˜ìŠ¤ - ëª¨ë“  ì„¤ì •ê°’ì„ ì¤‘ì•™ ê´€ë¦¬"""
    
    # ===== API ì„¤ì • =====
    OPENAI_API_KEY: str = os.getenv("OPENAI_API_KEY")
    OPENAI_MODEL: str = os.getenv("OPENAI_MODEL", "gpt-3.5-turbo")
    OPENAI_EMBEDDING_MODEL: str = os.getenv("OPENAI_EMBEDDING_MODEL", "text-embedding-ada-002")
    MAX_TOKENS: int = int(os.getenv("MAX_TOKENS", "1000"))
    TEMPERATURE: float = float(os.getenv("TEMPERATURE", "0.7"))
    
    # ===== íŒŒì¼ ë° í´ë” ê²½ë¡œ ì„¤ì • =====
    UPLOAD_FOLDER: str = os.getenv("UPLOAD_FOLDER", "uploads")
    DATA_FOLDER: str = os.getenv("DATA_FOLDER", "data")
    STATIC_FOLDER: str = os.getenv("STATIC_FOLDER", "static")
    
    # í•˜ìœ„ í´ë” ê²½ë¡œë“¤
    @property
    def EXTRACTED_FOLDER(self) -> str:
        return f"{self.DATA_FOLDER}/extracted"
    
    @property
    def SUMMARIES_FOLDER(self) -> str:
        return f"{self.DATA_FOLDER}/summaries"
    
    @property
    def VECTOR_DB_FOLDER(self) -> str:
        return f"{self.DATA_FOLDER}/vector_db"
    
    # ===== ì„œë²„ ì„¤ì • =====
    HOST: str = os.getenv("HOST", "0.0.0.0")
    PORT: int = int(os.getenv("PORT", "8000"))
    DEBUG: bool = os.getenv("DEBUG", "False").lower() == "true"
    
    # ===== ë°°í¬ í™˜ê²½ ì„¤ì • =====
    KOYEB_PUBLIC_DOMAIN: str = os.getenv("KOYEB_PUBLIC_DOMAIN")
    IS_PRODUCTION: bool = KOYEB_PUBLIC_DOMAIN is not None
    
    # ===== CORS ì„¤ì • =====
    @property
    def ALLOWED_ORIGINS(self) -> List[str]:
        """í™˜ê²½ì— ë”°ë¥¸ CORS í—ˆìš© ë„ë©”ì¸ ì„¤ì •"""
        base_origins = [
            "http://localhost:8000",
            "http://127.0.0.1:8000"
        ]
        
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ ì¶”ê°€ ë„ë©”ì¸ ì„¤ì •
        env_origins = os.getenv("ALLOWED_ORIGINS", "").split(",")
        env_origins = [origin.strip() for origin in env_origins if origin.strip()]
        
        # Koyeb ë°°í¬ ë„ë©”ì¸ ì¶”ê°€
        if self.KOYEB_PUBLIC_DOMAIN:
            base_origins.extend([
                f"https://{self.KOYEB_PUBLIC_DOMAIN}",
                f"http://{self.KOYEB_PUBLIC_DOMAIN}"
            ])
        
        # í™˜ê²½ë³€ìˆ˜ ë„ë©”ì¸ ì¶”ê°€
        base_origins.extend(env_origins)
        
        return list(set(base_origins))  # ì¤‘ë³µ ì œê±°
    
    # ===== íŒŒì¼ ì œí•œ ì„¤ì • =====
    MAX_FILE_SIZE_MB: int = int(os.getenv("MAX_FILE_SIZE_MB", "50"))
    
    # ===== ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • =====
    DATABASE_URL: str = os.getenv("DATABASE_URL", "sqlite:///./pdf_learner.db")
    
    # ===== AI ì²˜ë¦¬ ì„¤ì • =====
    CHUNK_SIZE: int = int(os.getenv("CHUNK_SIZE", "1000"))
    CHUNK_OVERLAP: int = int(os.getenv("CHUNK_OVERLAP", "200"))
    EMBEDDING_BATCH_SIZE: int = int(os.getenv("EMBEDDING_BATCH_SIZE", "50"))
    EMBEDDING_DIMENSION: int = int(os.getenv("EMBEDDING_DIMENSION", "1536"))
    
    # ===== ë²¡í„° DB ì„¤ì • =====
    VECTOR_DB_PATH: str = os.getenv("VECTOR_DB_PATH", f"{DATA_FOLDER}/vector_db")
    
    # ===== AI Provider ì„¤ì • =====
    # ê¸°ë³¸ AI ì œê³µì—…ì²´ ì„¤ì •
    DEFAULT_AI_PROVIDER: str = os.getenv("DEFAULT_AI_PROVIDER", "openai")
    
    # OpenAI ì„¤ì • (ê¸°ì¡´ í˜¸í™˜ì„± ìœ ì§€)
    @property
    def OPENAI_CONFIG(self) -> dict:
        """OpenAI Provider ì„¤ì • ë°˜í™˜"""
        return {
            "provider_name": "openai",
            "api_key": self.OPENAI_API_KEY,
            "default_model": self.OPENAI_MODEL,
            "default_embedding_model": self.OPENAI_EMBEDDING_MODEL,
            "max_tokens": self.MAX_TOKENS,
            "temperature": self.TEMPERATURE
        }
    
    # ë‹¤ì¤‘ AI Provider ì„¤ì •
    @property
    def AI_PROVIDERS_CONFIG(self) -> dict:
        """ëª¨ë“  AI Provider ì„¤ì • ë°˜í™˜"""
        providers = {}
        
        # OpenAI ì„¤ì • (API í‚¤ê°€ ìˆì„ ë•Œë§Œ)
        if self.OPENAI_API_KEY:
            providers["openai"] = self.OPENAI_CONFIG
        
        # Anthropic ì„¤ì • (í™˜ê²½ë³€ìˆ˜ê°€ ìˆì„ ë•Œ)
        anthropic_key = os.getenv("ANTHROPIC_API_KEY")
        if anthropic_key:
            providers["anthropic"] = {
                "provider_name": "anthropic",
                "api_key": anthropic_key,
                "default_model": os.getenv("ANTHROPIC_MODEL", "claude-3-sonnet-20240229"),
                "max_tokens": int(os.getenv("ANTHROPIC_MAX_TOKENS", "1000")),
                "temperature": float(os.getenv("ANTHROPIC_TEMPERATURE", "0.7"))
            }
        
        # Local LLM ì„¤ì • (í™˜ê²½ë³€ìˆ˜ê°€ ìˆì„ ë•Œ)
        local_model_path = os.getenv("LOCAL_MODEL_PATH")
        if local_model_path:
            providers["local"] = {
                "provider_name": "local",
                "model_path": local_model_path,
                "default_model": os.getenv("LOCAL_MODEL", "llama2"),
                "max_tokens": int(os.getenv("LOCAL_MAX_TOKENS", "1000")),
                "temperature": float(os.getenv("LOCAL_TEMPERATURE", "0.7"))
            }
        
        return providers
    
    # ì§€ì›í•˜ëŠ” ëª¨ë¸ ëª©ë¡ (í™•ì¥ ê°€ëŠ¥)
    @property
    def SUPPORTED_TEXT_MODELS(self) -> dict:
        """ì§€ì›í•˜ëŠ” í…ìŠ¤íŠ¸ ìƒì„± ëª¨ë¸ ëª©ë¡"""
        return {
            "openai": [
                "gpt-3.5-turbo",
                "gpt-3.5-turbo-16k", 
                "gpt-4",
                "gpt-4-turbo-preview",
                "gpt-4o",
                "gpt-4o-mini"
            ],
            "anthropic": [
                "claude-3-haiku-20240307",
                "claude-3-sonnet-20240229",
                "claude-3-opus-20240229",
                "claude-3-5-sonnet-20241022"
            ],
            "local": [
                "llama2",
                "llama3",
                "mistral-7b",
                "gemma-7b",
                "qwen2-7b"
            ]
        }
    
    @property
    def SUPPORTED_EMBEDDING_MODELS(self) -> dict:
        """ì§€ì›í•˜ëŠ” ì„ë² ë”© ëª¨ë¸ ëª©ë¡"""
        return {
            "openai": [
                "text-embedding-ada-002",
                "text-embedding-3-small",
                "text-embedding-3-large"
            ],
            "local": [
                "all-MiniLM-L6-v2",
                "all-mpnet-base-v2",
                "multilingual-e5-large"
            ]
        }
    
    # AI Provider ê¸°ëŠ¥ í”Œë˜ê·¸
    ENABLE_MULTI_PROVIDER: bool = os.getenv("ENABLE_MULTI_PROVIDER", "True").lower() == "true"
    ENABLE_LOCAL_LLM: bool = os.getenv("ENABLE_LOCAL_LLM", "False").lower() == "true"
    ENABLE_MODEL_SWITCHING: bool = os.getenv("ENABLE_MODEL_SWITCHING", "True").lower() == "true"
    
    def validate_required_settings(self) -> None:
        """í•„ìˆ˜ ì„¤ì •ê°’ë“¤ì´ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ ê²€ì¦"""
        errors = []
        warnings = []
        
        # AI Provider ì„¤ì • ê²€ì¦
        providers_config = self.AI_PROVIDERS_CONFIG
        if not providers_config:
            warnings.append("No AI providers configured. At least one provider is recommended.")
        
        # ê¸°ë³¸ ì œê³µì—…ì²´ ê²€ì¦
        if self.DEFAULT_AI_PROVIDER not in providers_config:
            if providers_config:
                # ì‚¬ìš© ê°€ëŠ¥í•œ ì²« ë²ˆì§¸ ì œê³µì—…ì²´ë¡œ ëŒ€ì²´
                available_provider = list(providers_config.keys())[0]
                warnings.append(f"Default provider '{self.DEFAULT_AI_PROVIDER}' not available. Using '{available_provider}' instead.")
            else:
                errors.append(f"Default provider '{self.DEFAULT_AI_PROVIDER}' not configured and no alternatives available")
        
        # OpenAI ì„¤ì • ê²€ì¦ (OpenAIê°€ ì„¤ì •ëœ ê²½ìš°ë§Œ)
        if "openai" in providers_config:
            if not self.OPENAI_API_KEY:
                errors.append("OPENAI_API_KEY is required when OpenAI provider is enabled")
        
        # Anthropic ì„¤ì • ê²€ì¦
        if "anthropic" in providers_config:
            anthropic_key = os.getenv("ANTHROPIC_API_KEY")
            if not anthropic_key:
                errors.append("ANTHROPIC_API_KEY is required when Anthropic provider is enabled")
        
        # í”„ë¡œë•ì…˜ í™˜ê²½ ê²€ì¦
        if self.IS_PRODUCTION:
            if not self.KOYEB_PUBLIC_DOMAIN:
                errors.append("KOYEB_PUBLIC_DOMAIN is required for production")
        
        # íŒŒì¼ í¬ê¸° ì œí•œ ê²€ì¦
        if self.MAX_FILE_SIZE_MB <= 0:
            errors.append("MAX_FILE_SIZE_MB must be greater than 0")
        
        # AI ì„¤ì • ê²€ì¦
        if self.CHUNK_SIZE <= 0:
            errors.append("CHUNK_SIZE must be greater than 0")
        
        if self.CHUNK_OVERLAP < 0:
            errors.append("CHUNK_OVERLAP must be non-negative")
        
        if self.TEMPERATURE < 0 or self.TEMPERATURE > 2:
            errors.append("TEMPERATURE must be between 0 and 2")
        
        # ê²½ê³  ì¶œë ¥
        if warnings:
            print("âš ï¸  Configuration warnings:")
            for warning in warnings:
                print(f"   - {warning}")
        
        # ì˜¤ë¥˜ ì²˜ë¦¬
        if errors:
            error_message = "Configuration validation failed:\n" + "\n".join(f"- {error}" for error in errors)
            raise ValueError(error_message)
    
    def get_folder_paths(self) -> List[str]:
        """ìƒì„±í•´ì•¼ í•  ëª¨ë“  í´ë” ê²½ë¡œ ëª©ë¡ì„ ë°˜í™˜"""
        return [
            self.UPLOAD_FOLDER,
            self.DATA_FOLDER,
            self.EXTRACTED_FOLDER,
            self.SUMMARIES_FOLDER,
            self.VECTOR_DB_FOLDER,
            self.STATIC_FOLDER,
            "backend"  # backend í´ë”ë„ í¬í•¨
        ]
    
    def display_settings(self) -> str:
        """í˜„ì¬ ì„¤ì •ê°’ë“¤ì„ í‘œì‹œìš© ë¬¸ìì—´ë¡œ ë°˜í™˜ (ë¯¼ê°ì •ë³´ ì œì™¸)"""
        providers_config = self.AI_PROVIDERS_CONFIG
        
        # AI Provider ì •ë³´
        provider_info = []
        for name, config in providers_config.items():
            has_key = "api_key" in config and bool(config["api_key"])
            provider_info.append(f"- {name.upper()}: {'âœ… Configured' if has_key else 'âŒ No API Key'}")
        
        if not provider_info:
            provider_info.append("- No providers configured")
        
        return f"""
PDF Learner Settings:
===================
Environment: {'Production' if self.IS_PRODUCTION else 'Development'}
Host: {self.HOST}:{self.PORT}
Debug Mode: {self.DEBUG}

Folders:
- Upload: {self.UPLOAD_FOLDER}
- Data: {self.DATA_FOLDER}
- Static: {self.STATIC_FOLDER}

AI Provider Settings:
- Default Provider: {self.DEFAULT_AI_PROVIDER}
- Multi-Provider: {'Enabled' if self.ENABLE_MULTI_PROVIDER else 'Disabled'}
- Model Switching: {'Enabled' if self.ENABLE_MODEL_SWITCHING else 'Disabled'}
- Local LLM: {'Enabled' if self.ENABLE_LOCAL_LLM else 'Disabled'}

Configured Providers:
{chr(10).join(provider_info)}

AI Processing:
- Chunk Size: {self.CHUNK_SIZE}
- Temperature: {self.TEMPERATURE}
- Embedding Batch: {self.EMBEDDING_BATCH_SIZE}

File Limits:
- Max Size: {self.MAX_FILE_SIZE_MB}MB

CORS Origins: {len(self.ALLOWED_ORIGINS)} domains configured
Database: {self.DATABASE_URL}
        """.strip()

# ì „ì—­ ì„¤ì • ì¸ìŠ¤í„´ìŠ¤
settings = Settings()

# ì„¤ì • ê²€ì¦ í•¨ìˆ˜
def validate_settings() -> None:
    """ì„¤ì •ê°’ ê²€ì¦ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    try:
        settings.validate_required_settings()
        print("âœ… ì„¤ì • ê²€ì¦ ì™„ë£Œ")
    except ValueError as e:
        print(f"âŒ ì„¤ì • ê²€ì¦ ì‹¤íŒ¨:\n{e}")
        raise

# ì„¤ì • ì •ë³´ ì¶œë ¥ í•¨ìˆ˜
def print_settings() -> None:
    """í˜„ì¬ ì„¤ì • ì •ë³´ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."""
    print(settings.display_settings())

# ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ìš©
if __name__ == "__main__":
    print("ğŸ”§ Config ëª¨ë“ˆ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    try:
        # ì„¤ì • ê²€ì¦
        validate_settings()
        
        # ì„¤ì • ì •ë³´ ì¶œë ¥
        print_settings()
        
        print("\nğŸ‰ Config ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"\nâŒ Config ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")